{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>a) Cargue los datos de entrenamiento y pruebas (\\train 32x32.mat\" y \\test 32x32.mat\"). Determine el\n",
    "tama~no de las im\u0013agenes, el n\u0013umero de clases diferentes y de ejemplos en cada categor\u0013\u0010a. Finalmente,\n",
    "visualice 5 im\u0013agenes de entrenamiento y 5 de test (elegidas aleatoriamente).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Cantidad de ejemplos por categoría en dataset de entrenamiento\n",
      "clase: 0\n",
      "13861\n",
      "___________________________________________-\n",
      "clase: 1\n",
      "10585\n",
      "___________________________________________-\n",
      "clase: 2\n",
      "8497\n",
      "___________________________________________-\n",
      "clase: 3\n",
      "7458\n",
      "___________________________________________-\n",
      "clase: 4\n",
      "6882\n",
      "___________________________________________-\n",
      "clase: 5\n",
      "5727\n",
      "___________________________________________-\n",
      "clase: 6\n",
      "5595\n",
      "___________________________________________-\n",
      "clase: 7\n",
      "5045\n",
      "___________________________________________-\n",
      "clase: 8\n",
      "4659\n",
      "___________________________________________-\n",
      "clase: 9\n",
      "4948\n",
      "___________________________________________-\n",
      "Cantidad de ejemplos por categoría en dataset de prueba\n",
      "clase: 0\n",
      "5099\n",
      "___________________________________________-\n",
      "clase: 1\n",
      "4149\n",
      "___________________________________________-\n",
      "clase: 2\n",
      "2882\n",
      "___________________________________________-\n",
      "clase: 3\n",
      "2523\n",
      "___________________________________________-\n",
      "clase: 4\n",
      "2384\n",
      "___________________________________________-\n",
      "clase: 5\n",
      "1977\n",
      "___________________________________________-\n",
      "clase: 6\n",
      "2019\n",
      "___________________________________________-\n",
      "clase: 7\n",
      "1660\n",
      "___________________________________________-\n",
      "clase: 8\n",
      "1595\n",
      "___________________________________________-\n",
      "clase: 9\n",
      "1744\n",
      "___________________________________________-\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "%matplotlib inline\n",
    "\n",
    "train_data = sio.loadmat('train_32x32.mat')\n",
    "test_data = sio.loadmat('test_32x32.mat')\n",
    "X_train = train_data['X'].T\n",
    "y_train = train_data['y'] - 1\n",
    "X_test = test_data['X'].T\n",
    "y_test = test_data['y'] - 1\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "n_classes = len(np.unique(y_train))\n",
    "print(n_classes)\n",
    "occurrenses = 0\n",
    "print(\"Cantidad de ejemplos por categoría en dataset de entrenamiento\")\n",
    "for i in range(0,10):\n",
    "    print(\"clase: \" + str(i))\n",
    "    occurrenses += np.count_nonzero(y_train == [i])\n",
    "    print(np.count_nonzero(y_train == [i]))\n",
    "    print(\"___________________________________________-\")\n",
    "\n",
    "print(\"Cantidad de ejemplos por categoría en dataset de prueba\")\n",
    "for i in range(0,10):\n",
    "    print(\"clase: \" + str(i))\n",
    "    print(np.count_nonzero(y_test == [i]))\n",
    "    print(\"___________________________________________-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "6252\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f62a881630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19252\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHjNJREFUeJztnVuMXNd1pv9V976xL2yS3eJFJC1GlmSPaaEjCBPFsGMk\n0RgBbL8I8UOgByMKMBljDGQeBAeIPW+ewdiGHwYG6LEQZeA4NsY2LARGAksRIDvRyKJsXUjRuvDO\nZrOb7Ht3dVXXZc1DlzAUtf/NYl+qKe//AwhW73X2OfvsOuucqv3XWsvcHUKI9Mhs9wCEENuDnF+I\nRJHzC5Eocn4hEkXOL0SiyPmFSBQ5vxCJIucXIlHk/EIkSm4jnc3sYQDfBJAF8L/c/aux7QsDXd49\n0he0ZYz/0jBnzWB7b7ZC+5SbRWpbXOW2rlyN2oqZOrUxlhsFaqs1stTWaK7vvry7azHY3pOp0j7L\nkbkqGD/nlSY/t2srPcF2M9oFPQU+xnwmfA0AgIFfO7VmeI7rzue3kGlQ23quAQBYaeSpbbkWnsfm\nKr8+QKajPjuDxvJyZJb/P+t2fjPLAvifAP4QwCUAL5rZU+7+OuvTPdKHj337kbAtt0qPNVxcCrY/\ntONN2uel5UPU9uzlI9T24Z0T1Hao+xq1MY7P3kltl5d2UNvcYhe1ZbP8Yv+P9z4XbP/33W/RPv9W\n5vOxvzBNbSdW9lHbkyceDLZbxIkfvPMctY2WFqgtb9xZJyr9wfbpavjmBAAHemao7WCJz0eMk0t3\nUNsvJw4E25cvhh+UAJBdCd+8Ln3zG22PaSMf+x8A8La7n3H3VQD/AODTG9ifEKKDbMT59wK4eN3f\nl1ptQoj3AVu+4Gdmj5nZcTM7vjq3stWHE0K0yUacfxzA/uv+3tdqexfufszdx9x9rDDAv8cKITrL\nRpz/RQBHzOyQmRUA/CmApzZnWEKIrWbdq/3uXjez/wTgn7Em9T3h7iejfWBUYslF5BW2mhuT82Ls\n7gmrBwDwuzvOUlsfkRYvrQ6taxx39PIV7EKWz8fUXC+1lSPyG2Mox+dj1bncNFvrprZ6OXxpZYr8\nvO7r5UrLIzt+TW01cGXrX5Z/J9j+9PQ9tM9cjX9CrRUj8ts6qVZv3Q3ru4gknW8/Oc+GdH53/ymA\nn25kH0KI7UG/8BMiUeT8QiSKnF+IRJHzC5Eocn4hEmVDq/23SiFTx97uuaCtN8sjunYXwpFq3ZFI\ntRilLI/cY3IewCW952cO0z4X5geobWdPmdpWIxF/+TyXyw4Vp4Ltd0X6zDXD7wkATDe4rHhyfpTa\nsvPhS8t383H0Z/l87MtF5Dfn+5xvhOXIM7M7aZ9clgcf5UmEKRCP3Ht7bpjaajOlYHumySXMnsHw\nXGUiY3/Ptm1vKYT4rULOL0SiyPmFSBQ5vxCJIucXIlE6utqfNcdAPhzTvyfPg1z25OeD7TXnw4+t\nvC7VeEDQ2eouamPE8sGtl2qNn1tPiac8u69wJdjen+Gr5bE0WJM1rlZMLXElgNHduz6F5tVVPsYY\nJ5fCisTstUiKrEjw0XhXOC0YAFTq/JqbnuFzlV8IKzvNSJBOLOdlu+jJL0SiyPmFSBQ5vxCJIucX\nIlHk/EIkipxfiETpqNSXQwNDueWgjcl5ADCSCweexIJOluvry+8XY7ERDsCIBQrt7uX58UpZXvqp\n3uD35ZUKl+1+Xr4r2L7YvED7zDS4fJWPlOsq5rmt0ReWyz68m+fpi+USnGvGAnv4ZTxRDp+bLUVK\npa3yuZ/q49dcrMRac4WPkY2k0cWDdPpKYck0G6mIdCN68guRKHJ+IRJFzi9Eosj5hUgUOb8QiSLn\nFyJRNiT1mdk5AIsAGgDq7j4W237VcxivhqPEmIwGAJO5sFwzWdtB+8zX+P568zyybDgXzhcIAGfL\n4Txs86vrK0AaK1FWrfCyW36Vy5g/3HV/sP3sEI9WvKfrMrUdLFyjtr29XJ692hN+b0ZLMUmX2wrg\ncxUWj9eoRXIhUjI8Yi6W328Hkd8AoNzL37MaydVnJX7OvYXwsW4l2m8zdP5PuDu/QoQQtyX62C9E\nomzU+R3A02b2kpk9thkDEkJ0ho1+7H/I3cfNbDeAn5nZb9z9ues3aN0UHgOA3hFe0lkI0Vk29OR3\n9/HW/1MAfgzggcA2x9x9zN3Hugb5IpwQorOs2/nNrMfM+t55DeCPAJzYrIEJIbaWjXzs3wPgx2b2\nzn7+3t3/KdZhpZ7HqzN7g7ZyjSc/LGTDksfkDJf66kt8f3sPTFPb0B4eWcZkqtMLvBRTNSI1ZSOl\nnzLknAGgWeNlnFbIPO4rzNI+6y17Vm/yc3Nyam8s7qF9ni8cobax7jPUFktAOtwVfj8vNkdoH6/z\n+Y0Ru4bdI/skcxUbR2MTksau2/nd/QyAj2x4BEKIbUFSnxCJIucXIlHk/EIkipxfiESR8wuRKB1N\n4GnmKOXCyS5ZO8Cj8HKRZIVXiz3UNlAK1wsE4rXpTszfET7WIj/Wju4KtcXIZnl0Vq2HS1sjPeGa\nh33Z9Z3zJedy3uUlLrVm8+ExDhV5DF4tcqzXK/uoLca1lXDCzYg6iEwkgefc4voiOJn0CQBGJD0j\nSVABYFcpLGHGfOJG9OQXIlHk/EIkipxfiESR8wuRKHJ+IRKlo6v9fbkqHho+fcv9ujOrYcMg73Ou\nspPaqk1+2rG8gJPl8MpxrcZXqas1fqwl43ndMpFV2+49fMV8J1lNf22Zr5ZPVHi5rnKd5xKcnuGl\nq5rV8JyMlsJqBACMdZ+ltit1PsZTK2EVBuDBNo1+Xmos30uuNwA7+/ncx97rWC7BpWUSEBQp2TZc\nJKv9kWCxG9GTX4hEkfMLkShyfiESRc4vRKLI+YVIFDm/EInSUakvZ41oOSxGzcPDLDe5DHVmiefV\nOz/LNcJ8JHfe/Hw49bjP8nEs1Hi6ci56Ac2dPNDp3oO8vNZAPhzAM1HhEubVCpfsYhKVR6SoTJEE\n9uRixbU4sTyDsX3eNRAuJvXhnRO0zx8MnqK2kdwctcWCj+YbPCDo6Z4PBtunl/m1w+Tq9ot16ckv\nRLLI+YVIFDm/EIki5xciUeT8QiSKnF+IRLmp1GdmTwD4EwBT7v6hVtsQgO8DOAjgHIBH3J3Xg2pR\n9TzOVncFbbGSS/d0haWtvkjOtzcu87JQvf/GJZT8AhdLhsjhMpF8cKUZbrQGP9bkAzzib+huLm0d\nKl4Ntq80eCmphRyXoepZ/nzIFiIlxRrhvHRnVrgES6M3Afxx7+vU9oF8+Jxjx+vNrq9E2bOL91Jb\nLAfhJ/q4fJgfDc/js1d/h/Zh72czVhbsBtp58v8tgIdvaHscwDPufgTAM62/hRDvI27q/O7+HICZ\nG5o/DeDJ1usnAXxmk8clhNhi1vudf4+7v/MTqStYq9grhHgfseEFP3d3RH5VaGaPmdlxMztenl3f\n9ywhxOazXuefNLNRAGj9P8U2dPdj7j7m7mPdg3wRSwjRWdbr/E8BeLT1+lEAP9mc4QghOkU7Ut/3\nAHwcwLCZXQLwZQBfBfADM/s8gPMAHmnnYKvNLC6WwxF1LCEhAPSQiK4rNZ7UERe5fDXyc65KZub4\nOMofDC9tLB7gMlqtl99fC/NcKstGqnzlbyFJ4ztcq/LIvUqDXwYN5+NvrEYi/kgJqsVaifaJRb69\nXOVJOt+sjFLbv7x9d7C9vsAjMX9c/11q6znPz7nOFWT86mP7qY2V3orNPbsG2hf62nB+d/8cMX3y\nFo4jhLjN0C/8hEgUOb8QiSLnFyJR5PxCJIqcX4hE6WgCT3fDajMslSzX+Q+Afr4Qjm56afoA7bPj\nDB9HZqFMbav7eY2/q0fD8lD5Hv7LxUyey3KZi1z2cuMRf9PVHmpjUZMxhop8PhYi0pw3I8ISeayM\nluZpl/5sOPkoAPz9xIPU9sppLqMNHA+/ZwOneQRh11kuBTfPXqQ2u/swtZ0p8OSe5w6Fz7tQ5Elc\nmTzYvAWxT09+IRJFzi9Eosj5hUgUOb8QiSLnFyJR5PxCJEpHpb6GG5ZqYUmvTiRAADh+JSzl1F/g\nNfdG3uLy28oHeBLJy7/PJcf6XWFJJhuR5fYO89puC338WLNXeG29C/MD1Hag58aMa2sc7gnXrAPi\nte7eKPMkTaf7+DzWVsOX1tMXw1F2ALBwjUuYO1/gkZNHTnKp0jP1YPvyPi5hFqci8maNS4TZRT6P\nuaUhaquQZKc9JX6sj+y4FGz/RSQJ6o3oyS9Eosj5hUgUOb8QiSLnFyJR5PxCJErHA3sq9fCqbSxf\n2cKVvmD7vt/wHHiFab4CfO1+vlpe3RVeHQYAq4XH6GWuVEx38cRu1Wpk+iNBMztKt54CfaLC8x3u\n6VugtlhZK7aiDwD5N8P5+PKX+Ur6obN8pbowz3Mrxlg6EJ7/mXv49WbN8PUGAH0neO4/ZPg+691c\nEcpkw7ZshgeFzdTDykgd/Fp8z3Hb3lII8VuFnF+IRJHzC5Eocn4hEkXOL0SiyPmFSJR2ynU9AeBP\nAEy5+4dabV8B8OcArrY2+5K7/3QjA1mp8cCNTCV8j+qa5DnfPCK7VAcjec4KXF5hOesyq/xYSxO8\nTFbsWLkdXPa6o4fnwZurhSW2rizPB1ducvnq2fEj1Nb3PC+vNfxyWGrNLvNxeJHLVMv7uGS6MsTn\nf5Gk1avt5RJm9QKfDy4CAt4VKUS7yY/Z00vhoKpqpPTajbQzpL8F8HCg/RvufrT1b0OOL4ToPDd1\nfnd/DkA4TlQI8b5lIx9GvmBmr5rZE2bGA+uFELcl63X+bwE4DOAogAkAX2MbmtljZnbczI7X5vlP\nboUQnWVdzu/uk+7ecPcmgG8DeCCy7TF3H3P3sXx/pIC5EKKjrMv5zWz0uj8/C+DE5gxHCNEp2pH6\nvgfg4wCGzewSgC8D+LiZHQXgAM4B+It2DpbNNDFQDMtzuQyP0Bvv5iW0KDl+X2vwwDKgHrkfEmmu\nWeKSna1yWdEiUXHdwzwfXKzk1emlcLmuBXBZ7rnzd1Fb4V+5uDX6r3wcjPl7+P7KuyOS6UE+x80d\nXD7s7g9fb/2R/HjVPl7yLLtvlNoqI/zcGiUe1dfTHZYdjwxcDbYDwNG+cA6/F3PtR3ze1Pnd/XOB\n5u+0fQQhxG2JfuEnRKLI+YVIFDm/EIki5xciUeT8QiRKRxN4FjINWk5qd2GR9js5GJZXqkNcvipd\nq1BbPpILMibNZXeEk3sOj/KxV2t8imMluVYqPMrx6iqPFDw5Hp6r7l/yH1jtfpsnLS1d45O1dJiP\nY/pD4Qi9yv5IOanIoyhb5FJwqcDHv6svLJkyyRkAXh/hZcjm7x+htsX9PCrRd/PjdRfDczJa4olV\nDxengu1F47LnjejJL0SiyPmFSBQ5vxCJIucXIlHk/EIkipxfiETpqNRX9wyuVcPyUEzq+8Cua8H2\nMx89RPvsPMFlwK5rkQixHJdrFkukzmA/v4euVHkyyMJVPv2ZcS71PX/+Pmrb9etw9Njg8xdpHy/y\nMS58mMteE7/PZdHdd08G22PS59wMlw4by7xfYzEii5J6d/kslw5jNIr8nFdGeORebx+XnsvkGrlY\n5gmyhnJhSbfSPEP73Iie/EIkipxfiESR8wuRKHJ+IRJFzi9EonR2tb+ZwdVKeEV3tsQDT/aUwkrA\nyUM8SGRplq9g90zwld7+s9y243z4Xlnv4jkGB3nMCYqzPAijUVrffbn31HSwffEozz1X3s0VjrkP\n8hXsnUfCxwKAnV3hNO1TTb6ib9lIqbRcJBfiUkRtWQwnbDxbiZTkusSPlVuJKEVcdEBfiefWm17s\nCba/PceVFkas9NqN6MkvRKLI+YVIFDm/EIki5xciUeT8QiSKnF+IRGmnXNd+AH8HYA/WynMdc/dv\nmtkQgO8DOIi1kl2PuPtsbF/duRruH+IBJozpalgKsQyXocqj3OYZLm31jnOpr2uy/VJI75Cpc2ko\nxswd4XMGgIXDvN/FPw7Ljr2jPBdfZYXLQ81VPldZEjQDADkL2wqRgJr+fl7FeUdMKlvmMnF/Vzig\nZvwCl2eHXufHqg5GAowiuu6BPu4as8s8CI2xUAtLmA1v/3nezpZ1AH/l7vcCeBDAX5rZvQAeB/CM\nux8B8EzrbyHE+4SbOr+7T7j7r1qvFwGcArAXwKcBPNna7EkAn9mqQQohNp9b+s5vZgcBfBTACwD2\nuPtEy3QFa18LhBDvE9p2fjPrBfBDAF9093clFHd3x9p6QKjfY2Z23MyOl2dv/TuzEGJraMv5zSyP\nNcf/rrv/qNU8aWajLfsogGAVAXc/5u5j7j7WPVjcjDELITaBmzq/mRmA7wA45e5fv870FIBHW68f\nBfCTzR+eEGKraCeq7/cA/BmA18zs5VbblwB8FcAPzOzzAM4DeORmO6o2cji9FI5UqjR4SNTlBV7W\nirG6k0tKtf5IHrZd/H64uissiWX7ItF582FJBgDyC1xGq+3m+9x7R7jkGQB05cP9ilkuQ50HzxVX\nz0dk0UKk9BZhtRE554htodK5T42VYX4tLu7j18fg8By1rTb5uZXnw1Jfrcb7MMm00eTX9o3c1Pnd\n/RcA2B4/2faRhBC3FfqFnxCJIucXIlHk/EIkipxfiESR8wuRKB1N4Fmp5/DW9K6grZjnUhQr8RRL\n+Ng3wiPE7tt1hdq6slximyeRVP15XoppvNzPbfPc1rvOclKXZgaC7fWIbNSIRO5l8nyOsyRyDwAq\njfB7FosEjEUXLpUjpc2KkUhBEtU3OLIQbAeAyw/3UdvdByeo7RO73qS2Mys8GSeLTvUmfzaXV8Ny\nZNPbl/r05BciUeT8QiSKnF+IRJHzC5Eocn4hEkXOL0SidFTq68mvYmwknMBzuMgTTLJIwFNTPHlQ\nd5FHnI2W5qltb5FHZp2rhJM+Xqvy+nNTS9y2TKK5gLiMuRC5ZTfmSURapI+tcnmo0c1ltPkqj1gs\nEqmStQNAqYu/ZyvjfK48zy/j+d7wGEd2hOs/AsDOnohM3M+lvjeX+fV4eoFLfUxOLRS57MwiIF1S\nnxDiZsj5hUgUOb8QiSLnFyJR5PxCJEpHV/tzmSZd1e/L8uAYlt9vtcpzrc1FgiJOd4eDiwBgrsZL\nP+Uy4ZXqcj0WkMJzz3mFB9TkBvhK772jk9SGfeHmyTJXHa5M8Bx+MRqROWZJ2mN96nU+H5EYIjQj\nZduaJKddLF9gjKcv3k1tixd4rslMLaKokDJfd0SCjxgXbyEgTE9+IRJFzi9Eosj5hUgUOb8QiSLn\nFyJR5PxCJMpNpT4z2w/g77BWgtsBHHP3b5rZVwD8OYCrrU2/5O4/je0riyaV9CpNLtsxcnkua3RF\nAnuYZAcANef3wwuLYUlsvsIDXGJ52BCRqPKRc9vTxSWg/aXZYPtx3En7TOW5RGWR4Q918QCYpdWw\nxDlX5nNVmeeyaJ5PFWyQv9dHhq8F2w/08JJnczUeRDRb3ktt2RU+WblyTOoLt4928wC0Oin/lYvk\nSHzPtm1sUwfwV+7+KzPrA/CSmf2sZfuGu/+Pto8mhLhtaKdW3wSAidbrRTM7BYDf/oQQ7wtu6Tu/\nmR0E8FEAL7SavmBmr5rZE2a2vp+JCSG2hbad38x6AfwQwBfdfQHAtwAcBnAUa58Mvkb6PWZmx83s\n+PLsrZd0FkJsDW05v5nlseb433X3HwGAu0+6e8PdmwC+DeCBUF93P+buY+4+1jPIfwMvhOgsN3V+\nMzMA3wFwyt2/fl376HWbfRbAic0fnhBiq2hntf/3APwZgNfM7OVW25cAfM7MjmJN/jsH4C9utiOD\nI29hCas7x78SlEgJrT39PA/b3QM88o3JYQDo+ABeymulm8uU/3fxILVlyjyybKXAJbE35niuuMli\nWLaLRfXlLkSkykjw21Qf3yeL3ms0uOSV7+XXQK3On1OlEi/1xq6rHTkeRbq7wK+riT5eYu10TySq\nbzUiA5Lxj5a4pFsn8xu7ft9z3Jtt4O6/ABB6x6KavhDi9ka/8BMiUeT8QiSKnF+IRJHzC5Eocn4h\nEqWjCTzLzQJeWSAZJiOML4Xllf4il2sG8ivUFo0gjNwOD3eFI8RqET3sxSyPpqtHovpyJZ7Ac/za\nALVdnBoJtg++xiW2gyeXqW3+Lp7QdGqES30Mr/Nx7Bjm4yju4XJeb4mlC43IsyQpLACcmL+D2s5c\n5mW3ckv84mlGft/W1xu+VodyfD6YpFeIRKzeiJ78QiSKnF+IRJHzC5Eocn4hEkXOL0SiyPmFSJSO\nSn3uhlWSeDAmUWQtLIn15rnEsyfPI6Ji0lzMNlPvCbZfq0ai2yJRbDHsdPhYANB3gffrPx2OYite\n4bJRZo5HsWUOcqkvW+DvGUuuWpnmyTHLkbqGw4N8jEcGrlLbfb2Xg+3jVS6XxiIgm8tcIsxFVLZ6\nH0+s2V0Iy5HsegN4VB/zrxB68guRKHJ+IRJFzi9Eosj5hUgUOb8QiSLnFyJROir1ZaxJEyrGovBm\nqlxuYpQjYVRTq33UFqvTNrUS7jexwBM3Ni9yuab/LJcB+8/yqL58mUe4LY+G5bKZe4don6HX+Rhj\nuPPx7xuaC7bPd0cSZ/YsUVvO2q9Bdz3nKjuD7ZdXeCLOao27hZUidR77+Xx4pF9Xnr/XW4me/EIk\nipxfiESR8wuRKHJ+IRJFzi9Eotx0td/MSgCeA1Bsbf9/3P3LZjYE4PsADmKtXNcj7s7rYGEtQIet\n6sdKJM11hVfgF1b5yvzri6PUdnaBr3wvlHnpqko5rCDkzvE+e17jefoK83yVt5nn9+WZD/LjzXyE\nrCpn+Gp57zi/DIqzXFloLPIgl/4D4fd5tHue9slHVvRPL/DceZUGH/+uQlhB6M9z1WG9xFb0Y4/Z\n+Ur4/XxjgZdly5FAuNVm+wJeO0/+KoA/cPePYK0c98Nm9iCAxwE84+5HADzT+lsI8T7hps7va7xz\n+8y3/jmATwN4stX+JIDPbMkIhRBbQlvf+c0s26rQOwXgZ+7+AoA97j7R2uQKAP4ZRQhx29GW87t7\nw92PAtgH4AEz+9ANdsfap4H3YGaPmdlxMzu+Mrv537OEEOvjllb73X0OwLMAHgYwaWajAND6f4r0\nOebuY+4+1jXIF6qEEJ3lps5vZrvMbKD1ugvAHwL4DYCnADza2uxRAD/ZqkEKITafdnSBUQBPmlkW\nazeLH7j7P5rZ8wB+YGafB3AewCM325HBaZmh7kw44AfgQT8xaShWjmluiQcKxXLMdRFJbOh1LvHk\nl7jt6lEefLR8iEts2T7+9am7FJ7H+m948FFhns99jFiQy53dM8H2pQbP03d+iUuwVxd58NGuPp6f\nkOVkvLA8SPvMz/Prw1cjz8tmJF9jJC7p6mQ4yGhmjucSLJL3uVJvX+q76Zbu/iqAjwbapwF8su0j\nCSFuK/QLPyESRc4vRKLI+YVIFDm/EIki5xciUWztx3kdOpjZVazJggAwDOBaxw7O0Tjejcbxbt5v\n47jT3Xe1s8OOOv+7Dmx23N3HtuXgGofGoXHoY78QqSLnFyJRttP5j23jsa9H43g3Gse7+a0dx7Z9\n5xdCbC/62C9EomyL85vZw2b2hpm9bWbblvvPzM6Z2Wtm9rKZHe/gcZ8wsykzO3Fd25CZ/czM3mr9\nz8POtnYcXzGz8dacvGxmn+rAOPab2bNm9rqZnTSz/9xq7+icRMbR0Tkxs5KZ/dLMXmmN47+22jd3\nPty9o/8AZAGcBnAYQAHAKwDu7fQ4WmM5B2B4G477MQD3AzhxXdt/B/B46/XjAP7bNo3jKwD+S4fn\nYxTA/a3XfQDeBHBvp+ckMo6OzgkAA9Dbep0H8AKABzd7Prbjyf8AgLfd/Yy7rwL4B6wlA00Gd38O\nwI0B7x1PiErG0XHcfcLdf9V6vQjgFIC96PCcRMbRUXyNLU+aux3OvxfAxev+voRtmOAWDuBpM3vJ\nzB7bpjG8w+2UEPULZvZq62vBln/9uB4zO4i1/BHbmiT2hnEAHZ6TTiTNTX3B7yFfS0z6HwD8pZl9\nbLsHBMQTonaAb2HtK9lRABMAvtapA5tZL4AfAviiuy9cb+vknATG0fE58Q0kzW2X7XD+cQD7r/t7\nX6ut47j7eOv/KQA/xtpXku2irYSoW427T7YuvCaAb6NDc2Jmeaw53Hfd/Uet5o7PSWgc2zUnrWPf\nctLcdtkO538RwBEzO2RmBQB/irVkoB3FzHrMrO+d1wD+CMCJeK8t5bZIiPrOxdXis+jAnJiZAfgO\ngFPu/vXrTB2dEzaOTs9Jx5LmdmoF84bVzE9hbSX1NIC/3qYxHMaa0vAKgJOdHAeA72Ht42MNa2se\nnwewE2tlz94C8DSAoW0ax/8G8BqAV1sX22gHxvEQ1j7Cvgrg5da/T3V6TiLj6OicAPh3AH7dOt4J\nAH/Tat/U+dAv/IRIlNQX/IRIFjm/EIki5xciUeT8QiSKnF+IRJHzC5Eocn4hEkXOL0Si/D8WYB/7\n3odHqQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f6794bd828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52616\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f67954a710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6664\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f6795cf978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50795\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f6796368d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_images = X_train.shape[0]\n",
    "image_in_each_matrix = X_train.shape[1]\n",
    "print(image_in_each_matrix)\n",
    "\n",
    "for i in range(1,6):\n",
    "    \n",
    "    first = randint(0, total_images - 1)\n",
    "    second = randint(0, image_in_each_matrix)\n",
    "    print(first)\n",
    "    A = X_train[first][second]\n",
    "    figure(1)\n",
    "    imshow(A, interpolation='nearest')\n",
    "    show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "16167\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f67a6732b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8024\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfiES5f8ABJs90Di2HZ4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f67a6fb710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4509\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f6795b5b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5166\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nitT/A+aAPOtAYqOYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f6794bdfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15901\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKPiFSJT/A7UrNYEbXzM0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f679650630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_images = X_test.shape[0]\n",
    "image_in_each_matrix = X_test.shape[1]\n",
    "print(image_in_each_matrix)\n",
    "\n",
    "for i in range(1,6):\n",
    "    \n",
    "    first = randint(0, total_images - 1)\n",
    "    second = randint(0, image_in_each_matrix)\n",
    "    print(first)\n",
    "    A = X_test[first][second]\n",
    "    figure(1)\n",
    "    imshow(A, interpolation='nearest')\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Se aprecia un dataset totalmente desvalanciado, lo cual es esperable, pues los primeros números son más utilizados que los últimos si se sigue una secuencia, pues son los que aparecen primero. Y ya que el dataset fue obtenido desde el \"mundo real\" se esperaría esta distribución.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> b) Normalice las imágenes, dividiendo las intensidades originales de pixel por 255. Represente adecuadamente\n",
    "la salida deseada de la red de modo de tener un vector de tamaño igual al número de clases </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>C) Defina una CNN con arquitectura C ×P ×C ×P ×F ×F. Para la primera capa convolucional utilice 16\n",
    "filtros de 5×5 y para la segunda 512 filtros de 7×7. Para la capa MLP escondida use 20 neuronas. Esta\n",
    "arquitectura, con algunas diferencias, fue una de las primera CNNs entrenadas sobre SVHN y consigui´o\n",
    "una accuracy de 94.28% [11]. Genere un esquema lo m´as compacto posible que muestre los cambios\n",
    "de forma que experimenta un patr´on de entrada a medida que se ejecuta un forward-pass. Entrene la\n",
    "red anterior un m´aximo de 10 epochs. ¿Logra mejorar o al menos igualar el resultado reportado en la\n",
    "literatura?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (5, 5), activation=\"relu\", input_shape=(3, 32, 32..., padding=\"same\")`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (7, 7), activation=\"relu\", padding=\"same\")`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 32, 32)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 512, 16, 16)       401920    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 512, 8, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                655380    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 1,058,726\n",
      "Trainable params: 1,058,726\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73257 samples, validate on 26032 samples\n",
      "Epoch 1/8\n",
      "73257/73257 [==============================] - 153s - loss: 0.3903 - acc: 0.9025 - val_loss: 0.2331 - val_acc: 0.9166\n",
      "Epoch 2/8\n",
      "73257/73257 [==============================] - 147s - loss: 0.1667 - acc: 0.9396 - val_loss: 0.1648 - val_acc: 0.9415\n",
      "Epoch 3/8\n",
      "73257/73257 [==============================] - 147s - loss: 0.1091 - acc: 0.9621 - val_loss: 0.1065 - val_acc: 0.9639\n",
      "Epoch 4/8\n",
      "73257/73257 [==============================] - 147s - loss: 0.0881 - acc: 0.9703 - val_loss: 0.0987 - val_acc: 0.9673\n",
      "Epoch 5/8\n",
      "73257/73257 [==============================] - 147s - loss: 0.0785 - acc: 0.9740 - val_loss: 0.1008 - val_acc: 0.9666\n",
      "Epoch 6/8\n",
      "73257/73257 [==============================] - 147s - loss: 0.0722 - acc: 0.9762 - val_loss: 0.0828 - val_acc: 0.9732\n",
      "Epoch 7/8\n",
      "73257/73257 [==============================] - 147s - loss: 0.0676 - acc: 0.9779 - val_loss: 0.0869 - val_acc: 0.9714\n",
      "Epoch 8/8\n",
      "73257/73257 [==============================] - 147s - loss: 0.0639 - acc: 0.9793 - val_loss: 0.0770 - val_acc: 0.9753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x133717fd4e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(16, 5, 5, border_mode='same', activation='relu', input_shape=(3, 32, 32)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(512, 7, 7, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer='adagrad', metrics=['accuracy'])\n",
    "adagrad = Adagrad(lr=0.01, epsilon=1e-08, decay=0.0)\n",
    "model.fit(X_train, Y_train, batch_size=400, nb_epoch=8, verbose=1, \\\n",
    "            validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (5, 5), input_shape=(3, 32, 32..., padding=\"same\", activation=\"relu\")`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (7, 7), padding=\"same\", activation=\"relu\")`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 16, 32, 32)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 512, 16, 16)       401920    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 512, 8, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                655380    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 1,058,726\n",
      "Trainable params: 1,058,726\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73257 samples, validate on 26032 samples\n",
      "Epoch 1/8\n",
      "73257/73257 [==============================] - 156s - loss: 2.6088 - acc: 0.1881 - val_loss: 2.2233 - val_acc: 0.1959\n",
      "Epoch 2/8\n",
      "73257/73257 [==============================] - 151s - loss: 2.2335 - acc: 0.1892 - val_loss: 2.2243 - val_acc: 0.1959\n",
      "Epoch 3/8\n",
      "73257/73257 [==============================] - 151s - loss: 2.0653 - acc: 0.2564 - val_loss: 1.7573 - val_acc: 0.3928\n",
      "Epoch 4/8\n",
      "73257/73257 [==============================] - 175s - loss: 1.5004 - acc: 0.4957 - val_loss: 1.3719 - val_acc: 0.5558\n",
      "Epoch 5/8\n",
      "73257/73257 [==============================] - 367s - loss: 1.0932 - acc: 0.6485 - val_loss: 1.1354 - val_acc: 0.6460\n",
      "Epoch 6/8\n",
      "73257/73257 [==============================] - 381s - loss: 0.8277 - acc: 0.7505 - val_loss: 1.0129 - val_acc: 0.6911\n",
      "Epoch 7/8\n",
      "73257/73257 [==============================] - 367s - loss: 0.6954 - acc: 0.7988 - val_loss: 0.7626 - val_acc: 0.7824\n",
      "Epoch 8/8\n",
      "73257/73257 [==============================] - 388s - loss: 0.6167 - acc: 0.8251 - val_loss: 0.7101 - val_acc: 0.8011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x221f315b9e8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(16, 5, 5, border_mode='same', activation='relu', input_shape=(3, 32, 32)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(512, 7, 7, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adagrad', metrics=['accuracy'])\n",
    "adagrad = Adagrad(lr=0.01, epsilon=1e-08, decay=0.0)\n",
    "model.fit(X_train, Y_train, batch_size=400, nb_epoch=8, verbose=1, \\\n",
    "            validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>El primer cuadro utiliza binary crossentropy como funsión de perdida, lo cual es incorrecto, debido a que se busca clasificar imágenes, y existen 9 clases posibles, por lo cual un binary crossentropy no logra representar el dominio del problema y los errores obtenidos son completamente erroneos. </p>\n",
    "<p>En el segundo bloque se tiene con categorycal crossentropy el cual soporta n variables independientes, en este caso 9. Al usar la arquitectura mencionada, no se logra superar el valor mencionado en la bibliografía.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>D) Evalúe el efecto de modifícar el tamaño de los fíltros (de convoluciónn y pooling) reportando la\n",
    "sensibilidad del error de pruebas a estos cambios. Presente un gráfíco o tabla resumen. Por simplicidad\n",
    "entre durante sólo 10 epochs.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (10, 10), activation=\"relu\", padding=\"same\", input_shape=(3, 32, 32...)`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (15, 15), activation=\"relu\", padding=\"same\")`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 32, 32)        4816      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 6, 6)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 512, 6, 6)         1843712   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 512, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                10260     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 1,858,998\n",
      "Trainable params: 1,858,998\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73257 samples, validate on 26032 samples\n",
      "Epoch 1/10\n",
      "73257/73257 [==============================] - 74s - loss: 2.2591 - acc: 0.1834 - val_loss: 2.1017 - val_acc: 0.2357\n",
      "Epoch 2/10\n",
      "73257/73257 [==============================] - 64s - loss: 1.9380 - acc: 0.3240 - val_loss: 1.8671 - val_acc: 0.3516\n",
      "Epoch 3/10\n",
      "73257/73257 [==============================] - 64s - loss: 1.4875 - acc: 0.5244 - val_loss: 1.2936 - val_acc: 0.6082\n",
      "Epoch 4/10\n",
      "73257/73257 [==============================] - 64s - loss: 1.1011 - acc: 0.6615 - val_loss: 1.1310 - val_acc: 0.6209\n",
      "Epoch 5/10\n",
      "73257/73257 [==============================] - 64s - loss: 0.9450 - acc: 0.7149 - val_loss: 0.9479 - val_acc: 0.7078\n",
      "Epoch 6/10\n",
      "73257/73257 [==============================] - 64s - loss: 0.8382 - acc: 0.7510 - val_loss: 0.8286 - val_acc: 0.7592\n",
      "Epoch 7/10\n",
      "73257/73257 [==============================] - 64s - loss: 0.7566 - acc: 0.7769 - val_loss: 0.8444 - val_acc: 0.7434\n",
      "Epoch 8/10\n",
      "73257/73257 [==============================] - 64s - loss: 0.6900 - acc: 0.7989 - val_loss: 0.7445 - val_acc: 0.7797\n",
      "Epoch 9/10\n",
      "73257/73257 [==============================] - 64s - loss: 0.6306 - acc: 0.8177 - val_loss: 0.6978 - val_acc: 0.8045\n",
      "Epoch 10/10\n",
      "73257/73257 [==============================] - 64s - loss: 0.5834 - acc: 0.8328 - val_loss: 0.8322 - val_acc: 0.7406\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22ff9f3b748>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(16, 10, 10, border_mode='same', activation='relu', input_shape=(3, 32, 32)))\n",
    "model.add(MaxPooling2D(pool_size=(5, 5)))\n",
    "model.add(Convolution2D(512, 15, 15, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(5, 5)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adagrad', metrics=['accuracy'])\n",
    "adagrad = Adagrad(lr=0.01, epsilon=1e-08, decay=0.0)\n",
    "model.fit(X_train, Y_train, batch_size=400, nb_epoch=10, verbose=1, \\\n",
    "            validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (3, 3), activation=\"relu\", padding=\"same\", input_shape=(3, 32, 32...)`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (1, 1), activation=\"relu\", padding=\"same\")`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 32, 32)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 6, 6)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 512, 6, 6)         8704      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 512, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                10260     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 19,622\n",
      "Trainable params: 19,622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73257 samples, validate on 26032 samples\n",
      "Epoch 1/10\n",
      "73257/73257 [==============================] - 24s - loss: 2.2373 - acc: 0.1885 - val_loss: 2.2194 - val_acc: 0.1959\n",
      "Epoch 2/10\n",
      "73257/73257 [==============================] - 22s - loss: 2.2210 - acc: 0.1899 - val_loss: 2.1929 - val_acc: 0.1974\n",
      "Epoch 3/10\n",
      "73257/73257 [==============================] - 22s - loss: 2.1863 - acc: 0.2082 - val_loss: 2.1564 - val_acc: 0.2503\n",
      "Epoch 4/10\n",
      "73257/73257 [==============================] - 22s - loss: 2.1509 - acc: 0.2289 - val_loss: 2.1334 - val_acc: 0.2751\n",
      "Epoch 5/10\n",
      "73257/73257 [==============================] - 22s - loss: 2.1190 - acc: 0.2432 - val_loss: 2.1164 - val_acc: 0.2360\n",
      "Epoch 6/10\n",
      "73257/73257 [==============================] - 22s - loss: 2.0900 - acc: 0.2526 - val_loss: 2.0752 - val_acc: 0.2903\n",
      "Epoch 7/10\n",
      "73257/73257 [==============================] - 22s - loss: 2.0616 - acc: 0.2625 - val_loss: 2.0370 - val_acc: 0.3009\n",
      "Epoch 8/10\n",
      "73257/73257 [==============================] - 22s - loss: 2.0390 - acc: 0.2692 - val_loss: 1.9985 - val_acc: 0.3034\n",
      "Epoch 9/10\n",
      "73257/73257 [==============================] - 22s - loss: 2.0168 - acc: 0.2758 - val_loss: 1.9724 - val_acc: 0.3006\n",
      "Epoch 10/10\n",
      "73257/73257 [==============================] - 22s - loss: 1.9971 - acc: 0.2833 - val_loss: 1.9623 - val_acc: 0.2976\n",
      "Tamaño filtros primera capa convolucional: 3X3\n",
      "Tamaño filtros segunda capa convolucional: 1X1\n",
      "Tamaño filtros primera capa de pooling: 5X5\n",
      "Tamaño filtros segunda capa de pooling: 5X5\n",
      "Acc: 29.7633681623%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 16, 32, 32)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 6, 6)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 512, 6, 6)         33280     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 512, 3, 3)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                92180     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                210       \n",
      "================================================================="
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (2, 2), activation=\"relu\", padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total params: 126,118\n",
      "Trainable params: 126,118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73257 samples, validate on 26032 samples\n",
      "Epoch 1/10\n",
      "73257/73257 [==============================] - 25s - loss: 2.0668 - acc: 0.2578 - val_loss: 1.8970 - val_acc: 0.3303\n",
      "Epoch 2/10\n",
      "73257/73257 [==============================] - 24s - loss: 1.4934 - acc: 0.5082 - val_loss: 1.4258 - val_acc: 0.5241\n",
      "Epoch 3/10\n",
      "73257/73257 [==============================] - 24s - loss: 1.2149 - acc: 0.6170 - val_loss: 1.2734 - val_acc: 0.6134\n",
      "Epoch 4/10\n",
      "73257/73257 [==============================] - 24s - loss: 1.0779 - acc: 0.6675 - val_loss: 1.1060 - val_acc: 0.6548\n",
      "Epoch 5/10\n",
      "73257/73257 [==============================] - 24s - loss: 0.9931 - acc: 0.6969 - val_loss: 1.0898 - val_acc: 0.6595\n",
      "Epoch 6/10\n",
      "73257/73257 [==============================] - 24s - loss: 0.9309 - acc: 0.7177 - val_loss: 0.9806 - val_acc: 0.6953\n",
      "Epoch 7/10\n",
      "73257/73257 [==============================] - 24s - loss: 0.8786 - acc: 0.7363 - val_loss: 0.9225 - val_acc: 0.7301\n",
      "Epoch 8/10\n",
      "73257/73257 [==============================] - 24s - loss: 0.8267 - acc: 0.7542 - val_loss: 0.8826 - val_acc: 0.7399\n",
      "Epoch 9/10\n",
      "73257/73257 [==============================] - 24s - loss: 0.7861 - acc: 0.7670 - val_loss: 0.8360 - val_acc: 0.7601\n",
      "Epoch 10/10\n",
      "73257/73257 [==============================] - 24s - loss: 0.7559 - acc: 0.7761 - val_loss: 0.8186 - val_acc: 0.7559\n",
      "Tamaño filtros primera capa convolucional: 3X3\n",
      "Tamaño filtros segunda capa convolucional: 2X2\n",
      "Tamaño filtros primera capa de pooling: 5X5\n",
      "Tamaño filtros segunda capa de pooling: 2X2\n",
      "Acc: 75.5915795943%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 16, 32, 32)        784       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 8, 8)          0         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (4, 4), activation=\"relu\", padding=\"same\", input_shape=(3, 32, 32...)`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (5, 5), activation=\"relu\", padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 512, 8, 8)         205312    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 512, 2, 2)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20)                40980     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 247,286\n",
      "Trainable params: 247,286\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73257 samples, validate on 26032 samples\n",
      "Epoch 1/10\n",
      "73257/73257 [==============================] - 37s - loss: 2.2977 - acc: 0.1440 - val_loss: 2.2589 - val_acc: 0.1594\n",
      "Epoch 2/10\n",
      "73257/73257 [==============================] - 36s - loss: 2.2577 - acc: 0.1499 - val_loss: 2.2457 - val_acc: 0.1959\n",
      "Epoch 3/10\n",
      "73257/73257 [==============================] - 36s - loss: 2.2496 - acc: 0.1892 - val_loss: 2.2386 - val_acc: 0.1959\n",
      "Epoch 4/10\n",
      "73257/73257 [==============================] - 36s - loss: 2.2451 - acc: 0.1892 - val_loss: 2.2343 - val_acc: 0.1959\n",
      "Epoch 5/10\n",
      "73257/73257 [==============================] - 36s - loss: 2.2424 - acc: 0.1892 - val_loss: 2.2314 - val_acc: 0.1959\n",
      "Epoch 6/10\n",
      "73257/73257 [==============================] - 36s - loss: 2.2405 - acc: 0.1892 - val_loss: 2.2295 - val_acc: 0.1959\n",
      "Epoch 7/10\n",
      "73257/73257 [==============================] - 36s - loss: 2.2393 - acc: 0.1892 - val_loss: 2.2281 - val_acc: 0.1959\n",
      "Epoch 8/10\n",
      "73257/73257 [==============================] - 36s - loss: 2.2385 - acc: 0.1892 - val_loss: 2.2271 - val_acc: 0.1959\n",
      "Epoch 9/10\n",
      "73257/73257 [==============================] - 36s - loss: 2.2379 - acc: 0.1892 - val_loss: 2.2264 - val_acc: 0.1959\n",
      "Epoch 10/10\n",
      "73257/73257 [==============================] - 36s - loss: 2.2375 - acc: 0.1892 - val_loss: 2.2259 - val_acc: 0.1959\n",
      "Tamaño filtros primera capa convolucional: 4X4\n",
      "Tamaño filtros segunda capa convolucional: 5X5\n",
      "Tamaño filtros primera capa de pooling: 4X4\n",
      "Tamaño filtros segunda capa de pooling: 3X3\n",
      "Acc: 19.5874308543%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 16, 32, 32)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 16, 6, 6)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 512, 6, 6)         33280     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 512, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 20)                10260     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 44,198\n",
      "Trainable params: 44,198\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73257 samples, validate on 26032 samples\n",
      "Epoch 1/10\n",
      "73257/73257 [==============================] - 24s - loss: 2.2128 - acc: 0.1914 - val_loss: 2.1588 - val_acc: 0.2829\n",
      "Epoch 2/10\n",
      "73257/73257 [==============================] - 23s - loss: 2.0604 - acc: 0.2550 - val_loss: 1.9321 - val_acc: 0.3284\n",
      "Epoch 3/10\n",
      "73257/73257 [==============================] - 23s - loss: 1.9039 - acc: 0.3083 - val_loss: 1.7981 - val_acc: 0.3466\n",
      "Epoch 4/10\n",
      "73257/73257 [==============================] - 23s - loss: 1.7735 - acc: 0.3731 - val_loss: 1.9891 - val_acc: 0.2956\n",
      "Epoch 5/10\n",
      "73257/73257 [==============================] - 23s - loss: 1.6860 - acc: 0.4078 - val_loss: 1.6310 - val_acc: 0.4253\n",
      "Epoch 6/10\n",
      "73257/73257 [==============================] - 23s - loss: 1.6124 - acc: 0.4377 - val_loss: 1.6288 - val_acc: 0.4464\n",
      "Epoch 7/10\n",
      "73257/73257 [==============================] - 23s - loss: 1.5663 - acc: 0.4579 - val_loss: 1.5516 - val_acc: 0.4640\n",
      "Epoch 8/10\n",
      "73257/73257 [==============================] - 23s - loss: 1.5174 - acc: 0.4811 - val_loss: 1.5236 - val_acc: 0.4674\n",
      "Epoch 9/10\n",
      "73257/73257 [==============================] - 23s - loss: 1.4802 - acc: 0.4973 - val_loss: 1.4635 - val_acc: 0.5002\n",
      "Epoch 10/10\n",
      "73257/73257 [==============================] - 23s - loss: 1.4401 - acc: 0.5157 - val_loss: 1.6108 - val_acc: 0.4206\n",
      "Tamaño filtros primera capa convolucional: 3X3\n",
      "Tamaño filtros segunda capa convolucional: 2X2\n",
      "Tamaño filtros primera capa de pooling: 5X5\n",
      "Tamaño filtros segunda capa de pooling: 4X4\n",
      "Acc: 42.0559311616%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 16, 32, 32)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 16, 8, 8)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 512, 8, 8)         74240     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 512, 8, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 20)                655380    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 731,046\n",
      "Trainable params: 731,046\n",
      "Non-trainable params: 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (5, 5), activation=\"relu\", padding=\"same\", input_shape=(3, 32, 32...)`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\", padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "_________________________________________________________________\n",
      "Train on 73257 samples, validate on 26032 samples\n",
      "Epoch 1/10\n",
      "73257/73257 [==============================] - 41s - loss: 2.1145 - acc: 0.2564 - val_loss: 1.7168 - val_acc: 0.4094\n",
      "Epoch 2/10\n",
      "73257/73257 [==============================] - -14358s - loss: 1.4235 - acc: 0.5122 - val_loss: 1.3970 - val_acc: 0.5404\n",
      "Epoch 3/10\n",
      "73257/73257 [==============================] - 41s - loss: 1.1298 - acc: 0.6322 - val_loss: 1.1561 - val_acc: 0.6333\n",
      "Epoch 4/10\n",
      "73257/73257 [==============================] - 41s - loss: 0.9970 - acc: 0.6832 - val_loss: 1.0280 - val_acc: 0.6802\n",
      "Epoch 5/10\n",
      "73257/73257 [==============================] - 41s - loss: 0.9080 - acc: 0.7170 - val_loss: 0.9760 - val_acc: 0.7019\n",
      "Epoch 6/10\n",
      "73257/73257 [==============================] - 41s - loss: 0.8381 - acc: 0.7409 - val_loss: 0.9547 - val_acc: 0.7119\n",
      "Epoch 7/10\n",
      "73257/73257 [==============================] - 41s - loss: 0.7886 - acc: 0.7583 - val_loss: 0.9062 - val_acc: 0.7381\n",
      "Epoch 8/10\n",
      "73257/73257 [==============================] - 40s - loss: 0.7440 - acc: 0.7735 - val_loss: 0.9195 - val_acc: 0.7316\n",
      "Epoch 9/10\n",
      "73257/73257 [==============================] - 41s - loss: 0.7111 - acc: 0.7845 - val_loss: 0.8634 - val_acc: 0.7450\n",
      "Epoch 10/10\n",
      "73257/73257 [==============================] - 41s - loss: 0.6833 - acc: 0.7939 - val_loss: 0.7503 - val_acc: 0.7806\n",
      "Tamaño filtros primera capa convolucional: 5X5\n",
      "Tamaño filtros segunda capa convolucional: 3X3\n",
      "Tamaño filtros primera capa de pooling: 4X4\n",
      "Tamaño filtros segunda capa de pooling: 1X1\n",
      "Acc: 78.0577750461%\n"
     ]
    }
   ],
   "source": [
    "array = []\n",
    "for i in range(0,5):\n",
    "    first_max_pool_fil_size = randint(1,6)\n",
    "    second_max_pool_fil_size = randint(1,6)\n",
    "    first_convolution_filter_size = randint(1,6)\n",
    "    second_convolution_filter_size = randint(1,6)\n",
    "   \n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(16, first_convolution_filter_size, first_convolution_filter_size, border_mode='same', activation='relu', input_shape=(3, 32, 32)))\n",
    "    model.add(MaxPooling2D(pool_size=(first_max_pool_fil_size, first_max_pool_fil_size)))\n",
    "    model.add(Convolution2D(512, second_convolution_filter_size, second_convolution_filter_size, border_mode='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(second_max_pool_fil_size, second_max_pool_fil_size)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adagrad', metrics=['accuracy'])\n",
    "    adagrad = Adagrad(lr=0.01, epsilon=1e-08, decay=0.0)\n",
    "    model.fit(X_train, Y_train, batch_size=400, nb_epoch=10, verbose=1, \\\n",
    "                validation_data=(X_test, Y_test))\n",
    "    scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print(\"Tamaño filtros primera capa convolucional: \" + str(first_convolution_filter_size) + 'X' + str(first_convolution_filter_size) )\n",
    "    print(\"Tamaño filtros segunda capa convolucional: \" + str(second_convolution_filter_size) + 'X' + str(second_convolution_filter_size) )\n",
    "    print(\"Tamaño filtros primera capa de pooling: \" + str(first_max_pool_fil_size) + 'X' + str(first_max_pool_fil_size) )\n",
    "    print(\"Tamaño filtros segunda capa de pooling: \" + str(second_max_pool_fil_size) + 'X' + str(second_max_pool_fil_size) ) \n",
    "    print(\"Acc: \" + str(scores[1] * 100) + \"%\")\n",
    "    array.append([scores[1],first_max_pool_fil_size ,second_max_pool_fil_size, first_convolution_filter_size, second_convolution_filter_size] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (1, 1), activation=\"relu\", padding=\"same\", input_shape=(3, 32, 32...)`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (4, 4), activation=\"relu\", padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 32, 32)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 8, 8)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 512, 8, 8)         131584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 512, 2, 2)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                40980     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 172,838\n",
      "Trainable params: 172,838\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 73257 samples, validate on 26032 samples\n",
      "Epoch 1/10\n",
      "73257/73257 [==============================] - 44s - loss: 2.3025 - acc: 0.1430 - val_loss: 2.2570 - val_acc: 0.1594\n",
      "Epoch 2/10\n",
      "73257/73257 [==============================] - 41s - loss: 2.2507 - acc: 0.1514 - val_loss: 2.2450 - val_acc: 0.2308\n",
      "Epoch 3/10\n",
      "73257/73257 [==============================] - 41s - loss: 2.2281 - acc: 0.1920 - val_loss: 2.2255 - val_acc: 0.1801\n",
      "Epoch 4/10\n",
      "73257/73257 [==============================] - 41s - loss: 2.1914 - acc: 0.2265 - val_loss: 2.1522 - val_acc: 0.2625\n",
      "Epoch 5/10\n",
      "73257/73257 [==============================] - 41s - loss: 2.1415 - acc: 0.2600 - val_loss: 2.1247 - val_acc: 0.2534\n",
      "Epoch 6/10\n",
      "73257/73257 [==============================] - 41s - loss: 2.0490 - acc: 0.2896 - val_loss: 1.9602 - val_acc: 0.3389\n",
      "Epoch 7/10\n",
      "73257/73257 [==============================] - 41s - loss: 1.9280 - acc: 0.3307 - val_loss: 1.8630 - val_acc: 0.3885\n",
      "Epoch 8/10\n",
      "73257/73257 [==============================] - 41s - loss: 1.8242 - acc: 0.3769 - val_loss: 1.7458 - val_acc: 0.4063\n",
      "Epoch 9/10\n",
      "73257/73257 [==============================] - 41s - loss: 1.7411 - acc: 0.4145 - val_loss: 1.7372 - val_acc: 0.3947\n",
      "Epoch 10/10\n",
      "73257/73257 [==============================] - 42s - loss: 1.6664 - acc: 0.4467 - val_loss: 1.5900 - val_acc: 0.4784\n",
      "Tamaño filtros primera capa convolucional: 1X1\n",
      "Tamaño filtros segunda capa convolucional: 4X4\n",
      "Tamaño filtros primera capa de pooling: 4X4\n",
      "Tamaño filtros segunda capa de pooling: 4X4\n",
      "Acc: 47.8411186232%\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-b072bd800a51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Tamaño filtros segunda capa de pooling: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msecond_max_pool_fil_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'X'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msecond_max_pool_fil_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Acc: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"%\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfirst_max_pool_fil_size\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0msecond_max_pool_fil_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_convolution_filter_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecond_convolution_filter_size\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "first_max_pool_fil_size = randint(1,6)\n",
    "second_max_pool_fil_size = first_max_pool_fil_size\n",
    "first_convolution_filter_size = randint(1,6)\n",
    "second_convolution_filter_size = randint(1,6)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(16, first_convolution_filter_size, first_convolution_filter_size, border_mode='same', activation='relu', input_shape=(3, 32, 32)))\n",
    "model.add(MaxPooling2D(pool_size=(first_max_pool_fil_size, first_max_pool_fil_size)))\n",
    "model.add(Convolution2D(512, second_convolution_filter_size, second_convolution_filter_size, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(second_max_pool_fil_size, second_max_pool_fil_size)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adagrad', metrics=['accuracy'])\n",
    "adagrad = Adagrad(lr=0.01, epsilon=1e-08, decay=0.0)\n",
    "model.fit(X_train, Y_train, batch_size=400, nb_epoch=10, verbose=1, \\\n",
    "            validation_data=(X_test, Y_test))\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Tamaño filtros primera capa convolucional: \" + str(first_convolution_filter_size) + 'X' + str(first_convolution_filter_size) )\n",
    "print(\"Tamaño filtros segunda capa convolucional: \" + str(second_convolution_filter_size) + 'X' + str(second_convolution_filter_size) )\n",
    "print(\"Tamaño filtros primera capa de pooling: \" + str(first_max_pool_fil_size) + 'X' + str(first_max_pool_fil_size) )\n",
    "print(\"Tamaño filtros segunda capa de pooling: \" + str(second_max_pool_fil_size) + 'X' + str(second_max_pool_fil_size) ) \n",
    "print(\"Acc: \" + str(scores[1] * 100) + \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Se modificaron los valores utilizando funciones random para determinar los tamaños, todas las modificaciones hechas (se limitaron por la cantidad de tiempo y memoria)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<p>Evalúe el efecto de modiíficar el número de fíltros para las capas convolucionales tanto en los tiempos\n",
    "de entrenamiento como en el desempeño de la red. Presente un gráfico o tabla resumen. Por simplicidad\n",
    "entre durante sólo 10 epochs.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(749, (5, 5), input_shape=(3, 32, 32..., padding=\"same\", activation=\"relu\")`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(372, (7, 7), padding=\"same\", activation=\"relu\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 749, 32, 32)       56924     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 749, 6, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 372, 6, 6)         13653144  \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 372, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 372)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                7460      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 13,717,738\n",
      "Trainable params: 13,717,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 73257 samples, validate on 26032 samples\n",
      "Epoch 1/10\n",
      "73257/73257 [==============================] - 600s - loss: 13.0440 - acc: 0.1890 - val_loss: 12.9610 - val_acc: 0.1959\n",
      "Epoch 2/10\n",
      "73257/73257 [==============================] - 589s - loss: 13.0684 - acc: 0.1892 - val_loss: 12.9610 - val_acc: 0.1959\n",
      "Epoch 3/10\n",
      "73257/73257 [==============================] - 589s - loss: 13.0684 - acc: 0.1892 - val_loss: 12.9610 - val_acc: 0.1959\n",
      "Epoch 4/10\n",
      "73257/73257 [==============================] - 590s - loss: 13.0684 - acc: 0.1892 - val_loss: 12.9610 - val_acc: 0.1959\n",
      "Epoch 5/10\n",
      "73257/73257 [==============================] - 589s - loss: 13.0684 - acc: 0.1892 - val_loss: 12.9610 - val_acc: 0.1959\n",
      "Epoch 6/10\n",
      "73257/73257 [==============================] - 589s - loss: 13.0684 - acc: 0.1892 - val_loss: 12.9610 - val_acc: 0.1959\n",
      "Epoch 7/10\n",
      "66750/73257 [==========================>...] - ETA: 46s - loss: 13.0749 - acc: 0.1888"
     ]
    }
   ],
   "source": [
    "array = []\n",
    "for i in range(0,4):\n",
    "    first_layer_filter_quantity = randint(1,1024)\n",
    "    second_layer_filter_quantity = randint(1,1024)\n",
    "\n",
    "   \n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(first_layer_filter_quantity, 5, 5, border_mode='same', activation='relu', input_shape=(3, 32, 32)))\n",
    "    model.add(MaxPooling2D(pool_size=(5, 5)))\n",
    "    model.add(Convolution2D(second_layer_filter_quantity, 7, 7, border_mode='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(5, 5)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adagrad', metrics=['accuracy'])\n",
    "    adagrad = Adagrad(lr=0.01, epsilon=1e-08, decay=0.0)\n",
    "    model.fit(X_train, Y_train, batch_size=150, nb_epoch=10, verbose=1, \\\n",
    "                validation_data=(X_test, Y_test))\n",
    "    scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print(\"Cantidad filtros primera capa convolucional: \" + str(first_convolution_filter_size) + 'X' + str(first_convolution_filter_size) )\n",
    "    print(\"Cantidad filtros segunda capa convolucional: \" + str(second_convolution_filter_size) + 'X' + str(second_convolution_filter_size) )\n",
    "    print(\"Acc: \" + str(scores[1] * 100) + \"%\")\n",
    "    array.append([scores[1],first_max_pool_fil_size ,second_max_pool_fil_size, first_convolution_filter_size, second_convolution_filter_size] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Proponga una mejora sobre la red de\f",
    "nida en (c) que mejore el error de pruebas. Recuerde que debe\n",
    "de\f",
    "nir un subconjunto de validaci\u0013on si necesita elegir entre arquitecturas.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (5, 5), activation=\"relu\", input_shape=(3, 32, 32..., padding=\"same\")`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (7, 7), activation=\"relu\", padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 32, 32)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 6, 6)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 512, 6, 6)         401920    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 512, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                10260     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 413,606\n",
      "Trainable params: 413,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9333 samples, validate on 667 samples\n",
      "Epoch 1/10\n",
      "9333/9333 [==============================] - 6s - loss: 2.3371 - acc: 0.1367 - val_loss: 2.2526 - val_acc: 0.1439\n",
      "Epoch 2/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.2377 - acc: 0.1472 - val_loss: 2.2199 - val_acc: 0.1784\n",
      "Epoch 3/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.1975 - acc: 0.2153 - val_loss: 2.1844 - val_acc: 0.2624\n",
      "Epoch 4/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.1537 - acc: 0.2494 - val_loss: 2.1522 - val_acc: 0.2594\n",
      "Epoch 5/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.0881 - acc: 0.2827 - val_loss: 2.0545 - val_acc: 0.2759\n",
      "Epoch 6/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.9700 - acc: 0.3191 - val_loss: 1.9627 - val_acc: 0.3163\n",
      "Epoch 7/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.8542 - acc: 0.3434 - val_loss: 1.8374 - val_acc: 0.3343\n",
      "Epoch 8/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.7010 - acc: 0.3792 - val_loss: 1.7417 - val_acc: 0.4018\n",
      "Epoch 9/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.5487 - acc: 0.4609 - val_loss: 1.5234 - val_acc: 0.5097\n",
      "Epoch 10/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.4110 - acc: 0.5396 - val_loss: 1.4478 - val_acc: 0.5142\n",
      "Acc: 51.4242878382%\n",
      "acc: 51.42%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 16, 32, 32)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 6, 6)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 512, 6, 6)         401920    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 512, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                10260     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 413,606\n",
      "Trainable params: 413,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9333 samples, validate on 667 samples\n",
      "Epoch 1/10\n",
      "9333/9333 [==============================] - 4s - loss: 2.3211 - acc: 0.1393 - val_loss: 2.2567 - val_acc: 0.1469\n",
      "Epoch 2/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.2295 - acc: 0.1572 - val_loss: 2.2171 - val_acc: 0.1514\n",
      "Epoch 3/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.1631 - acc: 0.1810 - val_loss: 2.1474 - val_acc: 0.2009\n",
      "Epoch 4/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.0860 - acc: 0.2257 - val_loss: 2.0555 - val_acc: 0.2399\n",
      "Epoch 5/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.0053 - acc: 0.2783 - val_loss: 2.0089 - val_acc: 0.3223\n",
      "Epoch 6/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.8809 - acc: 0.3550 - val_loss: 1.8120 - val_acc: 0.3463\n",
      "Epoch 7/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.7243 - acc: 0.4134 - val_loss: 1.6465 - val_acc: 0.4573\n",
      "Epoch 8/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.5832 - acc: 0.4690 - val_loss: 1.5312 - val_acc: 0.4933\n",
      "Epoch 9/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.4426 - acc: 0.5349 - val_loss: 1.4074 - val_acc: 0.5307\n",
      "Epoch 10/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.3459 - acc: 0.5634 - val_loss: 1.3084 - val_acc: 0.5652\n",
      "Acc: 56.5217390589%\n",
      "acc: 56.52%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 16, 32, 32)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 6, 6)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 512, 6, 6)         401920    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 512, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20)                10260     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 413,606\n",
      "Trainable params: 413,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9333 samples, validate on 667 samples\n",
      "Epoch 1/10\n",
      "9333/9333 [==============================] - 4s - loss: 2.3713 - acc: 0.1919 - val_loss: 2.2149 - val_acc: 0.2534\n",
      "Epoch 2/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.1689 - acc: 0.2401 - val_loss: 2.1668 - val_acc: 0.1994\n",
      "Epoch 3/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.0885 - acc: 0.2682 - val_loss: 2.0682 - val_acc: 0.2879\n",
      "Epoch 4/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.9967 - acc: 0.3124 - val_loss: 1.9245 - val_acc: 0.3343\n",
      "Epoch 5/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.8987 - acc: 0.3504 - val_loss: 1.8230 - val_acc: 0.3868\n",
      "Epoch 6/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.8068 - acc: 0.3757 - val_loss: 1.7480 - val_acc: 0.4078\n",
      "Epoch 7/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.7156 - acc: 0.4071 - val_loss: 1.6392 - val_acc: 0.4213\n",
      "Epoch 8/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.6026 - acc: 0.4617 - val_loss: 1.7136 - val_acc: 0.3748\n",
      "Epoch 9/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.5225 - acc: 0.4951 - val_loss: 1.4725 - val_acc: 0.5127\n",
      "Epoch 10/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.4406 - acc: 0.5320 - val_loss: 1.4192 - val_acc: 0.5517\n",
      "Acc: 55.1724138378%\n",
      "acc: 55.17%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 16, 32, 32)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 16, 6, 6)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 512, 6, 6)         401920    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 512, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 20)                10260     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 413,606\n",
      "Trainable params: 413,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9333 samples, validate on 667 samples\n",
      "Epoch 1/10\n",
      "9333/9333 [==============================] - 4s - loss: 2.3314 - acc: 0.1791 - val_loss: 2.2340 - val_acc: 0.2009\n",
      "Epoch 2/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.2385 - acc: 0.1945 - val_loss: 2.2207 - val_acc: 0.2009\n",
      "Epoch 3/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.2285 - acc: 0.1948 - val_loss: 2.2169 - val_acc: 0.2009\n",
      "Epoch 4/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.2195 - acc: 0.2008 - val_loss: 2.2069 - val_acc: 0.2084\n",
      "Epoch 5/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.2099 - acc: 0.2053 - val_loss: 2.1890 - val_acc: 0.2054\n",
      "Epoch 6/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.1569 - acc: 0.2440 - val_loss: 2.1156 - val_acc: 0.2909\n",
      "Epoch 7/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.0581 - acc: 0.2802 - val_loss: 2.0265 - val_acc: 0.3148\n",
      "Epoch 8/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.9326 - acc: 0.3182 - val_loss: 1.9379 - val_acc: 0.2894\n",
      "Epoch 9/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.7985 - acc: 0.3727 - val_loss: 1.7298 - val_acc: 0.3823\n",
      "Epoch 10/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.6338 - acc: 0.4491 - val_loss: 1.5876 - val_acc: 0.4768\n",
      "Acc: 47.6761618744%\n",
      "acc: 47.68%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 16, 32, 32)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 16, 6, 6)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 512, 6, 6)         401920    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 512, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 20)                10260     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 413,606\n",
      "Trainable params: 413,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9333 samples, validate on 667 samples\n",
      "Epoch 1/10\n",
      "9333/9333 [==============================] - 4s - loss: 2.3091 - acc: 0.1847 - val_loss: 2.2155 - val_acc: 0.2099\n",
      "Epoch 2/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.1992 - acc: 0.1920 - val_loss: 2.1219 - val_acc: 0.2099\n",
      "Epoch 3/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.1408 - acc: 0.2080 - val_loss: 2.1109 - val_acc: 0.2819\n",
      "Epoch 4/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.0797 - acc: 0.2446 - val_loss: 2.0054 - val_acc: 0.3088\n",
      "Epoch 5/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.0234 - acc: 0.2784 - val_loss: 1.9409 - val_acc: 0.3088\n",
      "Epoch 6/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.9646 - acc: 0.3013 - val_loss: 1.9059 - val_acc: 0.3163\n",
      "Epoch 7/10\n",
      "9333/9333 [==============================] - 4s - loss: 1.9108 - acc: 0.3180 - val_loss: 1.8560 - val_acc: 0.3118\n",
      "Epoch 8/10\n",
      "9333/9333 [==============================] - 4s - loss: 1.8494 - acc: 0.3371 - val_loss: 1.8821 - val_acc: 0.2819\n",
      "Epoch 9/10\n",
      "9333/9333 [==============================] - 4s - loss: 1.7959 - acc: 0.3499 - val_loss: 1.7561 - val_acc: 0.3358\n",
      "Epoch 10/10\n",
      "9333/9333 [==============================] - 4s - loss: 1.7476 - acc: 0.3713 - val_loss: 1.6979 - val_acc: 0.3928\n",
      "Acc: 39.2803599273%\n",
      "acc: 39.28%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 16, 32, 32)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 16, 6, 6)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 512, 6, 6)         401920    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 512, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 20)                10260     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 413,606\n",
      "Trainable params: 413,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9333 samples, validate on 667 samples\n",
      "Epoch 1/10\n",
      "9333/9333 [==============================] - 4s - loss: 2.2967 - acc: 0.1443 - val_loss: 2.2301 - val_acc: 0.1619\n",
      "Epoch 2/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.2183 - acc: 0.1944 - val_loss: 2.1892 - val_acc: 0.1784\n",
      "Epoch 3/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.1682 - acc: 0.2100 - val_loss: 2.1650 - val_acc: 0.1829\n",
      "Epoch 4/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.1153 - acc: 0.2335 - val_loss: 2.0832 - val_acc: 0.2534\n",
      "Epoch 5/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.0522 - acc: 0.2715 - val_loss: 2.0366 - val_acc: 0.2324\n",
      "Epoch 6/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.0027 - acc: 0.3078 - val_loss: 1.9749 - val_acc: 0.2834\n",
      "Epoch 7/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.9397 - acc: 0.3337 - val_loss: 1.9644 - val_acc: 0.2654\n",
      "Epoch 8/10\n",
      "9333/9333 [==============================] - 4s - loss: 1.8880 - acc: 0.3556 - val_loss: 1.9358 - val_acc: 0.3583\n",
      "Epoch 9/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.8185 - acc: 0.3794 - val_loss: 1.8028 - val_acc: 0.3838\n",
      "Epoch 10/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.7556 - acc: 0.4000 - val_loss: 1.8016 - val_acc: 0.3913\n",
      "Acc: 39.1304349167%\n",
      "acc: 39.13%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 16, 32, 32)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 16, 6, 6)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 512, 6, 6)         401920    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 512, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 20)                10260     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 413,606\n",
      "Trainable params: 413,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9333 samples, validate on 667 samples\n",
      "Epoch 1/10\n",
      "9333/9333 [==============================] - 4s - loss: 2.3229 - acc: 0.1411 - val_loss: 2.2723 - val_acc: 0.1139\n",
      "Epoch 2/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.2404 - acc: 0.1479 - val_loss: 2.2385 - val_acc: 0.1199\n",
      "Epoch 3/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.2036 - acc: 0.1811 - val_loss: 2.1988 - val_acc: 0.1874\n",
      "Epoch 4/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.1485 - acc: 0.2342 - val_loss: 2.1216 - val_acc: 0.2159\n",
      "Epoch 5/10\n",
      "9333/9333 [==============================] - 4s - loss: 2.0649 - acc: 0.2682 - val_loss: 2.0767 - val_acc: 0.2624\n",
      "Epoch 6/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.9587 - acc: 0.3137 - val_loss: 1.9237 - val_acc: 0.3103\n",
      "Epoch 7/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.8542 - acc: 0.3507 - val_loss: 1.8630 - val_acc: 0.3238\n",
      "Epoch 8/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.7540 - acc: 0.3845 - val_loss: 1.7729 - val_acc: 0.3478\n",
      "Epoch 9/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.6697 - acc: 0.4116 - val_loss: 1.7360 - val_acc: 0.3808\n",
      "Epoch 10/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.5801 - acc: 0.4638 - val_loss: 1.6018 - val_acc: 0.4333\n",
      "Acc: 43.3283358768%\n",
      "acc: 43.33%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 16, 32, 32)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 16, 6, 6)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 512, 6, 6)         401920    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 512, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 20)                10260     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 413,606\n",
      "Trainable params: 413,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9333 samples, validate on 667 samples\n",
      "Epoch 1/10\n",
      "9333/9333 [==============================] - 4s - loss: 2.3609 - acc: 0.1884 - val_loss: 2.2316 - val_acc: 0.1979\n",
      "Epoch 2/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.2440 - acc: 0.1922 - val_loss: 2.2211 - val_acc: 0.1979\n",
      "Epoch 3/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.2360 - acc: 0.1922 - val_loss: 2.2165 - val_acc: 0.1979\n",
      "Epoch 4/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.2180 - acc: 0.1933 - val_loss: 2.1837 - val_acc: 0.1979\n",
      "Epoch 5/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.1921 - acc: 0.2077 - val_loss: 2.1352 - val_acc: 0.2324\n",
      "Epoch 6/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.1395 - acc: 0.2399 - val_loss: 2.0634 - val_acc: 0.2834\n",
      "Epoch 7/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.0661 - acc: 0.2762 - val_loss: 2.0022 - val_acc: 0.3418\n",
      "Epoch 8/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.9878 - acc: 0.3185 - val_loss: 1.9182 - val_acc: 0.3358\n",
      "Epoch 9/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.9258 - acc: 0.3460 - val_loss: 1.9166 - val_acc: 0.3073\n",
      "Epoch 10/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.8566 - acc: 0.3729 - val_loss: 1.7529 - val_acc: 0.4123\n",
      "Acc: 41.2293852895%\n",
      "acc: 41.23%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 16, 32, 32)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 16, 6, 6)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 512, 6, 6)         401920    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 512, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 20)                10260     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 413,606\n",
      "Trainable params: 413,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9333 samples, validate on 667 samples\n",
      "Epoch 1/10\n",
      "9333/9333 [==============================] - 4s - loss: 2.3481 - acc: 0.1805 - val_loss: 2.2665 - val_acc: 0.1934\n",
      "Epoch 2/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.2606 - acc: 0.1935 - val_loss: 2.2526 - val_acc: 0.1934\n",
      "Epoch 3/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.2446 - acc: 0.1997 - val_loss: 2.2315 - val_acc: 0.2234\n",
      "Epoch 4/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.2113 - acc: 0.2371 - val_loss: 2.1778 - val_acc: 0.2729\n",
      "Epoch 5/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.1424 - acc: 0.2610 - val_loss: 2.1039 - val_acc: 0.2714\n",
      "Epoch 6/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.0717 - acc: 0.2874 - val_loss: 2.0384 - val_acc: 0.2924\n",
      "Epoch 7/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.0206 - acc: 0.2955 - val_loss: 1.9885 - val_acc: 0.3028\n",
      "Epoch 8/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.9700 - acc: 0.3098 - val_loss: 1.9782 - val_acc: 0.2879\n",
      "Epoch 9/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.9292 - acc: 0.3127 - val_loss: 1.9126 - val_acc: 0.3118\n",
      "Epoch 10/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.8851 - acc: 0.3195 - val_loss: 1.8866 - val_acc: 0.3118\n",
      "Acc: 31.1844078095%\n",
      "acc: 31.18%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 16, 32, 32)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 16, 6, 6)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 512, 6, 6)         401920    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 512, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 20)                10260     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 413,606\n",
      "Trainable params: 413,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9333 samples, validate on 667 samples\n",
      "Epoch 1/10\n",
      "9333/9333 [==============================] - 4s - loss: 2.4748 - acc: 0.1421 - val_loss: 2.2505 - val_acc: 0.1409\n",
      "Epoch 2/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.2421 - acc: 0.1438 - val_loss: 2.2269 - val_acc: 0.1469\n",
      "Epoch 3/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.2113 - acc: 0.1628 - val_loss: 2.2031 - val_acc: 0.1874\n",
      "Epoch 4/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.1756 - acc: 0.1960 - val_loss: 2.1578 - val_acc: 0.2114\n",
      "Epoch 5/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.1250 - acc: 0.2219 - val_loss: 2.0896 - val_acc: 0.2519\n",
      "Epoch 6/10\n",
      "9333/9333 [==============================] - 3s - loss: 2.0613 - acc: 0.2528 - val_loss: 2.0551 - val_acc: 0.2639\n",
      "Epoch 7/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.9880 - acc: 0.2735 - val_loss: 2.0051 - val_acc: 0.2879\n",
      "Epoch 8/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.9245 - acc: 0.2920 - val_loss: 1.9247 - val_acc: 0.2984\n",
      "Epoch 9/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.8537 - acc: 0.3158 - val_loss: 1.8795 - val_acc: 0.3163\n",
      "Epoch 10/10\n",
      "9333/9333 [==============================] - 3s - loss: 1.7905 - acc: 0.3477 - val_loss: 1.8006 - val_acc: 0.3313\n",
      "Acc: 33.1334332878%\n",
      "acc: 33.13%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 16, 32, 32)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 16, 6, 6)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 512, 6, 6)         401920    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 512, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 20)                10260     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 413,606\n",
      "Trainable params: 413,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9334 samples, validate on 666 samples\n",
      "Epoch 1/10\n",
      "9334/9334 [==============================] - 4s - loss: 2.2819 - acc: 0.1631 - val_loss: 2.2416 - val_acc: 0.1922\n",
      "Epoch 2/10\n",
      "9334/9334 [==============================] - 3s - loss: 2.2360 - acc: 0.1935 - val_loss: 2.2292 - val_acc: 0.2117\n",
      "Epoch 3/10\n",
      "9334/9334 [==============================] - 3s - loss: 2.2162 - acc: 0.2011 - val_loss: 2.2516 - val_acc: 0.1562\n",
      "Epoch 4/10\n",
      "9334/9334 [==============================] - 3s - loss: 2.1870 - acc: 0.2206 - val_loss: 2.1719 - val_acc: 0.2492\n",
      "Epoch 5/10\n",
      "9334/9334 [==============================] - 3s - loss: 2.1276 - acc: 0.2501 - val_loss: 2.0838 - val_acc: 0.3153\n",
      "Epoch 6/10\n",
      "9334/9334 [==============================] - 3s - loss: 2.0451 - acc: 0.2924 - val_loss: 1.9806 - val_acc: 0.3063\n",
      "Epoch 7/10\n",
      "9334/9334 [==============================] - 3s - loss: 1.9470 - acc: 0.3395 - val_loss: 1.8858 - val_acc: 0.3574\n",
      "Epoch 8/10\n",
      "9334/9334 [==============================] - 3s - loss: 1.8593 - acc: 0.3775 - val_loss: 1.8369 - val_acc: 0.3784\n",
      "Epoch 9/10\n",
      "9334/9334 [==============================] - 3s - loss: 1.7693 - acc: 0.4113 - val_loss: 1.7345 - val_acc: 0.4459\n",
      "Epoch 10/10\n",
      "9334/9334 [==============================] - 3s - loss: 1.6743 - acc: 0.4447 - val_loss: 1.6325 - val_acc: 0.4369\n",
      "Acc: 43.6936938369%\n",
      "acc: 43.69%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_23 (Conv2D)           (None, 16, 32, 32)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 16, 6, 6)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 512, 6, 6)         401920    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 512, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 20)                10260     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 413,606\n",
      "Trainable params: 413,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9334 samples, validate on 666 samples\n",
      "Epoch 1/10\n",
      "9334/9334 [==============================] - 4s - loss: 2.3776 - acc: 0.1405 - val_loss: 2.2596 - val_acc: 0.1351\n",
      "Epoch 2/10\n",
      "9334/9334 [==============================] - 4s - loss: 2.2381 - acc: 0.1451 - val_loss: 2.2527 - val_acc: 0.1396\n",
      "Epoch 3/10\n",
      "9334/9334 [==============================] - 4s - loss: 2.2172 - acc: 0.1526 - val_loss: 2.2129 - val_acc: 0.1486\n",
      "Epoch 4/10\n",
      "9334/9334 [==============================] - 3s - loss: 2.1805 - acc: 0.1695 - val_loss: 2.2022 - val_acc: 0.1967\n",
      "Epoch 5/10\n",
      "9334/9334 [==============================] - 3s - loss: 2.1374 - acc: 0.1988 - val_loss: 2.1392 - val_acc: 0.2072\n",
      "Epoch 6/10\n",
      "9334/9334 [==============================] - 3s - loss: 2.0863 - acc: 0.2337 - val_loss: 2.1199 - val_acc: 0.1907\n",
      "Epoch 7/10\n",
      "9334/9334 [==============================] - 3s - loss: 2.0289 - acc: 0.2525 - val_loss: 2.0147 - val_acc: 0.2688\n",
      "Epoch 8/10\n",
      "9334/9334 [==============================] - 3s - loss: 1.9600 - acc: 0.2738 - val_loss: 1.9634 - val_acc: 0.2898\n",
      "Epoch 9/10\n",
      "9334/9334 [==============================] - 3s - loss: 1.8970 - acc: 0.2998 - val_loss: 1.8853 - val_acc: 0.3108\n",
      "Epoch 10/10\n",
      "9334/9334 [==============================] - 3s - loss: 1.8335 - acc: 0.3306 - val_loss: 1.8621 - val_acc: 0.3288\n",
      "Acc: 32.8828829366%\n",
      "acc: 32.88%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 16, 32, 32)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 16, 6, 6)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 512, 6, 6)         401920    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 512, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 20)                10260     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 413,606\n",
      "Trainable params: 413,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9334 samples, validate on 666 samples\n",
      "Epoch 1/10\n",
      "9334/9334 [==============================] - 4s - loss: 2.4172 - acc: 0.1800 - val_loss: 2.2493 - val_acc: 0.1892\n",
      "Epoch 2/10\n",
      "9334/9334 [==============================] - 3s - loss: 2.2488 - acc: 0.1984 - val_loss: 2.2298 - val_acc: 0.1967\n",
      "Epoch 3/10\n",
      "9334/9334 [==============================] - 3s - loss: 2.1843 - acc: 0.2374 - val_loss: 2.2140 - val_acc: 0.1652\n",
      "Epoch 4/10\n",
      "9334/9334 [==============================] - 3s - loss: 2.0934 - acc: 0.2639 - val_loss: 2.0783 - val_acc: 0.2748\n",
      "Epoch 5/10\n",
      "9334/9334 [==============================] - 3s - loss: 1.9816 - acc: 0.3000 - val_loss: 1.9674 - val_acc: 0.3739\n",
      "Epoch 6/10\n",
      "9334/9334 [==============================] - 3s - loss: 1.8618 - acc: 0.3501 - val_loss: 1.8658 - val_acc: 0.3514\n",
      "Epoch 7/10\n",
      "9334/9334 [==============================] - 3s - loss: 1.7695 - acc: 0.3824 - val_loss: 1.7197 - val_acc: 0.4099\n",
      "Epoch 8/10\n",
      "9334/9334 [==============================] - 3s - loss: 1.6585 - acc: 0.4274 - val_loss: 1.6748 - val_acc: 0.4234\n",
      "Epoch 9/10\n",
      "9334/9334 [==============================] - 3s - loss: 1.5558 - acc: 0.4772 - val_loss: 1.5455 - val_acc: 0.4760\n",
      "Epoch 10/10\n",
      "9334/9334 [==============================] - 3s - loss: 1.4498 - acc: 0.5217 - val_loss: 1.3996 - val_acc: 0.5480\n",
      "Acc: 54.8048050375%\n",
      "acc: 54.80%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_27 (Conv2D)           (None, 16, 32, 32)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 16, 6, 6)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 512, 6, 6)         401920    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 512, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 20)                10260     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 413,606\n",
      "Trainable params: 413,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9334 samples, validate on 666 samples\n",
      "Epoch 1/10\n",
      "9334/9334 [==============================] - 4s - loss: 2.4948 - acc: 0.1872 - val_loss: 2.2535 - val_acc: 0.1997\n",
      "Epoch 2/10\n",
      "9334/9334 [==============================] - 3s - loss: 2.2316 - acc: 0.1946 - val_loss: 2.2286 - val_acc: 0.2012\n",
      "Epoch 3/10\n",
      "9334/9334 [==============================] - 3s - loss: 2.1888 - acc: 0.2207 - val_loss: 2.1628 - val_acc: 0.2432\n",
      "Epoch 4/10\n",
      "9334/9334 [==============================] - 3s - loss: 2.1263 - acc: 0.2452 - val_loss: 2.0877 - val_acc: 0.2598\n",
      "Epoch 5/10\n",
      "9334/9334 [==============================] - 4s - loss: 2.0571 - acc: 0.2829 - val_loss: 2.0605 - val_acc: 0.2297\n",
      "Epoch 6/10\n",
      "9334/9334 [==============================] - 3s - loss: 1.9811 - acc: 0.3063 - val_loss: 2.0517 - val_acc: 0.3183\n",
      "Epoch 7/10\n",
      "9334/9334 [==============================] - 3s - loss: 1.9114 - acc: 0.3333 - val_loss: 1.8866 - val_acc: 0.3589\n",
      "Epoch 8/10\n",
      "9334/9334 [==============================] - 3s - loss: 1.8481 - acc: 0.3563 - val_loss: 1.8350 - val_acc: 0.3589\n",
      "Epoch 9/10\n",
      "9334/9334 [==============================] - 3s - loss: 1.7810 - acc: 0.3873 - val_loss: 1.8033 - val_acc: 0.3859\n",
      "Epoch 10/10\n",
      "9334/9334 [==============================] - 3s - loss: 1.7058 - acc: 0.4173 - val_loss: 1.7070 - val_acc: 0.4129\n",
      "Acc: 41.291291336%\n",
      "acc: 41.29%\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_29 (Conv2D)           (None, 16, 32, 32)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 16, 6, 6)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 512, 6, 6)         401920    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 512, 1, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 20)                10260     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 413,606\n",
      "Trainable params: 413,606\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9334 samples, validate on 666 samples\n",
      "Epoch 1/10\n",
      "9334/9334 [==============================] - 4s - loss: 2.2982 - acc: 0.1452 - val_loss: 2.2524 - val_acc: 0.1366\n",
      "Epoch 2/10\n",
      "9334/9334 [==============================] - 3s - loss: 2.2281 - acc: 0.1955 - val_loss: 2.2197 - val_acc: 0.2222\n",
      "Epoch 3/10\n",
      "9334/9334 [==============================] - 4s - loss: 2.1933 - acc: 0.2056 - val_loss: 2.1877 - val_acc: 0.1967\n",
      "Epoch 4/10\n",
      "9334/9334 [==============================] - 3s - loss: 2.1481 - acc: 0.2249 - val_loss: 2.1366 - val_acc: 0.2117\n",
      "Epoch 5/10\n",
      "9334/9334 [==============================] - 3s - loss: 2.0841 - acc: 0.2651 - val_loss: 2.0890 - val_acc: 0.3003\n",
      "Epoch 6/10\n",
      "9334/9334 [==============================] - 3s - loss: 1.9882 - acc: 0.3095 - val_loss: 1.9414 - val_acc: 0.3288\n",
      "Epoch 7/10\n",
      "9334/9334 [==============================] - 3s - loss: 1.8752 - acc: 0.3523 - val_loss: 1.8145 - val_acc: 0.3874\n",
      "Epoch 8/10\n",
      "9334/9334 [==============================] - 3s - loss: 1.7533 - acc: 0.4030 - val_loss: 1.7183 - val_acc: 0.4054\n",
      "Epoch 9/10\n",
      "9334/9334 [==============================] - 3s - loss: 1.6436 - acc: 0.4519 - val_loss: 1.6098 - val_acc: 0.4354\n",
      "Epoch 10/10\n",
      "9334/9334 [==============================] - 3s - loss: 1.5106 - acc: 0.5060 - val_loss: 1.4731 - val_acc: 0.5015\n",
      "Acc: 50.1501502754%\n",
      "acc: 50.15%\n",
      "44.06% (+/- 8.05%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "kfold = KFold(10000, n_folds=15 , shuffle=True)\n",
    "cvscores = []\n",
    "\n",
    "for i, (train, test) in enumerate(kfold):\n",
    "\n",
    "   \n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(16, 5, 5, border_mode='same', activation='relu', input_shape=(3, 32, 32)))\n",
    "    model.add(MaxPooling2D(pool_size=(5, 5)))\n",
    "    model.add(Convolution2D(512, 7, 7, border_mode='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(5, 5)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(n_classes, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adagrad', metrics=['accuracy'])\n",
    "    adagrad = Adagrad(lr=0.01, epsilon=1e-08, decay=0.0)\n",
    "    model.fit(X_train[train], Y_train[train], batch_size=200, nb_epoch=10, verbose=1, \\\n",
    "                validation_data=(X_train[test], Y_train[test]))\n",
    "    scores = model.evaluate(X_train[test], Y_train[test], verbose=0)\n",
    "    print(\"Acc: \" + str(scores[1] * 100) + \"%\")\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Elija una de las redes entrenadas (preferentemente una con buen desempe~no) y visualice los pesos\n",
    "correspondientes a los \f",
    "ltros de la primera capa convolucional. Visualice adem\u0013as el efecto del \f",
    "ltro\n",
    "sobre algunas im\u0013agenes de entrenamiento. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (5, 5), input_shape=(3, 32, 32..., activation=\"relu\", padding=\"same\")`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (7, 7), activation=\"relu\", padding=\"same\")`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 32, 32)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 512, 16, 16)       401920    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 512, 8, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                655380    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 1,058,726\n",
      "Trainable params: 1,058,726\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73257 samples, validate on 26032 samples\n",
      "Epoch 1/8\n",
      "73257/73257 [==============================] - 152s - loss: 2.2357 - acc: 0.2255 - val_loss: 1.9050 - val_acc: 0.3330\n",
      "Epoch 2/8\n",
      "73257/73257 [==============================] - 145s - loss: 1.6667 - acc: 0.4574 - val_loss: 1.4314 - val_acc: 0.5282\n",
      "Epoch 3/8\n",
      "73257/73257 [==============================] - 145s - loss: 1.1937 - acc: 0.6260 - val_loss: 1.2291 - val_acc: 0.6050\n",
      "Epoch 4/8\n",
      "73257/73257 [==============================] - 145s - loss: 0.9710 - acc: 0.6945 - val_loss: 0.9302 - val_acc: 0.7069\n",
      "Epoch 5/8\n",
      "73257/73257 [==============================] - 145s - loss: 0.8633 - acc: 0.7277 - val_loss: 0.9949 - val_acc: 0.6870\n",
      "Epoch 6/8\n",
      "73257/73257 [==============================] - 145s - loss: 0.7929 - acc: 0.7527 - val_loss: 0.8685 - val_acc: 0.7196\n",
      "Epoch 7/8\n",
      "73257/73257 [==============================] - 146s - loss: 0.7430 - acc: 0.7726 - val_loss: 0.8247 - val_acc: 0.7489\n",
      "Epoch 8/8\n",
      "73257/73257 [==============================] - 146s - loss: 0.7020 - acc: 0.7903 - val_loss: 0.7925 - val_acc: 0.7602\n",
      "{'activity_regularizer': None, 'use_bias': True, 'data_format': 'channels_first', 'kernel_regularizer': None, 'activation': 'relu', 'filters': 16, 'strides': (1, 1), 'bias_regularizer': None, 'trainable': True, 'dtype': 'float32', 'batch_input_shape': (None, 3, 32, 32), 'bias_constraint': None, 'name': 'conv2d_1', 'kernel_constraint': None, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'mode': 'fan_avg', 'scale': 1.0, 'seed': None, 'distribution': 'uniform'}}, 'padding': 'same', 'kernel_size': (5, 5), 'dilation_rate': (1, 1)}\n",
      "[array([[[[ -9.81532708e-02,   8.65190029e-02,   1.65041275e-02, ...,\n",
      "           -5.09863533e-02,   8.40646848e-02,   2.58493442e-02],\n",
      "         [  7.71356095e-03,  -5.23053762e-03,   7.09983930e-02, ...,\n",
      "            5.91750965e-02,   8.41256138e-03,   3.16277072e-02],\n",
      "         [ -9.18334872e-02,  -3.93002108e-02,  -8.43300521e-02, ...,\n",
      "           -5.87264337e-02,  -1.09832779e-01,  -4.19329256e-02]],\n",
      "\n",
      "        [[ -1.79885134e-01,   4.24535014e-02,  -1.05966441e-01, ...,\n",
      "           -7.17671588e-02,  -3.02867172e-03,   8.69512036e-02],\n",
      "         [ -2.20039025e-01,  -4.27150689e-02,  -9.37684905e-03, ...,\n",
      "            3.37768681e-02,   4.40113805e-02,  -7.00754747e-02],\n",
      "         [ -9.59922820e-02,   6.63890243e-02,  -2.26768758e-03, ...,\n",
      "           -5.29810712e-02,   9.98987537e-03,   4.68988903e-02]],\n",
      "\n",
      "        [[ -1.06889896e-01,  -3.87443826e-02,  -7.41957426e-02, ...,\n",
      "            1.51485913e-02,   4.29016259e-03,  -1.25249416e-01],\n",
      "         [ -7.26397336e-02,   8.37748405e-03,  -1.48756206e-01, ...,\n",
      "           -8.74079838e-02,  -8.91178995e-02,   6.87889606e-02],\n",
      "         [ -1.06242627e-01,  -1.27291769e-01,  -8.36672261e-02, ...,\n",
      "            6.14756793e-02,  -3.34083475e-02,  -9.29979011e-02]],\n",
      "\n",
      "        [[ -1.66441411e-01,  -8.33465606e-02,  -8.60042349e-02, ...,\n",
      "            2.09375024e-02,   3.16561386e-02,  -6.25914782e-02],\n",
      "         [ -6.45678714e-02,  -6.78818151e-02,   8.56732056e-02, ...,\n",
      "            1.57435015e-02,  -1.38279468e-01,   9.49207246e-02],\n",
      "         [  2.14537838e-03,   6.79232329e-02,   1.37928694e-01, ...,\n",
      "           -3.77647765e-02,  -1.15278140e-01,  -2.42144912e-02]],\n",
      "\n",
      "        [[ -1.65359005e-01,  -1.77198332e-02,   7.43448436e-02, ...,\n",
      "            2.61264220e-02,  -9.15353596e-02,  -1.02700695e-01],\n",
      "         [ -1.79698810e-01,   2.63714865e-02,  -2.73398589e-02, ...,\n",
      "            8.58311504e-02,  -1.42625958e-01,  -5.38937785e-02],\n",
      "         [  3.77081148e-02,  -3.11464723e-02,  -5.65684140e-02, ...,\n",
      "            5.58636785e-02,  -3.58080119e-02,   9.36727971e-03]]],\n",
      "\n",
      "\n",
      "       [[[ -9.03950557e-02,  -3.48640755e-02,   1.12969428e-02, ...,\n",
      "            2.95480117e-02,   1.58239645e-03,   2.89634522e-02],\n",
      "         [ -4.78497222e-02,  -1.19408943e-01,   7.15644285e-02, ...,\n",
      "           -6.95452169e-02,   3.27539770e-03,   9.89105403e-02],\n",
      "         [ -1.63301587e-01,  -7.31974933e-03,   3.92040564e-03, ...,\n",
      "            3.08000203e-02,   6.65029213e-02,   4.99271601e-02]],\n",
      "\n",
      "        [[ -1.60208598e-01,   2.46690419e-02,  -3.85801718e-02, ...,\n",
      "            3.90465781e-02,  -8.52096379e-02,   1.84589718e-02],\n",
      "         [ -1.66349396e-01,  -1.19507879e-01,   1.21775800e-02, ...,\n",
      "           -9.76774693e-02,   7.40340725e-02,   4.29271422e-02],\n",
      "         [ -8.45315754e-02,   3.99780534e-02,   3.33215706e-02, ...,\n",
      "           -1.28228351e-01,   9.57866535e-02,  -1.00759804e-01]],\n",
      "\n",
      "        [[ -1.41594768e-01,  -1.16610155e-01,   1.06732413e-01, ...,\n",
      "            6.60072938e-02,   2.86632720e-02,  -2.10874546e-02],\n",
      "         [ -1.73143595e-01,   7.82328993e-02,   1.51846986e-02, ...,\n",
      "           -1.06465839e-01,  -1.68110635e-02,  -8.45946893e-02],\n",
      "         [ -1.27509728e-01,   7.21852481e-02,   3.35904323e-02, ...,\n",
      "           -1.17264718e-01,  -5.75336143e-02,  -3.69263440e-02]],\n",
      "\n",
      "        [[  5.41573390e-02,   4.74713631e-02,   3.92000787e-02, ...,\n",
      "            7.15105748e-03,  -1.99315622e-02,   2.57172864e-02],\n",
      "         [  2.96556130e-02,   6.93139434e-02,   2.84363778e-04, ...,\n",
      "           -1.18124774e-02,   4.41394746e-02,   3.74202169e-02],\n",
      "         [ -3.04775629e-02,   1.31512096e-03,   4.96142395e-02, ...,\n",
      "            9.07661244e-02,  -6.62561879e-02,  -1.00629821e-01]],\n",
      "\n",
      "        [[  3.21011543e-02,   6.04732223e-02,  -1.53817246e-02, ...,\n",
      "            5.78087196e-02,  -8.92637223e-02,  -1.19137682e-01],\n",
      "         [  3.80554958e-03,  -1.14975519e-01,  -1.43292576e-01, ...,\n",
      "           -1.30808890e-01,  -1.40188202e-01,  -4.27186042e-02],\n",
      "         [ -6.25971779e-02,   4.73491273e-05,  -4.72091548e-02, ...,\n",
      "            5.73000312e-02,   6.36158371e-03,   3.10047064e-02]]],\n",
      "\n",
      "\n",
      "       [[[ -6.69407919e-02,  -8.63115638e-02,   1.11483477e-01, ...,\n",
      "            6.15725443e-02,   1.17111176e-01,  -8.71038884e-02],\n",
      "         [  1.88285746e-02,  -2.84791011e-02,  -8.29843283e-02, ...,\n",
      "           -1.10739514e-01,   8.59963968e-02,   6.22163750e-02],\n",
      "         [ -1.13082297e-01,   7.33822137e-02,  -1.03613496e-01, ...,\n",
      "            7.82339089e-03,  -7.22377673e-02,   1.37794027e-02]],\n",
      "\n",
      "        [[  3.02032679e-02,  -2.64196806e-02,   1.10901721e-01, ...,\n",
      "            7.25369826e-02,   1.02733500e-01,   4.75751199e-02],\n",
      "         [  8.55479613e-02,  -9.04619023e-02,   1.01659046e-02, ...,\n",
      "           -2.76990086e-02,  -6.66046143e-03,  -1.08762145e-01],\n",
      "         [  7.76734576e-02,   6.23291507e-02,  -7.64222220e-02, ...,\n",
      "           -1.20573379e-01,   3.80610675e-02,   1.44555029e-02]],\n",
      "\n",
      "        [[ -7.95429200e-02,  -1.20232619e-01,   4.29132814e-03, ...,\n",
      "           -4.84751761e-02,   1.04295768e-01,  -1.27103636e-02],\n",
      "         [  4.49301936e-02,  -7.41795525e-02,  -1.34829521e-01, ...,\n",
      "            8.55048373e-02,   6.89419210e-02,   8.76434892e-02],\n",
      "         [  1.17523678e-01,   9.91352182e-03,   3.74485143e-02, ...,\n",
      "           -1.01287112e-01,  -6.87127709e-02,  -1.01402991e-01]],\n",
      "\n",
      "        [[ -2.48210579e-02,  -8.09630528e-02,  -1.78842135e-02, ...,\n",
      "           -8.76082107e-02,   2.10526269e-02,   1.43651236e-02],\n",
      "         [  6.48075417e-02,  -1.37569550e-02,  -1.50879789e-02, ...,\n",
      "            4.85009700e-02,  -4.68263738e-02,   8.05643350e-02],\n",
      "         [  6.91189021e-02,  -8.83415490e-02,  -5.29869050e-02, ...,\n",
      "           -1.71058122e-02,   1.06512167e-01,  -1.02985315e-01]],\n",
      "\n",
      "        [[  1.66037846e-02,   6.55544326e-02,   1.06243439e-01, ...,\n",
      "           -1.17450297e-01,   8.74463245e-02,   7.22037703e-02],\n",
      "         [  9.58900782e-04,   3.67606315e-03,  -2.10944600e-02, ...,\n",
      "           -1.39645059e-02,   6.77483752e-02,  -4.30940762e-02],\n",
      "         [ -1.15967430e-02,   4.96276580e-02,  -1.03347778e-01, ...,\n",
      "            5.23213558e-02,   8.68539698e-03,  -8.19357559e-02]]],\n",
      "\n",
      "\n",
      "       [[[ -1.70860421e-02,  -1.21921487e-01,   5.80197871e-02, ...,\n",
      "            4.98651005e-02,  -5.12577081e-03,  -7.60468245e-02],\n",
      "         [ -1.85418129e-02,   1.06343115e-02,  -7.14635709e-03, ...,\n",
      "           -1.14915423e-01,  -6.40275842e-03,  -3.92432250e-02],\n",
      "         [ -8.07056855e-03,   7.25500286e-02,  -9.25121084e-02, ...,\n",
      "            8.40423778e-02,   1.18847817e-01,   4.71812114e-02]],\n",
      "\n",
      "        [[  4.16306853e-02,  -2.65436936e-02,   4.95854914e-02, ...,\n",
      "            3.61173716e-03,  -8.61389004e-03,  -1.20857231e-01],\n",
      "         [  1.82142422e-01,   2.52977014e-02,  -1.39648141e-02, ...,\n",
      "           -7.39583671e-02,   2.60554142e-02,   9.89608467e-03],\n",
      "         [  8.49077180e-02,   2.23379023e-02,  -9.96489525e-02, ...,\n",
      "            5.18802647e-03,  -3.88685092e-02,  -2.46986412e-02]],\n",
      "\n",
      "        [[  2.08205402e-01,  -9.79914516e-02,   8.15585814e-03, ...,\n",
      "           -8.49303529e-02,  -3.10010910e-02,   7.66839366e-03],\n",
      "         [  9.26824939e-03,   8.32792670e-02,  -2.69817561e-02, ...,\n",
      "           -1.08794026e-01,  -5.23574986e-02,  -3.96674909e-02],\n",
      "         [  4.30167951e-02,   2.41173641e-03,   2.71962415e-02, ...,\n",
      "            7.38148242e-02,   1.16528027e-01,  -6.71091722e-04]],\n",
      "\n",
      "        [[  1.14690021e-01,   4.54610959e-03,  -5.66311479e-02, ...,\n",
      "            6.34212941e-02,  -8.81600827e-02,  -1.20272152e-01],\n",
      "         [  6.61321953e-02,   2.57016420e-02,  -1.49448320e-01, ...,\n",
      "            4.99568172e-02,  -5.12337312e-03,  -6.32761642e-02],\n",
      "         [  1.88798591e-01,  -9.60033908e-02,  -3.44142057e-02, ...,\n",
      "           -2.57200431e-02,  -2.73305606e-02,   8.67827609e-02]],\n",
      "\n",
      "        [[  3.44384722e-02,  -1.24145709e-01,   8.08442608e-02, ...,\n",
      "            6.90310299e-02,   6.63798973e-02,  -5.54144830e-02],\n",
      "         [ -1.63841788e-02,  -3.09256259e-02,   2.63233557e-02, ...,\n",
      "            2.06764508e-02,   1.23904943e-02,  -6.10271059e-02],\n",
      "         [ -5.90472445e-02,  -2.44929045e-02,   1.22017182e-01, ...,\n",
      "            2.77347537e-03,   9.73681360e-02,  -4.34456542e-02]]],\n",
      "\n",
      "\n",
      "       [[[  2.38565922e-01,   2.19304767e-02,   7.64428377e-02, ...,\n",
      "            3.18344496e-02,   1.02924027e-01,  -3.46362703e-02],\n",
      "         [  1.74603954e-01,  -1.20949648e-01,   8.74881912e-03, ...,\n",
      "           -9.01959911e-02,  -8.40735808e-02,  -5.31950556e-02],\n",
      "         [  3.82474996e-02,  -4.63230424e-02,   4.74001700e-03, ...,\n",
      "            7.79237598e-02,   8.49498510e-02,   4.28304728e-03]],\n",
      "\n",
      "        [[  2.30373710e-01,   6.50657490e-02,   1.39969453e-01, ...,\n",
      "           -1.30197508e-02,   5.55703267e-02,   1.20570017e-02],\n",
      "         [  1.80376306e-01,   3.67311910e-02,  -2.16848999e-02, ...,\n",
      "           -7.08508268e-02,  -7.39509612e-02,   4.06037755e-02],\n",
      "         [  1.76668450e-01,   2.80784350e-03,   7.29918107e-02, ...,\n",
      "            8.65839049e-02,  -1.15710299e-03,  -7.25102425e-02]],\n",
      "\n",
      "        [[  1.35391146e-01,  -1.62661932e-02,   8.10467675e-02, ...,\n",
      "            8.36433843e-02,   9.00428742e-02,   2.86733117e-02],\n",
      "         [  2.17098564e-01,   6.40056580e-02,  -9.80717763e-02, ...,\n",
      "            5.73458076e-02,   7.72036845e-03,   8.37278515e-02],\n",
      "         [  9.66440812e-02,  -1.03189312e-01,   9.80088562e-02, ...,\n",
      "           -5.04856333e-02,   2.01452356e-02,   1.09120328e-02]],\n",
      "\n",
      "        [[  7.10493177e-02,  -1.06932654e-03,  -5.79280145e-02, ...,\n",
      "            7.60076270e-02,  -5.57893002e-03,   3.34799811e-02],\n",
      "         [  1.50002718e-01,   2.50574779e-02,  -1.70368571e-02, ...,\n",
      "           -7.62537271e-02,   2.90764812e-02,  -3.22940834e-02],\n",
      "         [  9.12465230e-02,   5.20928763e-02,   1.13333892e-02, ...,\n",
      "           -3.75888087e-02,  -7.06675351e-02,   1.92256942e-02]],\n",
      "\n",
      "        [[ -4.27282080e-02,  -1.06209636e-01,  -3.56322862e-02, ...,\n",
      "           -7.47028440e-02,  -1.22694880e-01,  -6.57258183e-02],\n",
      "         [  1.39356807e-01,  -1.04307048e-01,  -1.23244934e-01, ...,\n",
      "           -1.09402262e-01,   4.78293397e-04,  -3.23682316e-02],\n",
      "         [  3.95349078e-02,  -1.02416620e-01,  -2.78936699e-03, ...,\n",
      "           -9.24519300e-02,  -1.69706754e-02,  -1.07347228e-01]]]], dtype=float32), array([ 0.06481902, -0.0195583 ,  0.10930843,  0.07770581, -0.00605806,\n",
      "       -0.01112532,  0.02512315,  0.11384413, -0.01933209,  0.00855279,\n",
      "       -0.01991237, -0.0189176 , -0.01608373, -0.0198632 , -0.00460059,\n",
      "       -0.01499234], dtype=float32)]\n",
      "{'trainable': True, 'padding': 'valid', 'data_format': 'channels_first', 'name': 'max_pooling2d_1', 'pool_size': (2, 2), 'strides': (2, 2)}\n",
      "[]\n",
      "{'activation': 'relu', 'use_bias': True, 'data_format': 'channels_first', 'kernel_regularizer': None, 'strides': (1, 1), 'filters': 512, 'name': 'conv2d_2', 'bias_regularizer': None, 'trainable': True, 'padding': 'same', 'activity_regularizer': None, 'kernel_constraint': None, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'mode': 'fan_avg', 'scale': 1.0, 'seed': None, 'distribution': 'uniform'}}, 'bias_constraint': None, 'kernel_size': (7, 7), 'dilation_rate': (1, 1)}\n",
      "[array([[[[  1.37000876e-02,   9.17102117e-03,  -4.44395319e-02, ...,\n",
      "            1.22979898e-02,  -7.11887702e-03,  -2.03689821e-02],\n",
      "         [  2.05524005e-02,  -1.36560565e-02,   1.89606734e-02, ...,\n",
      "           -1.00489974e-03,   5.17070293e-06,  -6.88344613e-03],\n",
      "         [ -9.12465807e-03,  -3.41250747e-03,  -4.39514443e-02, ...,\n",
      "           -1.27769159e-02,   2.09740847e-02,  -5.89476712e-03],\n",
      "         ..., \n",
      "         [  1.81479026e-02,  -2.38505825e-02,   1.45587302e-03, ...,\n",
      "           -1.25681954e-02,  -3.96290980e-03,   3.16467322e-03],\n",
      "         [ -2.85729556e-03,  -2.82159243e-02,  -1.26118585e-02, ...,\n",
      "           -4.19302937e-03,  -1.23481336e-03,  -1.82100926e-02],\n",
      "         [  5.82305342e-03,  -6.07239176e-03,  -7.21466728e-04, ...,\n",
      "            7.64710829e-03,  -1.52660888e-02,   3.61322425e-04]],\n",
      "\n",
      "        [[ -1.93351787e-02,  -1.23818731e-02,  -2.11629644e-02, ...,\n",
      "           -1.11288195e-02,  -1.11346587e-03,   9.92119033e-03],\n",
      "         [  9.51355696e-03,  -1.25255678e-02,   1.10901531e-03, ...,\n",
      "            4.53362736e-04,  -2.38117520e-02,  -1.00287683e-02],\n",
      "         [ -1.18349493e-02,   5.49688470e-03,  -1.84939895e-02, ...,\n",
      "           -4.25933599e-02,   9.80346743e-03,   6.02893718e-03],\n",
      "         ..., \n",
      "         [  4.32979595e-03,  -2.38057841e-02,  -2.14023795e-03, ...,\n",
      "            1.14334673e-02,  -4.04688809e-03,  -1.77902300e-02],\n",
      "         [ -2.27867253e-02,  -2.59414501e-02,   1.75345456e-03, ...,\n",
      "           -1.91861317e-02,   9.41304083e-04,  -5.19635342e-03],\n",
      "         [  2.93522514e-03,  -1.16696600e-02,   2.05793791e-02, ...,\n",
      "            2.34629121e-02,   1.18762627e-02,  -1.20722996e-02]],\n",
      "\n",
      "        [[ -3.23585421e-02,  -2.03673523e-02,  -3.24995741e-02, ...,\n",
      "           -2.85495166e-03,   2.08936278e-02,   3.15836840e-03],\n",
      "         [  5.19579567e-04,  -1.85605809e-02,   4.37121978e-03, ...,\n",
      "            2.22524516e-02,  -2.43801195e-02,  -1.31129874e-02],\n",
      "         [ -4.20178808e-02,   1.01261828e-02,  -4.58318181e-02, ...,\n",
      "           -2.92789489e-02,   1.90483965e-02,   4.71333414e-03],\n",
      "         ..., \n",
      "         [  1.65370498e-02,  -8.44181608e-03,  -4.84942552e-03, ...,\n",
      "            1.93803739e-02,  -1.39093697e-02,  -9.47487168e-03],\n",
      "         [  5.07955719e-03,  -1.18173165e-02,  -2.43275613e-02, ...,\n",
      "           -5.76051185e-03,  -2.51069479e-02,  -3.42052476e-03],\n",
      "         [  1.45993019e-02,  -2.52260566e-02,   6.73340634e-04, ...,\n",
      "           -1.72050018e-03,   1.79079250e-02,  -4.96160239e-03]],\n",
      "\n",
      "        ..., \n",
      "        [[ -2.93185413e-02,  -1.16402982e-02,  -1.81547012e-02, ...,\n",
      "           -1.26681486e-02,   7.29062129e-03,  -1.39886951e-02],\n",
      "         [  2.24357601e-02,  -7.86295347e-03,  -3.08725121e-03, ...,\n",
      "            7.60338129e-03,  -6.48349896e-03,  -1.08181257e-02],\n",
      "         [ -2.60350816e-02,  -2.33683269e-03,  -6.69918880e-02, ...,\n",
      "           -3.58502194e-02,   1.07044932e-02,  -2.36726627e-02],\n",
      "         ..., \n",
      "         [ -4.76584164e-03,   1.60652306e-03,  -5.90682402e-03, ...,\n",
      "            5.19176247e-03,   9.16199107e-03,  -1.33843319e-02],\n",
      "         [ -7.09070917e-03,  -2.77855396e-02,  -7.02895271e-03, ...,\n",
      "           -1.90605014e-03,  -2.40317243e-03,  -1.94911025e-02],\n",
      "         [  6.43553649e-05,  -1.20087760e-02,   1.97922047e-02, ...,\n",
      "           -1.19488733e-02,  -1.39763383e-02,   1.78362951e-02]],\n",
      "\n",
      "        [[ -2.69949660e-02,  -3.51313315e-02,  -1.29936943e-02, ...,\n",
      "            4.76468494e-03,   1.41752213e-02,  -2.48282962e-02],\n",
      "         [  6.42673159e-03,  -1.37197331e-03,   1.60132591e-02, ...,\n",
      "            3.37979430e-03,  -1.50170261e-02,   4.11829818e-03],\n",
      "         [ -1.56864021e-02,  -7.81356078e-03,  -4.11122181e-02, ...,\n",
      "           -3.49088386e-02,  -6.39520306e-03,   5.90615813e-03],\n",
      "         ..., \n",
      "         [ -7.03363447e-04,  -1.72407087e-02,   1.77460909e-02, ...,\n",
      "           -1.97649887e-03,   8.52468703e-03,   4.14957013e-03],\n",
      "         [  4.36877366e-03,  -8.13153572e-03,  -1.75045375e-02, ...,\n",
      "           -9.91787412e-04,   8.50608200e-03,  -2.34032068e-02],\n",
      "         [  2.34656241e-02,   2.17605289e-03,   2.38412563e-02, ...,\n",
      "           -3.25873867e-03,  -2.02227198e-02,   3.40888463e-03]],\n",
      "\n",
      "        [[ -2.30945796e-02,  -2.79616378e-02,  -1.47639709e-02, ...,\n",
      "           -8.51894729e-03,  -4.16982984e-05,   4.11596324e-04],\n",
      "         [  2.41146106e-02,  -2.00769311e-04,   1.41228409e-02, ...,\n",
      "            1.77063104e-02,   1.73879527e-02,  -8.07608478e-03],\n",
      "         [ -3.22187413e-03,  -6.06817473e-03,  -6.35088533e-02, ...,\n",
      "           -1.12852640e-03,  -1.36752175e-02,  -1.41918268e-02],\n",
      "         ..., \n",
      "         [ -4.39478131e-03,  -2.54580509e-02,   9.38763318e-04, ...,\n",
      "            1.10499412e-02,  -2.92475708e-03,  -1.59785803e-02],\n",
      "         [ -4.19238553e-04,  -2.57007796e-02,  -2.65860115e-04, ...,\n",
      "            6.64104358e-04,   2.83352728e-03,   4.22919821e-03],\n",
      "         [ -1.40236062e-03,  -1.25933653e-02,   2.05420926e-02, ...,\n",
      "            2.04346683e-02,   1.50906146e-02,   3.86077538e-03]]],\n",
      "\n",
      "\n",
      "       [[[  7.87162129e-03,   9.24785528e-03,  -4.33240533e-02, ...,\n",
      "           -1.36179747e-02,  -2.08606645e-02,   4.86630993e-03],\n",
      "         [ -3.68915219e-03,  -9.48057335e-04,   7.64054758e-03, ...,\n",
      "            1.63192898e-02,  -1.85231995e-02,  -1.17444731e-02],\n",
      "         [  3.37190053e-04,   1.55952200e-02,   1.90726947e-02, ...,\n",
      "           -2.72093993e-02,  -5.06554637e-03,  -2.14548297e-02],\n",
      "         ..., \n",
      "         [ -7.94085488e-03,  -3.60506447e-03,   2.13038921e-03, ...,\n",
      "           -8.54541548e-03,  -2.25056410e-02,  -1.80555955e-02],\n",
      "         [  3.89103196e-03,  -3.26335052e-04,  -1.45859802e-02, ...,\n",
      "           -7.82827009e-03,  -2.17618216e-02,   1.79792847e-03],\n",
      "         [  2.17520203e-02,  -4.06496227e-03,   1.88015122e-03, ...,\n",
      "           -2.37357989e-03,   1.70379337e-02,   1.18781701e-02]],\n",
      "\n",
      "        [[ -1.72232799e-02,   1.25546614e-02,  -1.11694597e-02, ...,\n",
      "           -1.66159086e-02,   4.74215066e-03,  -2.36752350e-02],\n",
      "         [  2.10506283e-02,  -5.66982478e-03,   2.13090181e-02, ...,\n",
      "            1.26038557e-02,  -2.11481825e-02,  -2.13219225e-02],\n",
      "         [  4.29972559e-02,   1.79192685e-02,  -1.41315078e-02, ...,\n",
      "           -2.94500943e-02,  -9.13494453e-03,   2.03554891e-03],\n",
      "         ..., \n",
      "         [ -4.95144026e-03,  -3.98809556e-03,  -3.06894095e-03, ...,\n",
      "            1.77175049e-02,  -1.61721222e-02,  -1.33165568e-02],\n",
      "         [ -8.94238800e-03,  -3.65514681e-03,   1.27878296e-03, ...,\n",
      "            6.83739129e-03,   6.21877261e-04,  -4.47088014e-03],\n",
      "         [  1.56149445e-02,  -2.16585808e-02,   2.26311907e-02, ...,\n",
      "            1.81816369e-02,   4.75710165e-03,   2.87386402e-03]],\n",
      "\n",
      "        [[ -2.92502530e-02,   1.14838779e-03,  -1.12760002e-02, ...,\n",
      "           -2.42130621e-03,  -4.00793832e-03,  -1.44524709e-03],\n",
      "         [  1.86170992e-02,  -1.83523763e-02,   6.60380581e-03, ...,\n",
      "           -2.30580731e-03,  -5.88649139e-03,  -1.40528623e-02],\n",
      "         [  1.92541890e-02,  -1.10421143e-03,  -2.28073280e-02, ...,\n",
      "           -2.19045822e-02,   4.99701593e-03,   2.43078340e-02],\n",
      "         ..., \n",
      "         [ -9.67745378e-04,  -1.97937544e-02,   3.60578601e-03, ...,\n",
      "            3.62252607e-03,  -1.16857486e-02,  -1.83264054e-02],\n",
      "         [  5.41432388e-03,  -9.84379370e-03,  -1.13536967e-02, ...,\n",
      "           -3.82824778e-03,  -7.91481347e-04,  -1.17260106e-02],\n",
      "         [  1.61504224e-02,  -9.28966608e-03,   2.16001607e-02, ...,\n",
      "            1.44586181e-02,  -5.13779465e-03,  -6.27002679e-03]],\n",
      "\n",
      "        ..., \n",
      "        [[ -3.91218672e-03,   1.37611236e-02,  -3.14589217e-03, ...,\n",
      "            8.83611385e-03,  -3.95436864e-03,   1.34450747e-04],\n",
      "         [  1.21776611e-02,  -1.96588282e-02,   2.08817087e-02, ...,\n",
      "           -3.34308017e-03,  -1.53693296e-02,  -1.16439071e-02],\n",
      "         [  1.57416388e-02,  -1.33547150e-02,   1.42249954e-03, ...,\n",
      "           -6.02048859e-02,  -2.15480030e-02,   2.09028088e-03],\n",
      "         ..., \n",
      "         [  1.31125338e-02,  -1.59206390e-02,   2.36418769e-02, ...,\n",
      "            1.43028274e-02,   1.61280110e-02,  -2.28456520e-02],\n",
      "         [  3.16172536e-03,   2.74340971e-03,  -2.74375454e-03, ...,\n",
      "            2.73226015e-03,  -1.28219482e-02,   3.16597987e-03],\n",
      "         [ -2.58832835e-02,  -5.58038987e-03,   3.90478154e-03, ...,\n",
      "           -7.99488369e-03,  -1.87451355e-02,  -8.93126149e-03]],\n",
      "\n",
      "        [[  1.22988988e-02,   2.11328338e-03,  -2.15518456e-02, ...,\n",
      "           -1.81299006e-03,   2.71912105e-03,  -2.98654139e-02],\n",
      "         [  2.05839146e-02,   1.89135212e-03,   2.29769554e-02, ...,\n",
      "            2.43714433e-02,   1.01277102e-02,  -3.93397082e-03],\n",
      "         [ -6.62127417e-03,  -1.00174798e-02,  -5.08971214e-02, ...,\n",
      "           -5.75202219e-02,  -4.86913137e-03,   2.17784103e-03],\n",
      "         ..., \n",
      "         [ -6.51230849e-03,  -1.82459187e-02,   2.05805786e-02, ...,\n",
      "            5.19589661e-03,   1.07461335e-02,  -1.53905433e-02],\n",
      "         [ -2.18807105e-02,   1.30428141e-02,  -2.09353045e-02, ...,\n",
      "           -1.43434918e-02,  -1.09088644e-02,  -2.73007993e-03],\n",
      "         [  1.84933431e-02,   4.88419738e-03,  -2.60484684e-03, ...,\n",
      "            1.35145625e-02,  -2.31397022e-02,   4.54150978e-03]],\n",
      "\n",
      "        [[  4.97225160e-03,   4.23986436e-04,   1.77060459e-02, ...,\n",
      "            9.54389013e-03,  -1.09116752e-02,   1.28064817e-02],\n",
      "         [  5.31303789e-03,   2.92874384e-03,   2.51765084e-03, ...,\n",
      "            1.60917789e-02,   4.11304459e-03,   1.65586174e-03],\n",
      "         [  4.70551327e-02,   1.32301226e-02,  -3.63100022e-02, ...,\n",
      "           -1.09503660e-02,  -3.94185074e-03,  -1.44219613e-02],\n",
      "         ..., \n",
      "         [  8.15918110e-03,  -5.26062120e-03,   2.11218931e-02, ...,\n",
      "            2.01564170e-02,   1.66161917e-02,   4.63607535e-03],\n",
      "         [ -2.07772478e-03,  -7.30876345e-03,   2.92968168e-03, ...,\n",
      "           -9.07953084e-03,   1.20813465e-02,  -1.39815509e-02],\n",
      "         [ -8.41731322e-04,  -1.09785683e-02,   2.06551366e-02, ...,\n",
      "            1.80340018e-02,  -9.20163654e-03,  -3.45915090e-03]]],\n",
      "\n",
      "\n",
      "       [[[  1.33929085e-02,   3.80076701e-03,   1.07948938e-02, ...,\n",
      "           -1.96422767e-02,  -1.89608168e-02,   1.39747895e-02],\n",
      "         [  1.15449075e-02,   1.38168107e-03,   9.11802333e-03, ...,\n",
      "           -7.61408301e-05,  -9.27024335e-03,   1.18344091e-04],\n",
      "         [  3.90571356e-02,  -6.55909255e-03,   5.29055111e-02, ...,\n",
      "            1.61548378e-05,  -2.15200577e-02,  -1.10898130e-02],\n",
      "         ..., \n",
      "         [ -5.97115653e-03,  -4.09868220e-03,   1.22116115e-02, ...,\n",
      "            1.22938687e-02,  -1.79641042e-02,  -1.42167136e-03],\n",
      "         [ -4.76353709e-03,  -8.43811594e-03,   2.25289981e-03, ...,\n",
      "           -8.05122871e-03,  -1.57875605e-02,   3.38455359e-03],\n",
      "         [ -3.93255334e-03,  -2.44757552e-02,   2.31025014e-02, ...,\n",
      "           -3.78361065e-03,   1.10825580e-02,  -1.36648593e-02]],\n",
      "\n",
      "        [[ -3.51035595e-03,   9.69343632e-03,   1.94347780e-02, ...,\n",
      "            2.82705436e-03,  -5.26811811e-04,   2.01438833e-02],\n",
      "         [  2.84712249e-03,   3.62213381e-04,  -2.70285760e-03, ...,\n",
      "           -2.20214971e-03,  -2.47406606e-02,  -1.20673636e-02],\n",
      "         [  2.78719552e-02,   1.86297596e-02,   1.15582412e-02, ...,\n",
      "           -6.05197251e-02,   1.51845161e-03,  -2.00919174e-02],\n",
      "         ..., \n",
      "         [  4.68384242e-03,  -1.38416672e-02,   2.30991878e-02, ...,\n",
      "            2.11003516e-02,  -5.52827865e-03,  -2.79360008e-03],\n",
      "         [ -2.43037613e-03,  -4.35230322e-04,  -1.03319762e-02, ...,\n",
      "           -6.68915280e-04,  -7.70162372e-03,  -1.50592928e-03],\n",
      "         [  9.64524318e-03,  -1.11957658e-02,   2.25860570e-02, ...,\n",
      "            1.94030907e-02,  -2.05505807e-02,   1.49264466e-03]],\n",
      "\n",
      "        [[  1.14297345e-02,  -1.12839397e-02,   1.58358384e-02, ...,\n",
      "           -2.28944868e-02,  -1.94628797e-02,   1.90351307e-02],\n",
      "         [ -4.81635798e-04,  -1.12558398e-02,   8.42665322e-03, ...,\n",
      "            7.89139792e-03,  -2.14688554e-02,  -7.51991663e-03],\n",
      "         [  2.18992308e-03,   7.17732939e-04,   2.84991153e-02, ...,\n",
      "           -6.39710650e-02,   3.96542531e-03,   2.43328512e-03],\n",
      "         ..., \n",
      "         [  2.32002605e-03,  -1.90041550e-02,   4.77284892e-03, ...,\n",
      "           -7.98090547e-03,  -2.22431365e-02,  -7.77815562e-03],\n",
      "         [ -1.60696954e-02,   1.26632638e-02,  -5.12873055e-03, ...,\n",
      "           -1.75241474e-02,  -1.95050575e-02,  -5.96157927e-03],\n",
      "         [  1.09774638e-02,  -1.04816118e-02,   5.18888328e-03, ...,\n",
      "            4.47234325e-03,  -6.73115905e-03,  -1.08913770e-02]],\n",
      "\n",
      "        ..., \n",
      "        [[  2.25353092e-02,  -2.22161110e-03,   6.84808195e-03, ...,\n",
      "           -9.61313210e-03,  -2.19918601e-03,  -3.28927254e-03],\n",
      "         [  7.63927866e-03,  -8.33234377e-03,   1.72987476e-03, ...,\n",
      "            1.51050258e-02,  -1.26258191e-03,  -1.15555068e-02],\n",
      "         [ -5.25272451e-03,   1.00022759e-02,  -2.06817277e-02, ...,\n",
      "           -3.82011868e-02,  -1.36395358e-03,   1.83691680e-02],\n",
      "         ..., \n",
      "         [ -5.87546546e-03,  -1.77098438e-02,   1.87333580e-02, ...,\n",
      "            9.43709724e-03,  -2.39750203e-02,  -2.21107230e-02],\n",
      "         [ -1.27589339e-02,   1.47358673e-02,  -2.46703662e-02, ...,\n",
      "           -2.01169122e-02,  -5.12872636e-03,  -5.60933305e-03],\n",
      "         [ -3.70572018e-03,  -5.36000868e-03,  -1.94416009e-02, ...,\n",
      "           -7.81615451e-03,  -1.87354721e-02,  -3.38305440e-03]],\n",
      "\n",
      "        [[  1.98399667e-02,  -4.03864449e-03,   1.89147031e-04, ...,\n",
      "            8.69918894e-03,  -1.08213006e-02,   2.02274974e-02],\n",
      "         [  7.88699929e-03,  -2.15083221e-03,   1.78526994e-02, ...,\n",
      "            2.75745941e-03,  -2.51312386e-02,  -2.41611563e-02],\n",
      "         [  4.71457327e-03,  -4.20385040e-03,  -3.28668579e-02, ...,\n",
      "           -3.65623422e-02,   1.80919748e-03,  -2.02184040e-02],\n",
      "         ..., \n",
      "         [ -6.19060942e-04,  -2.93783620e-02,  -3.91846243e-03, ...,\n",
      "            2.05328520e-02,  -2.31961198e-02,  -2.19653398e-02],\n",
      "         [ -1.97291337e-02,  -5.54986484e-03,  -1.85829047e-02, ...,\n",
      "           -4.40967875e-03,  -1.75673403e-02,  -5.35172003e-04],\n",
      "         [  1.07794870e-02,  -9.91392415e-03,   1.55182220e-02, ...,\n",
      "           -4.49682120e-03,  -1.18700666e-02,  -1.01477904e-02]],\n",
      "\n",
      "        [[  9.26287472e-03,   1.46308038e-02,   7.86661543e-03, ...,\n",
      "            3.64172296e-03,  -1.23433527e-02,   1.54793682e-02],\n",
      "         [  7.20257219e-03,  -1.01465418e-03,   9.25529841e-03, ...,\n",
      "            7.19568599e-03,   7.24393502e-03,  -1.96638610e-03],\n",
      "         [  1.42778847e-02,   1.91174578e-02,  -5.51023781e-02, ...,\n",
      "           -4.51102518e-02,   1.84547883e-02,   2.83758738e-03],\n",
      "         ..., \n",
      "         [  2.75451201e-03,   1.25272979e-03,   2.11761519e-02, ...,\n",
      "            5.54190204e-03,  -2.95198959e-04,  -1.29693234e-02],\n",
      "         [  3.42660840e-03,   1.42321931e-02,   1.48327404e-03, ...,\n",
      "           -4.47053323e-03,  -1.65584963e-03,  -2.43486445e-02],\n",
      "         [ -2.03896370e-02,  -1.36561953e-02,   9.47680883e-03, ...,\n",
      "            1.52039137e-02,   7.45073333e-03,  -1.78354885e-02]]],\n",
      "\n",
      "\n",
      "       ..., \n",
      "       [[[ -7.21843820e-03,   4.57901461e-03,  -2.99560241e-02, ...,\n",
      "           -1.46028940e-02,  -1.86245609e-03,  -1.31717529e-02],\n",
      "         [  1.44336661e-02,  -6.13843417e-03,   1.13012525e-03, ...,\n",
      "           -8.40061984e-04,   3.75154987e-03,  -1.39117921e-02],\n",
      "         [  2.11348850e-02,  -2.12322269e-03,   1.78466365e-02, ...,\n",
      "            2.43767165e-02,   1.13880122e-02,   8.65034107e-03],\n",
      "         ..., \n",
      "         [  1.60693955e-02,  -3.06534506e-02,   5.08844806e-03, ...,\n",
      "           -1.02550332e-02,   1.34176575e-04,   3.35000083e-03],\n",
      "         [ -1.52779659e-02,  -2.95584742e-02,  -1.45783406e-02, ...,\n",
      "           -1.59025025e-02,  -1.33009925e-02,  -3.64947226e-03],\n",
      "         [ -2.44290978e-02,   2.90432107e-03,   1.71000287e-02, ...,\n",
      "           -7.04198261e-04,  -1.75631978e-02,   2.15711296e-02]],\n",
      "\n",
      "        [[  1.13591440e-02,  -1.81063972e-02,  -1.55762238e-02, ...,\n",
      "            1.33331558e-02,  -1.73296519e-02,  -1.50793353e-02],\n",
      "         [ -3.79551086e-03,  -1.92691293e-02,   2.06006709e-02, ...,\n",
      "           -3.92103009e-03,   3.26179899e-03,  -1.49018411e-03],\n",
      "         [  2.99375374e-02,  -8.45857803e-03,  -2.17503551e-02, ...,\n",
      "           -1.24802813e-02,  -7.97186047e-04,   1.51821384e-02],\n",
      "         ..., \n",
      "         [  2.27545202e-02,  -1.36572383e-02,   8.86537042e-03, ...,\n",
      "           -8.78624152e-03,   5.84514986e-04,  -1.13350227e-02],\n",
      "         [ -1.89192761e-02,  -1.04987519e-02,   1.86954776e-03, ...,\n",
      "            1.72549579e-03,   5.16696787e-03,  -1.61925219e-02],\n",
      "         [ -1.72815602e-02,  -2.49528568e-02,  -1.61496513e-02, ...,\n",
      "            2.54929159e-03,   2.47275382e-02,  -1.51861226e-02]],\n",
      "\n",
      "        [[  1.48672769e-02,  -2.28106976e-02,  -1.02605708e-02, ...,\n",
      "           -3.02869789e-02,  -1.61396479e-03,  -6.13975152e-03],\n",
      "         [  2.68640835e-03,   1.10004898e-02,   2.30424274e-02, ...,\n",
      "            5.81005355e-03,   9.20964405e-04,  -2.05173381e-02],\n",
      "         [  2.83630192e-02,  -1.19851315e-02,  -1.32455444e-02, ...,\n",
      "           -1.96809638e-02,  -1.62871778e-02,   1.71857458e-02],\n",
      "         ..., \n",
      "         [  1.03104850e-02,   4.44666576e-03,   1.36826597e-02, ...,\n",
      "            1.34485262e-02,  -1.91468019e-02,  -1.05349813e-02],\n",
      "         [  4.02906723e-03,   3.73921846e-03,  -1.44509785e-02, ...,\n",
      "           -7.32550910e-03,  -1.05780987e-02,  -2.42049657e-02],\n",
      "         [  1.95067711e-02,   3.83319682e-04,  -9.48525220e-03, ...,\n",
      "            1.03028296e-02,  -2.13563442e-02,   4.90084663e-03]],\n",
      "\n",
      "        ..., \n",
      "        [[  1.28916986e-02,  -1.13084884e-02,  -7.20529491e-03, ...,\n",
      "           -2.34299097e-02,  -2.45547518e-02,  -9.10363815e-06],\n",
      "         [ -1.23707217e-03,  -2.53089145e-02,   4.03486798e-03, ...,\n",
      "            3.38059617e-04,  -1.07177403e-02,  -9.66785010e-03],\n",
      "         [  3.58492024e-02,  -3.32922325e-04,  -1.29378319e-03, ...,\n",
      "           -1.31257239e-03,  -1.89678445e-02,   2.29778271e-02],\n",
      "         ..., \n",
      "         [  1.74407624e-02,  -1.80344516e-03,   1.98955182e-02, ...,\n",
      "            1.05364323e-02,  -2.51665153e-02,  -2.06962824e-02],\n",
      "         [ -1.75494025e-03,  -2.77549261e-03,  -2.12819334e-02, ...,\n",
      "           -2.16921121e-02,  -1.50701562e-02,  -7.04722945e-03],\n",
      "         [  1.70391165e-02,   1.57639030e-02,  -2.73421388e-02, ...,\n",
      "            1.81796886e-02,  -3.93000711e-03,  -1.49413729e-02]],\n",
      "\n",
      "        [[  1.63351297e-02,  -1.13873193e-02,   1.04236426e-02, ...,\n",
      "           -1.03026368e-02,  -1.37570240e-02,  -6.03350159e-03],\n",
      "         [  8.21203273e-03,  -6.08735532e-03,   1.78971831e-02, ...,\n",
      "            6.34895056e-04,  -2.20505036e-02,  -9.03622899e-03],\n",
      "         [  5.84066957e-02,  -4.02217265e-03,  -3.65525447e-02, ...,\n",
      "           -2.82812826e-02,  -9.86474659e-03,   1.95433572e-02],\n",
      "         ..., \n",
      "         [  7.29442108e-03,   5.35416231e-03,  -4.74133389e-03, ...,\n",
      "           -2.77475943e-03,  -1.68431308e-02,  -1.57408398e-02],\n",
      "         [ -1.25818895e-02,  -8.20927788e-03,  -7.04638753e-03, ...,\n",
      "           -6.94669737e-03,  -5.95508376e-03,   3.04451678e-03],\n",
      "         [  1.30900452e-02,  -2.47626118e-02,  -4.77626082e-03, ...,\n",
      "            1.91819966e-02,   4.85307351e-03,  -2.29040068e-02]],\n",
      "\n",
      "        [[  2.56483387e-02,  -1.11724399e-02,   1.21097714e-02, ...,\n",
      "           -3.32558937e-02,   2.63481168e-03,  -9.92510840e-03],\n",
      "         [  2.29657404e-02,   2.13470049e-02,  -3.15629621e-03, ...,\n",
      "            1.05546257e-02,  -2.72137020e-03,  -1.94139406e-02],\n",
      "         [  6.10576943e-02,  -2.49310806e-02,  -1.34186447e-02, ...,\n",
      "            1.11015728e-02,   2.39416510e-02,  -7.30187865e-03],\n",
      "         ..., \n",
      "         [  1.72261763e-02,  -1.09657855e-03,   8.82549305e-03, ...,\n",
      "           -2.80459062e-03,  -2.03731172e-02,  -1.04930205e-02],\n",
      "         [ -1.42706968e-02,   2.30358588e-03,  -8.04638490e-03, ...,\n",
      "            4.04999172e-03,  -4.79860883e-03,  -1.84004791e-02],\n",
      "         [ -3.49882385e-03,  -5.24631748e-03,   1.17252627e-02, ...,\n",
      "            5.65197272e-03,   9.15203243e-04,  -7.67492130e-03]]],\n",
      "\n",
      "\n",
      "       [[[ -7.91923143e-03,  -7.35041592e-03,  -2.13272963e-02, ...,\n",
      "            2.21420988e-03,  -9.01640113e-03,  -2.27084793e-02],\n",
      "         [ -1.45329849e-03,   6.75239717e-04,   1.43968398e-02, ...,\n",
      "            1.10714706e-02,  -2.03965455e-02,  -4.67158016e-03],\n",
      "         [  1.72371212e-02,  -1.54045811e-02,  -1.06707355e-02, ...,\n",
      "           -1.94934402e-02,  -1.34352064e-02,  -3.41100432e-03],\n",
      "         ..., \n",
      "         [  7.34470319e-03,  -2.12524869e-02,   1.18634943e-02, ...,\n",
      "            2.46276031e-03,  -4.40178160e-03,  -2.88821850e-03],\n",
      "         [ -4.72672842e-03,  -1.88537650e-02,  -1.50120379e-02, ...,\n",
      "           -3.99623159e-03,  -8.74501560e-03,   4.34038695e-03],\n",
      "         [  1.06282951e-02,  -2.20890250e-02,  -3.42345424e-03, ...,\n",
      "           -2.11891942e-02,   3.12271994e-03,  -3.17739230e-03]],\n",
      "\n",
      "        [[ -1.72388107e-02,  -2.60912664e-02,  -1.86800249e-02, ...,\n",
      "           -1.62514094e-02,  -1.17644239e-02,  -1.04816426e-02],\n",
      "         [ -8.85943125e-04,  -3.55432718e-03,   2.16258802e-02, ...,\n",
      "            9.15401801e-03,  -1.28395390e-02,  -1.42216878e-02],\n",
      "         [  1.81506630e-02,   9.07026883e-03,  -2.00431999e-02, ...,\n",
      "           -9.12326295e-03,  -1.99350305e-02,  -1.20387413e-03],\n",
      "         ..., \n",
      "         [  2.03688256e-02,  -7.44103827e-03,   2.15424560e-02, ...,\n",
      "            1.25812821e-03,  -2.18864121e-02,   4.43045981e-04],\n",
      "         [  5.72874676e-03,  -1.32621992e-02,  -2.13797316e-02, ...,\n",
      "           -8.92904308e-03,  -7.75082642e-03,  -5.08447178e-03],\n",
      "         [ -3.33434320e-03,  -2.47959755e-02,   2.31439956e-02, ...,\n",
      "            2.77673826e-05,   4.00768034e-03,   3.80213838e-03]],\n",
      "\n",
      "        [[ -2.44138800e-02,  -1.93385184e-02,   7.42601184e-03, ...,\n",
      "           -8.28495715e-03,  -5.44669013e-03,  -1.53070968e-03],\n",
      "         [  2.26827096e-02,  -2.17696838e-03,   2.26264130e-02, ...,\n",
      "            5.46288863e-03,  -1.85725931e-02,  -1.91317946e-02],\n",
      "         [  1.39714200e-02,   7.35309441e-03,  -5.06319338e-03, ...,\n",
      "           -4.30274848e-03,  -1.17782596e-03,   3.65856988e-03],\n",
      "         ..., \n",
      "         [ -6.46171859e-03,   6.85377559e-03,   2.15002093e-02, ...,\n",
      "            1.96988229e-02,  -1.88263704e-03,   2.83155032e-03],\n",
      "         [ -3.69068747e-03,  -2.62591075e-02,  -1.77232996e-02, ...,\n",
      "           -4.13606735e-03,  -2.41950098e-02,  -1.01017915e-02],\n",
      "         [  7.06127519e-03,  -6.87400345e-03,   2.26647276e-02, ...,\n",
      "            1.27191693e-02,   2.05859393e-02,  -6.82337023e-03]],\n",
      "\n",
      "        ..., \n",
      "        [[  1.84602775e-02,  -7.37363193e-03,  -1.69822033e-02, ...,\n",
      "            5.90274530e-03,  -5.97125711e-03,  -1.85068082e-02],\n",
      "         [ -2.67299963e-03,   1.11187063e-02,   5.08708414e-03, ...,\n",
      "            1.56306699e-02,  -2.11337507e-02,  -2.41797138e-03],\n",
      "         [ -7.14155333e-03,   1.37342783e-02,  -4.49285880e-02, ...,\n",
      "           -2.52067428e-02,  -1.86981931e-02,  -2.62646843e-03],\n",
      "         ..., \n",
      "         [  1.80843789e-02,  -4.17049183e-03,   1.62288062e-02, ...,\n",
      "           -7.49606267e-03,  -1.31562343e-02,   2.23685429e-03],\n",
      "         [  1.82923011e-03,  -5.22824237e-04,   2.36612235e-04, ...,\n",
      "           -1.45502866e-03,  -7.14122504e-03,  -1.42367566e-02],\n",
      "         [  1.72676314e-02,  -9.82003659e-03,  -1.33891273e-02, ...,\n",
      "            2.27286108e-02,   1.60113256e-03,  -9.14434437e-03]],\n",
      "\n",
      "        [[  1.21723057e-03,  -4.83202981e-03,  -1.10711232e-02, ...,\n",
      "            1.37124201e-02,  -2.10663788e-02,  -2.14159153e-02],\n",
      "         [ -5.10298926e-03,   1.23674804e-02,   6.09038537e-03, ...,\n",
      "           -7.86742312e-04,  -2.42436640e-02,   1.76728703e-04],\n",
      "         [  1.76725388e-02,  -1.19661372e-02,  -3.99665870e-02, ...,\n",
      "           -1.75458379e-02,  -3.57112382e-03,   1.91935562e-02],\n",
      "         ..., \n",
      "         [  1.60562887e-03,   1.54169574e-02,   2.26647221e-02, ...,\n",
      "            1.80694573e-02,  -2.25535929e-02,  -7.33638182e-04],\n",
      "         [ -3.28521407e-03,  -2.47253175e-03,  -6.12081401e-03, ...,\n",
      "           -3.73002281e-03,  -2.46142242e-02,  -2.09166817e-02],\n",
      "         [  3.89262009e-03,  -7.93199055e-04,   1.50316563e-02, ...,\n",
      "            1.41130639e-02,   2.08451431e-02,  -5.36959246e-03]],\n",
      "\n",
      "        [[  1.73293017e-02,   1.36344612e-03,   3.09941359e-03, ...,\n",
      "           -3.06471772e-02,  -2.33651530e-02,  -2.08239071e-02],\n",
      "         [ -2.86460109e-03,   1.49399824e-02,   1.12970565e-02, ...,\n",
      "           -2.04682490e-03,  -2.14684606e-02,  -1.38918282e-02],\n",
      "         [  2.79913284e-02,  -3.31809570e-04,  -2.12575272e-02, ...,\n",
      "            2.31545512e-03,   1.06123695e-02,  -4.40583099e-03],\n",
      "         ..., \n",
      "         [  4.35589580e-03,  -9.00287926e-03,   1.74003802e-02, ...,\n",
      "           -6.65934756e-03,  -1.68929454e-02,   8.71780328e-04],\n",
      "         [ -4.24474105e-03,   1.34994397e-02,  -1.48921553e-02, ...,\n",
      "            4.38113371e-03,  -4.84458450e-03,  -3.39703425e-03],\n",
      "         [ -1.34643354e-02,  -4.15125489e-03,   2.75278674e-03, ...,\n",
      "            6.50284253e-03,   7.99940899e-04,  -1.29543841e-02]]],\n",
      "\n",
      "\n",
      "       [[[ -5.17831556e-03,  -2.11510491e-02,  -1.50261959e-02, ...,\n",
      "           -6.73880475e-03,  -1.93345789e-02,   3.02865077e-03],\n",
      "         [  4.00162069e-03,  -1.12045305e-02,   1.87963285e-02, ...,\n",
      "            3.39897908e-03,  -1.51493447e-02,  -1.43178375e-02],\n",
      "         [  1.27750672e-02,  -9.69247986e-03,  -1.18516665e-02, ...,\n",
      "           -1.06249424e-02,   9.01433546e-03,   1.28912060e-02],\n",
      "         ..., \n",
      "         [ -2.52575264e-03,  -3.50164785e-03,   1.98167060e-02, ...,\n",
      "            8.90114158e-03,  -8.63329135e-03,   4.60474100e-03],\n",
      "         [ -2.17696149e-02,  -2.67119706e-03,  -3.81083949e-03, ...,\n",
      "           -1.59758031e-02,  -1.33641828e-02,  -2.23934427e-02],\n",
      "         [  2.26276722e-02,  -2.14087684e-02,   7.06370501e-03, ...,\n",
      "            2.42919363e-02,  -2.00482737e-03,  -2.06821915e-02]],\n",
      "\n",
      "        [[ -8.09911173e-04,   1.33414641e-02,  -2.50842571e-02, ...,\n",
      "           -1.93047314e-03,  -1.38674304e-02,  -2.16815714e-03],\n",
      "         [  2.19158195e-02,  -1.62963010e-02,   1.90097615e-02, ...,\n",
      "            4.48397361e-04,  -1.05845816e-02,  -5.41663636e-03],\n",
      "         [  2.08205711e-02,   7.65416771e-03,  -2.27758288e-02, ...,\n",
      "           -4.85971496e-02,  -1.27715245e-02,  -9.54996143e-03],\n",
      "         ..., \n",
      "         [  2.17918307e-02,   4.74603102e-03,   1.92672550e-03, ...,\n",
      "            6.84009341e-04,  -6.27163146e-03,   3.88539117e-03],\n",
      "         [ -8.95839836e-03,  -5.68387844e-03,  -5.54832490e-03, ...,\n",
      "           -6.22615684e-03,  -1.38165886e-02,  -1.49438763e-02],\n",
      "         [  1.81268307e-03,  -2.32360046e-02,   2.04597339e-02, ...,\n",
      "            1.98865146e-03,  -2.14380398e-02,   2.09167693e-03]],\n",
      "\n",
      "        [[ -2.43593976e-02,   1.29013062e-02,  -7.37223309e-03, ...,\n",
      "            9.99291893e-04,  -3.46755900e-04,  -9.93433222e-03],\n",
      "         [  1.89044252e-02,   4.61604306e-03,   1.31539339e-02, ...,\n",
      "           -9.39340051e-03,  -8.70238710e-03,   2.92085577e-03],\n",
      "         [  2.30020918e-02,   5.11413440e-03,  -2.73784399e-02, ...,\n",
      "           -1.25218835e-02,  -5.17668435e-03,  -7.88840279e-03],\n",
      "         ..., \n",
      "         [ -4.10014112e-03,  -1.99594442e-03,   1.51356747e-02, ...,\n",
      "           -9.14067216e-03,  -1.05177052e-03,   2.13193521e-03],\n",
      "         [ -1.06478687e-02,  -1.14536034e-02,  -1.92304812e-02, ...,\n",
      "           -8.77505634e-03,  -1.21950749e-02,  -1.14740282e-02],\n",
      "         [ -1.36280721e-02,  -1.67585276e-02,   5.65317506e-03, ...,\n",
      "           -4.23039589e-03,   4.92626615e-03,   3.28344200e-03]],\n",
      "\n",
      "        ..., \n",
      "        [[ -1.67290941e-02,  -1.45723168e-02,  -1.96859669e-02, ...,\n",
      "            7.83081260e-03,  -8.82124528e-03,  -1.24683259e-02],\n",
      "         [  2.20530946e-02,  -1.87602025e-02,   2.01488715e-02, ...,\n",
      "            1.87299009e-02,   9.37809236e-04,   2.13742629e-03],\n",
      "         [  1.85793582e-02,   2.22035218e-03,  -6.07196987e-03, ...,\n",
      "           -4.61267726e-03,  -4.91091702e-03,   7.78385904e-03],\n",
      "         ..., \n",
      "         [ -7.66745815e-03,   9.58508719e-03,   1.05205784e-02, ...,\n",
      "            8.06630403e-03,  -1.81729086e-02,  -2.42214371e-02],\n",
      "         [ -2.35580411e-02,   1.14229359e-02,   2.77682650e-03, ...,\n",
      "           -5.65219671e-03,  -7.31299631e-04,  -4.76012845e-03],\n",
      "         [  2.24074423e-02,  -1.97692867e-02,   1.87564418e-02, ...,\n",
      "            9.83648002e-04,  -1.81599632e-02,  -7.44943507e-04]],\n",
      "\n",
      "        [[  6.75211567e-03,   1.12728903e-03,   1.08655402e-02, ...,\n",
      "            5.11568272e-03,   1.57100183e-03,  -2.15212181e-02],\n",
      "         [  4.74148430e-03,  -6.52594958e-03,   1.89872850e-02, ...,\n",
      "            1.77231375e-02,  -5.28939720e-03,  -1.88187100e-02],\n",
      "         [  2.64621135e-02,  -1.82921439e-03,  -1.65691059e-02, ...,\n",
      "            2.99849751e-04,   5.14915399e-03,  -3.85913905e-03],\n",
      "         ..., \n",
      "         [  1.51884872e-02,   7.16863805e-03,   1.71511248e-02, ...,\n",
      "           -5.76677779e-03,  -4.03521582e-04,  -7.60044344e-03],\n",
      "         [  1.08537439e-03,   6.59505313e-04,  -2.28889082e-02, ...,\n",
      "            3.47427092e-03,  -1.60279553e-02,   1.61494222e-03],\n",
      "         [  1.14727663e-02,  -1.97499469e-02,   2.06689239e-02, ...,\n",
      "            6.49214163e-03,   5.53505495e-04,  -1.95350461e-02]],\n",
      "\n",
      "        [[ -1.10776871e-02,  -2.57628295e-03,  -5.52634848e-03, ...,\n",
      "            9.21968743e-03,  -1.73073970e-02,  -1.84391215e-02],\n",
      "         [  9.28716268e-03,   1.26285208e-02,   2.35280227e-02, ...,\n",
      "           -3.44677316e-03,  -6.64185733e-04,  -1.92430019e-02],\n",
      "         [  2.13292446e-02,  -1.97382066e-02,   1.20648611e-02, ...,\n",
      "           -3.10476385e-02,   2.67764367e-03,  -1.09575288e-02],\n",
      "         ..., \n",
      "         [  9.42930765e-03,   6.00559078e-03,   6.41223835e-03, ...,\n",
      "            1.94193162e-02,  -1.65923145e-02,  -1.00601157e-02],\n",
      "         [ -9.29741003e-03,   1.46333976e-02,  -7.37176277e-03, ...,\n",
      "           -1.55836996e-02,  -1.19614871e-02,  -1.66810285e-02],\n",
      "         [ -1.40840616e-02,   5.18260244e-03,   6.88102888e-03, ...,\n",
      "           -6.92174211e-03,   2.28901617e-02,  -9.59743559e-03]]]], dtype=float32), array([-0.00985769, -0.00093653, -0.00988409,  0.01064522,  0.05840454,\n",
      "       -0.00870406, -0.01713728, -0.00869732, -0.01002786,  0.01321186,\n",
      "       -0.01005297, -0.00991817, -0.00990808, -0.00937297, -0.01173276,\n",
      "        0.04590558, -0.00947838, -0.01013783, -0.02818345,  0.07245488,\n",
      "        0.05485332, -0.00999172, -0.0081018 , -0.00943572, -0.01280127,\n",
      "       -0.01671367, -0.0095908 , -0.01327792, -0.00999999, -0.00999804,\n",
      "       -0.00999999, -0.0100635 ,  0.01196287, -0.00999999, -0.00132857,\n",
      "       -0.01972893, -0.02725526, -0.01195379, -0.00944745, -0.019458  ,\n",
      "        0.03932314, -0.01100624, -0.01951266, -0.01986097,  0.03971225,\n",
      "       -0.00610238, -0.00959738, -0.01604007, -0.01147869, -0.01001217,\n",
      "       -0.01675707, -0.01035534, -0.00994743,  0.06654684, -0.01006539,\n",
      "       -0.01179479, -0.07368577, -0.01917894, -0.00967764, -0.00954054,\n",
      "       -0.02007953, -0.01748211, -0.02514539, -0.01320647, -0.01323659,\n",
      "       -0.00999999, -0.0203772 ,  0.04301791, -0.00999996, -0.00535788,\n",
      "       -0.0212476 , -0.01014882, -0.0176877 ,  0.0687871 ,  0.05485787,\n",
      "       -0.01050025,  0.05133272, -0.00999576, -0.00912765, -0.01422627,\n",
      "       -0.02003355, -0.0099176 , -0.00984908, -0.01255653, -0.00957378,\n",
      "       -0.00864327, -0.01110849, -0.02243778, -0.02242001, -0.00983924,\n",
      "       -0.0197226 , -0.00995964, -0.01192174, -0.00990881, -0.0115209 ,\n",
      "       -0.00996971,  0.0572312 , -0.0090002 , -0.04306147,  0.05707628,\n",
      "       -0.03002979,  0.0040495 , -0.00997173, -0.00197854, -0.00927317,\n",
      "       -0.04960965, -0.01006919,  0.05392775, -0.01003873, -0.02395323,\n",
      "        0.07452886, -0.00999999, -0.00981502,  0.00767748, -0.00999998,\n",
      "       -0.01995269, -0.01994298, -0.00999998, -0.00048644, -0.00961209,\n",
      "        0.03447826, -0.00997818, -0.02570191, -0.00773289,  0.0174403 ,\n",
      "       -0.00979106, -0.03493859, -0.00999999, -0.04739595, -0.01005306,\n",
      "        0.03345367, -0.00930957, -0.00565262, -0.01240597,  0.04082673,\n",
      "        0.01884834, -0.01946096, -0.01034818, -0.0092527 , -0.00752575,\n",
      "       -0.01034405, -0.01532593, -0.00906207, -0.00978714, -0.00987599,\n",
      "       -0.00975879, -0.00987577,  0.05046766, -0.01644907, -0.01998485,\n",
      "       -0.01248534,  0.0217751 , -0.01949655,  0.04320221, -0.02047758,\n",
      "       -0.01794505, -0.0097965 ,  0.01384639, -0.01999919,  0.01770778,\n",
      "        0.03108348, -0.00887453,  0.01769403, -0.00499398, -0.01026384,\n",
      "       -0.01009842, -0.02370596,  0.01716004, -0.00983948, -0.01128954,\n",
      "       -0.00991337, -0.0097698 , -0.01023855, -0.01144742, -0.01852384,\n",
      "        0.00510579, -0.01821028, -0.01144196, -0.02081484, -0.00683512,\n",
      "       -0.02006807, -0.00944942, -0.00999672, -0.03655959, -0.01035418,\n",
      "       -0.00989469, -0.01217446, -0.00942461, -0.01781011, -0.00971406,\n",
      "       -0.00914231, -0.02635376, -0.00939431, -0.00961263, -0.00970854,\n",
      "       -0.01998873, -0.01804773, -0.02344817, -0.00978922, -0.00820438,\n",
      "       -0.01287717, -0.01002119, -0.09804959, -0.00751098, -0.02768445,\n",
      "       -0.00994984, -0.02037063, -0.01017078,  0.05237   , -0.01277371,\n",
      "       -0.01015388,  0.01517301, -0.02048804, -0.01135616, -0.00637442,\n",
      "       -0.01205322, -0.01026922, -0.01003387, -0.02055494, -0.00741052,\n",
      "       -0.00965057, -0.00967716, -0.00999995, -0.01001301, -0.00960247,\n",
      "       -0.02214458, -0.00994448, -0.0100103 , -0.01296192, -0.00999998,\n",
      "       -0.01483097, -0.00921615, -0.02187579,  0.02412545, -0.02345231,\n",
      "       -0.01072095, -0.0185783 , -0.00981839, -0.01010029, -0.00786014,\n",
      "        0.00015257, -0.01493276, -0.03699519, -0.01083423, -0.01196787,\n",
      "        0.02361497, -0.01837312, -0.00381484,  0.01428361, -0.03557321,\n",
      "       -0.02031036, -0.01178443,  0.00924878, -0.01057291,  0.03525363,\n",
      "       -0.00961124, -0.00986321, -0.00889698, -0.00799394, -0.0074017 ,\n",
      "       -0.00660196, -0.01032218, -0.0306678 , -0.00888269, -0.0030437 ,\n",
      "       -0.03600841,  0.03260323, -0.01941008, -0.0425192 , -0.00997766,\n",
      "        0.07149488,  0.04500875, -0.01521632, -0.00979512, -0.00999998,\n",
      "       -0.01074879, -0.00993292, -0.03120398, -0.01900967, -0.00706718,\n",
      "       -0.01016936, -0.00585939, -0.00993595, -0.01007991, -0.00990546,\n",
      "       -0.0107968 , -0.00990254, -0.02011929, -0.0076758 , -0.01371225,\n",
      "       -0.02004702,  0.01476857, -0.01021161,  0.04296696, -0.00435867,\n",
      "       -0.00977837, -0.02019178, -0.02157312,  0.04297737, -0.0299982 ,\n",
      "       -0.02019088, -0.02178399, -0.0128898 , -0.00592484, -0.00870348,\n",
      "       -0.01965038, -0.01097754, -0.010027  , -0.01546592, -0.01002046,\n",
      "       -0.01161046, -0.01397269, -0.06059635,  0.02394088, -0.00966835,\n",
      "       -0.01005869,  0.03619432,  0.01099013,  0.03077793, -0.00993187,\n",
      "       -0.01064761, -0.0098927 ,  0.00124746,  0.0432751 , -0.01236373,\n",
      "       -0.0101119 , -0.00983974,  0.02125663,  0.01575275, -0.02219146,\n",
      "       -0.00976934,  0.01463057, -0.00973733,  0.00590302, -0.00991212,\n",
      "       -0.03362499, -0.00140921, -0.01937568,  0.04818588, -0.00991437,\n",
      "       -0.00492163, -0.00638922, -0.02118798, -0.0100301 , -0.01008077,\n",
      "       -0.00991473, -0.01996207, -0.02902274, -0.00811446, -0.01913035,\n",
      "        0.01378919, -0.01029291, -0.01996157, -0.01006435, -0.04409661,\n",
      "       -0.0044248 , -0.02078714,  0.03358004, -0.01003192, -0.02145181,\n",
      "        0.05392798,  0.00085305, -0.00999998, -0.01      , -0.00985092,\n",
      "       -0.01029059, -0.0200122 , -0.00999999, -0.00951662, -0.01293028,\n",
      "       -0.00974197, -0.01821175,  0.03762794, -0.01014224, -0.01018154,\n",
      "        0.04484528, -0.05839899, -0.00983805, -0.01060901, -0.01481494,\n",
      "       -0.01011988, -0.01461099, -0.0108808 , -0.02007546, -0.00881663,\n",
      "       -0.00982327,  0.0467772 ,  0.02260739,  0.03514298, -0.02137188,\n",
      "       -0.00579322, -0.00989865, -0.01077879, -0.01040254, -0.02159971,\n",
      "        0.04741505, -0.00965684,  0.05268695, -0.00987338, -0.00976478,\n",
      "       -0.01960475, -0.01933457,  0.02618968, -0.00628469, -0.00986238,\n",
      "       -0.00996491,  0.05636626, -0.00823263, -0.0080537 ,  0.04891293,\n",
      "       -0.02055085, -0.00999012, -0.01544265, -0.01012718,  0.02793935,\n",
      "       -0.02238935, -0.02003616,  0.00347729,  0.05202119, -0.01888938,\n",
      "       -0.00995235, -0.01101165,  0.04169556, -0.00943703,  0.04008736,\n",
      "       -0.02000614, -0.01010149,  0.06083401,  0.04577165,  0.04739742,\n",
      "       -0.01059456, -0.01775999, -0.00999999,  0.06459717, -0.0104825 ,\n",
      "       -0.01129941, -0.02597851, -0.01173707, -0.00954724, -0.00381208,\n",
      "        0.03992135, -0.01329889, -0.0282486 , -0.02094932,  0.01962397,\n",
      "       -0.02065892, -0.01971696, -0.00965337, -0.07074088, -0.00527436,\n",
      "        0.00383457, -0.02036523, -0.00932164, -0.00986787,  0.01284345,\n",
      "        0.03093323, -0.01001392, -0.0191729 , -0.01875879, -0.00993359,\n",
      "       -0.05550284, -0.01042694, -0.02996838, -0.03313657, -0.02001427,\n",
      "        0.02127115, -0.01993373, -0.01024693, -0.02795616, -0.01782902,\n",
      "       -0.00999998, -0.00088805, -0.00896293, -0.01096032, -0.03840175,\n",
      "       -0.01021522, -0.00999999, -0.00991216, -0.00985028,  0.01606481,\n",
      "        0.0265687 ,  0.03704207, -0.02398136, -0.01484776, -0.00975276,\n",
      "       -0.0100671 , -0.02053385,  0.06638376,  0.05703092, -0.02008427,\n",
      "       -0.01135597,  0.01243929, -0.00790752,  0.00281071, -0.00993846,\n",
      "       -0.01071953, -0.0098068 , -0.01866799, -0.02148486, -0.01956956,\n",
      "       -0.00941254, -0.01066053, -0.01173541, -0.00889014, -0.01950082,\n",
      "       -0.0379598 ,  0.04551113, -0.00999999, -0.02294401, -0.01014165,\n",
      "       -0.01783124, -0.01050573], dtype=float32)]\n",
      "{'trainable': True, 'padding': 'valid', 'data_format': 'channels_first', 'name': 'max_pooling2d_2', 'pool_size': (2, 2), 'strides': (2, 2)}\n",
      "[]\n",
      "{'trainable': True, 'name': 'flatten_1'}\n",
      "[]\n",
      "{'units': 20, 'activation': 'relu', 'kernel_regularizer': None, 'name': 'dense_1', 'bias_regularizer': None, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'mode': 'fan_avg', 'scale': 1.0, 'seed': None, 'distribution': 'uniform'}}, 'trainable': True, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'use_bias': True, 'bias_constraint': None}\n",
      "[array([[-0.02297233, -0.00739837,  0.01423473, ..., -0.02173109,\n",
      "        -0.00735591,  0.00615666],\n",
      "       [-0.00311714,  0.00119114,  0.01105075, ..., -0.0197971 ,\n",
      "        -0.02189568,  0.00151175],\n",
      "       [-0.01781787,  0.00289817, -0.00059102, ..., -0.00078125,\n",
      "        -0.00683668,  0.00183707],\n",
      "       ..., \n",
      "       [-0.02207769, -0.02096259, -0.00072514, ..., -0.00435214,\n",
      "        -0.01205686,  0.01100961],\n",
      "       [-0.01505315, -0.01033089,  0.00972861, ..., -0.0148647 ,\n",
      "         0.00088263,  0.00089148],\n",
      "       [-0.01121318, -0.01765098,  0.00241148, ..., -0.02177021,\n",
      "        -0.00393047,  0.00785518]], dtype=float32), array([-0.00999999, -0.01      ,  0.05195576,  0.02814307, -0.00999987,\n",
      "       -0.00012348, -0.01      , -0.01      ,  0.02672255,  0.01786447,\n",
      "       -0.01      , -0.01      , -0.01      , -0.00999999,  0.05990238,\n",
      "       -0.00999972, -0.00999994, -0.00999995, -0.01      , -0.0116994 ], dtype=float32)]\n",
      "{'units': 10, 'activation': 'softmax', 'kernel_regularizer': None, 'name': 'dense_2', 'bias_regularizer': None, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'mode': 'fan_avg', 'scale': 1.0, 'seed': None, 'distribution': 'uniform'}}, 'trainable': True, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'use_bias': True, 'bias_constraint': None}\n",
      "[array([[ 0.17710237, -0.33860609, -0.2901538 , -0.40598962, -0.14767975,\n",
      "         0.35373905,  0.20828243,  0.22993633, -0.204074  ,  0.07849625],\n",
      "       [-0.19729443,  0.31881425,  0.21629411,  0.36240488, -0.15065692,\n",
      "         0.22855969, -0.45467469,  0.29550451,  0.16371295,  0.36649102],\n",
      "       [-0.28758198,  0.1261256 ,  0.21481803,  0.22168563, -0.2035585 ,\n",
      "        -0.34455812, -0.27817237, -0.07145005, -0.09126244, -0.23096947],\n",
      "       [ 0.09787087, -0.34448558,  0.48650324, -0.08446407,  0.4169963 ,\n",
      "        -0.1272555 , -0.32635209, -0.0213558 ,  0.53361183,  0.49295279],\n",
      "       [ 0.03096241,  0.19740827,  0.31538832, -0.1763393 , -0.01439453,\n",
      "        -0.12780006,  0.20655368,  0.27635375,  0.17945506, -0.12527479],\n",
      "       [-0.33287925,  0.28839105,  0.19543596, -0.22757675,  0.23963474,\n",
      "        -0.38886583,  0.17628706,  0.41701862, -0.3843146 , -0.17949298],\n",
      "       [-0.25301173,  0.19792628,  0.15923969,  0.19613308,  0.30163902,\n",
      "         0.39157221, -0.19024961,  0.1786626 ,  0.33582228,  0.08519071],\n",
      "       [-0.29527575, -0.07957857, -0.20595753,  0.34976402,  0.13601449,\n",
      "        -0.00746999, -0.29022676, -0.12179789, -0.41759399,  0.21830973],\n",
      "       [ 0.30274686, -0.20105259, -0.59323466,  0.29427269, -0.29490039,\n",
      "         0.55286944, -0.28725195,  0.24221037, -0.28982615,  0.35232335],\n",
      "       [-0.03256913,  0.28213525, -0.23717265, -0.52623236,  0.27387488,\n",
      "         0.30650473,  0.46335313,  0.19826666, -0.00991359, -0.43639162],\n",
      "       [-0.09113058,  0.17410272,  0.4135493 ,  0.33665535, -0.0122987 ,\n",
      "         0.16584493,  0.07168171, -0.45258901,  0.15436116,  0.25304037],\n",
      "       [-0.32759339,  0.14908864, -0.09279149, -0.16762255, -0.06025604,\n",
      "         0.08467264, -0.13093653,  0.02124535, -0.07499734,  0.19253534],\n",
      "       [-0.310004  , -0.43441272, -0.13023743, -0.21843134, -0.29928747,\n",
      "        -0.05743333,  0.19517715,  0.39336309,  0.1200624 ,  0.24661186],\n",
      "       [-0.42331019, -0.18299614, -0.43227288,  0.45621377,  0.05065488,\n",
      "         0.20563494,  0.33415726, -0.24451096,  0.34740284,  0.3801443 ],\n",
      "       [ 0.54231775, -0.19522005, -0.31625623, -0.24748141, -0.44744074,\n",
      "        -0.45706701,  0.51492703, -0.55109847, -0.33917379, -0.19585708],\n",
      "       [ 0.31663692, -0.29015857,  0.32729453, -0.01554084,  0.00499639,\n",
      "         0.0329196 , -0.04643379, -0.21873374,  0.34076723,  0.31488463],\n",
      "       [ 0.02065395,  0.23711321, -0.13500109,  0.28483394, -0.32753545,\n",
      "        -0.16129626, -0.03259166,  0.37551633,  0.06462947, -0.01272663],\n",
      "       [-0.24738142,  0.39044777, -0.07481696, -0.43391931,  0.34475362,\n",
      "        -0.13567911,  0.3880966 , -0.16680382,  0.0492267 ,  0.0979588 ],\n",
      "       [-0.40645388, -0.34446323, -0.41754043,  0.01258677, -0.22320648,\n",
      "        -0.01196727, -0.05071785,  0.0375379 , -0.09379337, -0.08339044],\n",
      "       [ 0.21351647, -0.04600873,  0.16362429, -0.27801332,  0.14061181,\n",
      "         0.31125286, -0.30285648,  0.1847567 , -0.30133492,  0.39075732]], dtype=float32), array([-0.19583613,  0.11254504, -0.05712004,  0.13667458, -0.05326834,\n",
      "        0.22990303,  0.07442048,  0.01705999,  0.08815906,  0.17721176], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(16, 5, 5, border_mode='same', activation='relu', input_shape=(3, 32, 32)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(512, 7, 7, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adagrad', metrics=['accuracy'])\n",
    "adagrad = Adagrad(lr=0.01, epsilon=1e-08, decay=0.0)\n",
    "model.fit(X_train, Y_train, batch_size=400, nb_epoch=8, verbose=1, \\\n",
    "            validation_data=(X_test, Y_test))\n",
    "weights = model.get_weights()\n",
    "for layer in model.layers:\n",
    "    g=layer.get_config()\n",
    "    h=layer.get_weights()\n",
    "    print (g)\n",
    "    print (h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (5, 5), activation=\"relu\", padding=\"same\", input_shape=(3, 32, 32...)`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (7, 7), activation=\"relu\", padding=\"same\")`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 16, 32, 32)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 512, 16, 16)       401920    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 512, 8, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                655380    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 1,058,726\n",
      "Trainable params: 1,058,726\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73257 samples, validate on 26032 samples\n",
      "Epoch 1/2\n",
      "73257/73257 [==============================] - 148s - loss: 2.0024 - acc: 0.3146 - val_loss: 1.5194 - val_acc: 0.4857\n",
      "Epoch 2/2\n",
      "73257/73257 [==============================] - 148s - loss: 1.2582 - acc: 0.5831 - val_loss: 1.0894 - val_acc: 0.6722\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(16, 5, 5, border_mode='same', activation='relu', input_shape=(3, 32, 32)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(512, 7, 7, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adagrad', metrics=['accuracy'])\n",
    "adagrad = Adagrad(lr=0.01, epsilon=1e-08, decay=0.0)\n",
    "model.fit(X_train, Y_train, batch_size=100, nb_epoch=2, verbose=1, \\\n",
    "            validation_data=(X_test, Y_test))\n",
    "inp = model.input    \n",
    "outputs = [layer.output for layer in model.layers]\n",
    "for out in outputs:\n",
    "    functors = [K.function([inp]+ [K.learning_phase()], [out]) ]  # evaluation functions\n",
    "\n",
    "layer_outs = [func([X_test, 1.]) for func in functors]\n",
    "print(layer_outs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<p>Elija una de las redes entrenadas en esta sección y determine los pares de dígitos (por ejemplo 1 con\n",
    "7) que la red tiende a confundir. Conjeture el motivo de tal confusión.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(16, (5, 5), activation=\"relu\", input_shape=(3, 32, 32..., padding=\"same\")`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (7, 7), activation=\"relu\", padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 16, 32, 32)        1216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 512, 16, 16)       401920    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 512, 8, 8)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                655380    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 1,058,726\n",
      "Trainable params: 1,058,726\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 73257 samples, validate on 26032 samples\n",
      "Epoch 1/2\n",
      "73257/73257 [==============================] - 150s - loss: 1.9990 - acc: 0.3309 - val_loss: 1.4594 - val_acc: 0.4579\n",
      "Epoch 2/2\n",
      "73257/73257 [==============================] - 147s - loss: 1.3159 - acc: 0.5264 - val_loss: 1.1633 - val_acc: 0.6001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[16,3,5,5]\n\t [[Node: conv2d_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](conv2d_1/transpose, conv2d_1/kernel/read)]]\n\t [[Node: dense_2/Softmax/_55 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_88_dense_2/Softmax\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'conv2d_1/convolution', defined at:\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-e7fa661593cc>\", line 7, in <module>\n    model.add(Convolution2D(16, 5, 5, border_mode='same', activation='relu', input_shape=(3, 32, 32)))\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\", line 433, in add\n    layer(x)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\topology.py\", line 585, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 164, in call\n    dilation_rate=self.dilation_rate)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3095, in conv2d\n    data_format='NHWC')\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 639, in convolution\n    op=op)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 308, in with_space_to_batch\n    return op(input, num_spatial_dims, padding)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 631, in op\n    name=name)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 129, in _non_atrous_convolution\n    name=name)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 396, in conv2d\n    data_format=data_format, name=name)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2327, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1226, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[16,3,5,5]\n\t [[Node: conv2d_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](conv2d_1/transpose, conv2d_1/kernel/read)]]\n\t [[Node: dense_2/Softmax/_55 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_88_dense_2/Softmax\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32mD:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[16,3,5,5]\n\t [[Node: conv2d_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](conv2d_1/transpose, conv2d_1/kernel/read)]]\n\t [[Node: dense_2/Softmax/_55 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_88_dense_2/Softmax\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e7fa661593cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mfunctors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m  \u001b[1;31m# evaluation functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mlayer_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfunctors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-e7fa661593cc>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mfunctors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m]\u001b[0m  \u001b[1;31m# evaluation functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mlayer_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfunctors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m-> 2229\u001b[1;33m                               feed_dict=feed_dict)\n\u001b[0m\u001b[0;32m   2230\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 767\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 965\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1015\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mD:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1033\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1035\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1036\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1037\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[16,3,5,5]\n\t [[Node: conv2d_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](conv2d_1/transpose, conv2d_1/kernel/read)]]\n\t [[Node: dense_2/Softmax/_55 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_88_dense_2/Softmax\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'conv2d_1/convolution', defined at:\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-e7fa661593cc>\", line 7, in <module>\n    model.add(Convolution2D(16, 5, 5, border_mode='same', activation='relu', input_shape=(3, 32, 32)))\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\", line 433, in add\n    layer(x)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\topology.py\", line 585, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 164, in call\n    dilation_rate=self.dilation_rate)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3095, in conv2d\n    data_format='NHWC')\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 639, in convolution\n    op=op)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 308, in with_space_to_batch\n    return op(input, num_spatial_dims, padding)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 631, in op\n    name=name)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 129, in _non_atrous_convolution\n    name=name)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 396, in conv2d\n    data_format=data_format, name=name)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 763, in apply_op\n    op_def=op_def)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2327, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1226, in __init__\n    self._traceback = _extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[16,3,5,5]\n\t [[Node: conv2d_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](conv2d_1/transpose, conv2d_1/kernel/read)]]\n\t [[Node: dense_2/Softmax/_55 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_88_dense_2/Softmax\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.optimizers import SGD, Adadelta, Adagrad\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(16, 5, 5, border_mode='same', activation='relu', input_shape=(3, 32, 32)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Convolution2D(512, 7, 7, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adagrad', metrics=['accuracy'])\n",
    "adagrad = Adagrad(lr=0.01, epsilon=1e-08, decay=0.0)\n",
    "model.fit(X_train, Y_train, batch_size=100, nb_epoch=2, verbose=1, \\\n",
    "            validation_data=(X_test, Y_test))\n",
    "inp = model.input    \n",
    "outputs = [layer.output for layer in model.layers]\n",
    "for out in outputs:\n",
    "    functors = [K.function([inp]+ [K.learning_phase()], [out]) ]  # evaluation functions\n",
    "\n",
    "layer_outs = [func([X_test, 1.]) for func in functors]\n",
    "print(layer_outs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
