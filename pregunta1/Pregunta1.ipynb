{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Prepare subconjuntos de entrenamiento, validaci´on y pruebas id´enticos a los que utiliz´o en el ´ultimo\n",
    "´ıtem de la tarea 1. Normalice las im´agenes de entrenamiento y pruebas, dividiendo las intensidades\n",
    "originales de pixel en cada canal por 255. Es importante recordar que en la tarea1 representamos las\n",
    "im´agenes como un vector unidimensional. Por lo tanto, antes de trabajar con CNNs ser´a necesario\n",
    "recuperar la forma original de las im´agenes. Adem´as, si desea trabajar con el orden de las dimensiones\n",
    "denominado ’tf’ (por defecto para TensorFlow†) deber´a hacer realizar la transposici´on correspondiente.\n",
    "Finalmente, genere una representaci´on adecuada de las salidas deseadas de la red.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.misc import imread\n",
    "import sys\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "sys.getdefaultencoding()\n",
    "\n",
    "def unpickle(file):\n",
    "    import cPickle\n",
    "    fo = open(file, rb)\n",
    "    dict = cPickle.load(fo)\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "label_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "\n",
    "\n",
    "def load_CIFAR_one(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        datadict = pickle.load(f, encoding='latin1')\n",
    "        X = datadict['data']\n",
    "        Y = datadict['labels']\n",
    "        Y = np.array(Y)\n",
    "    return X, Y\n",
    "\n",
    "def load_CIFAR10(PATH):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for b in range(1,6):\n",
    "        f = os.path.join(PATH, 'data_batch_%d' % (b, ))\n",
    "        X, Y = load_CIFAR_one(f)\n",
    "        xs.append(X)\n",
    "        ys.append(Y)\n",
    "    Xtr = np.concatenate(xs)\n",
    "    Ytr = np.concatenate(ys)\n",
    "    del X, Y\n",
    "    Xte, Yte = load_CIFAR_one(os.path.join(PATH, 'test_batch'))\n",
    "    return Xtr, Ytr, Xte, Yte\n",
    "\n",
    "x_train, y_train, x_test, y_test = load_CIFAR10(\"datasets/\")\n",
    "num_classes = len(np.unique(y_train))\n",
    "x_train = x_train.reshape((x_train.shape[0],3,32,32))\n",
    "\n",
    "x_test= x_test.reshape((x_test.shape[0],3,32,32))\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>B) Defina una CNN con arquitectura C × P × C × P × F × F. Para ambas capas convolucionales utilice\n",
    "64 filtros de 3 × 3 y funciones de activaci´on ReLu. Para las capas de pooling utilice filtros de 2 × 2 con\n",
    "stride 2. Para la capa MLP escondida use 512 neuronas. Genere un esquema lo m´as compacto posible\n",
    "que muestre los cambios de forma (dimensionalidad) que experimenta un patr´on de entrada a medida\n",
    "que se ejecuta un forward-pass y el n´umero de par´ametros de cada capa.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3, 32, 32)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 64, 32, 32)        1792      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 64, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 16, 16)        36928     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 64, 8, 8)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,141,514\n",
      "Trainable params: 2,141,514\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", input_shape=(3, 32, 32...)`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:9: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\")`\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "print(x_train.shape)\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', input_shape=(3,32,32)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\"))\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<p>C) Entrene la CNN definida en (b) utilizando SGD. En este dataset, una tasa de aprendizaje \\segura\"\n",
    "es \u0011 = 10􀀀4 o inferior, pero durante las primeras \\epochs\" el entrenamiento resulta demasiado lento.\n",
    "Para resolver el problema aprenderemos a controlar la tasa de aprendizaje utilizada en el entrenamiento.\n",
    "Implemente la siguiente idea: deseamos partir con una tasa de aprendizaje \u0011 = 10􀀀3 y dividir por 2\n",
    "ese valor cada 10 epochs. Suponga adem\u0013as que no queremos usar una tasa de aprendizaje menor a\n",
    "\u0011 = 10􀀀5. De\f",
    "na esta regla de ajuste para \u0011 y entrene la CNN de\f",
    "nida en (a) durante 25 epochs.\n",
    "Construya un gr\u0013a\f",
    "co que muestre los errores de entrenamiento, validaci\u0013on y pruebas como funci\u0013on del\n",
    "n\u0013umero de \\epochs\".</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function step_decay at 0x00000138A0AC1620>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 38s - loss: 2.2701 - acc: 0.1605 - val_loss: 2.2264 - val_acc: 0.2220\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 38s - loss: 2.1489 - acc: 0.2550 - val_loss: 2.0517 - val_acc: 0.2754\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.9965 - acc: 0.2951 - val_loss: 1.9492 - val_acc: 0.3179\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.9285 - acc: 0.3207 - val_loss: 1.8991 - val_acc: 0.3318\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 38s - loss: 1.8870 - acc: 0.3428 - val_loss: 1.8685 - val_acc: 0.3502\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 38s - loss: 1.8593 - acc: 0.3528 - val_loss: 1.8402 - val_acc: 0.3654\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 38s - loss: 1.8324 - acc: 0.3653 - val_loss: 1.8135 - val_acc: 0.3729\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 38s - loss: 1.8060 - acc: 0.3746 - val_loss: 1.7892 - val_acc: 0.3804\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.7784 - acc: 0.3844 - val_loss: 1.7615 - val_acc: 0.3931\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.7541 - acc: 0.3923 - val_loss: 1.7413 - val_acc: 0.3990\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.7395 - acc: 0.3981 - val_loss: 1.7315 - val_acc: 0.3982\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.7259 - acc: 0.4031 - val_loss: 1.7157 - val_acc: 0.4097\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.7118 - acc: 0.4078 - val_loss: 1.7003 - val_acc: 0.4112\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.6979 - acc: 0.4125 - val_loss: 1.6892 - val_acc: 0.4141\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.6856 - acc: 0.4177 - val_loss: 1.6783 - val_acc: 0.4202\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.6784 - acc: 0.4198 - val_loss: 1.6715 - val_acc: 0.4236\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.6713 - acc: 0.4230 - val_loss: 1.6645 - val_acc: 0.4279\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.6648 - acc: 0.4257 - val_loss: 1.6575 - val_acc: 0.4279\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.6574 - acc: 0.4272 - val_loss: 1.6499 - val_acc: 0.4302\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.6512 - acc: 0.4310 - val_loss: 1.6456 - val_acc: 0.4307\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.6476 - acc: 0.4329 - val_loss: 1.6423 - val_acc: 0.4321\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.6446 - acc: 0.4324 - val_loss: 1.6390 - val_acc: 0.4345\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.6411 - acc: 0.4339 - val_loss: 1.6359 - val_acc: 0.4328\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.6376 - acc: 0.4356 - val_loss: 1.6331 - val_acc: 0.4318\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.6347 - acc: 0.4359 - val_loss: 1.6301 - val_acc: 0.4368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x138a12b1fd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import SGD, rmsprop\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    lrate = initial_lrate * math.pow(0.5, math.floor((1+epoch)/5))\n",
    "    lrate = max(lrate,0.00001)\n",
    "    return lrate\n",
    "opt = SGD(lr=0.0, momentum=0.9, decay=0.0)\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt, metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,batch_size=400, nb_epoch=25,\n",
    "    validation_data=(x_test, y_test),shuffle=True,callbacks=[lrate])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 41s - loss: 2.2825 - acc: 0.1425 - val_loss: 2.2515 - val_acc: 0.1995\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 37s - loss: 2.2002 - acc: 0.2180 - val_loss: 2.1387 - val_acc: 0.2425\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 37s - loss: 2.0766 - acc: 0.2703 - val_loss: 2.0125 - val_acc: 0.3110\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.9653 - acc: 0.3119 - val_loss: 1.9202 - val_acc: 0.3258\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.9041 - acc: 0.3357 - val_loss: 1.8843 - val_acc: 0.3394\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.8753 - acc: 0.3481 - val_loss: 1.8626 - val_acc: 0.3509\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.8481 - acc: 0.3596 - val_loss: 1.8318 - val_acc: 0.3633\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.8218 - acc: 0.3690 - val_loss: 1.8052 - val_acc: 0.3775\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.7967 - acc: 0.3778 - val_loss: 1.7814 - val_acc: 0.3880\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 40s - loss: 1.7739 - acc: 0.3859 - val_loss: 1.7682 - val_acc: 0.3903\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.7595 - acc: 0.3917 - val_loss: 1.7510 - val_acc: 0.3990\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 40s - loss: 1.7458 - acc: 0.3965 - val_loss: 1.7400 - val_acc: 0.4002\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 39s - loss: 1.7334 - acc: 0.4025 - val_loss: 1.7252 - val_acc: 0.4057\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.7204 - acc: 0.4065 - val_loss: 1.7166 - val_acc: 0.4083\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 40s - loss: 1.7077 - acc: 0.4120 - val_loss: 1.7059 - val_acc: 0.4109\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 42s - loss: 1.7009 - acc: 0.4159 - val_loss: 1.6968 - val_acc: 0.4172\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.6935 - acc: 0.4158 - val_loss: 1.6903 - val_acc: 0.4167\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.6867 - acc: 0.4180 - val_loss: 1.6841 - val_acc: 0.4221\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 40s - loss: 1.6809 - acc: 0.4205 - val_loss: 1.6789 - val_acc: 0.4238\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 40s - loss: 1.6740 - acc: 0.4237 - val_loss: 1.6730 - val_acc: 0.4243\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 40s - loss: 1.6702 - acc: 0.4248 - val_loss: 1.6698 - val_acc: 0.4254\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.6670 - acc: 0.4257 - val_loss: 1.6657 - val_acc: 0.4280\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.6639 - acc: 0.4266 - val_loss: 1.6625 - val_acc: 0.4260\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.6606 - acc: 0.4278 - val_loss: 1.6594 - val_acc: 0.4290\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.6573 - acc: 0.4294 - val_loss: 1.6572 - val_acc: 0.4286\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD, rmsprop\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append([logs.get('acc'), logs.get('acc')])\n",
    "        \n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.001\n",
    "    lrate = initial_lrate * math.pow(0.5, math.floor((1+epoch)/5))\n",
    "    lrate = max(lrate,0.00001)\n",
    "    return lrate\n",
    "\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "opt = SGD(lr=0.0, momentum=0.9, decay=0.0)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt, metrics=['accuracy'])\n",
    "history_callback = model.fit(x_train, y_train,batch_size=400, nb_epoch=25, validation_data=(x_test, y_test),shuffle=True,callbacks=[lrate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a68d6bf630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = list(range(1,26))\n",
    "print(epochs)\n",
    "train_accuracy = history_callback.history[\"acc\"]\n",
    "validation_accyracy = history_callback.history[\"val_acc\"]\n",
    "plt.plot(epochs, train_accuracy )\n",
    "plt.plot( epochs, validation_accyracy )\n",
    "plt.legend( [\"training acc\", \"validation acc\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>D) Entrene la CNN de\f",
    "nida en (b) utilizando RMSProp durante 25 epochs. Elija la funci\u0013on de p\u0013erdida\n",
    "m\u0013as apropiada para este problema. Construya \f",
    "nalmente un gr\u0013a\f",
    "co que muestre los errores de entrenamiento,\n",
    "validaci\u0013on y pruebas como funci\u0013on del n\u0013umero de \\epochs\".</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 37s - loss: 1.6327 - acc: 0.4233 - val_loss: 1.3168 - val_acc: 0.5222\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 34s - loss: 1.1432 - acc: 0.5989 - val_loss: 1.0470 - val_acc: 0.6226\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 34s - loss: 0.9487 - acc: 0.6705 - val_loss: 0.9385 - val_acc: 0.6732\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 34s - loss: 0.8138 - acc: 0.7190 - val_loss: 1.0125 - val_acc: 0.6444\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 34s - loss: 0.6875 - acc: 0.7604 - val_loss: 0.9563 - val_acc: 0.6812\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 36s - loss: 0.5697 - acc: 0.8024 - val_loss: 0.9496 - val_acc: 0.6916\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 34s - loss: 0.4570 - acc: 0.8428 - val_loss: 0.9229 - val_acc: 0.7054\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 34s - loss: 0.3575 - acc: 0.8785 - val_loss: 0.9306 - val_acc: 0.7190\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 34s - loss: 0.2653 - acc: 0.9112 - val_loss: 0.9627 - val_acc: 0.7261\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 34s - loss: 0.1868 - acc: 0.9376 - val_loss: 1.1891 - val_acc: 0.7091\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 34s - loss: 0.1358 - acc: 0.9566 - val_loss: 1.2754 - val_acc: 0.7182\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 34s - loss: 0.0977 - acc: 0.9684 - val_loss: 1.5135 - val_acc: 0.6968\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 34s - loss: 0.0729 - acc: 0.9762 - val_loss: 1.9575 - val_acc: 0.6700\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 34s - loss: 0.0619 - acc: 0.9815 - val_loss: 1.5271 - val_acc: 0.7198\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 34s - loss: 0.0490 - acc: 0.9847 - val_loss: 1.8025 - val_acc: 0.6917\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 34s - loss: 0.0428 - acc: 0.9863 - val_loss: 1.8429 - val_acc: 0.7014\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 34s - loss: 0.0385 - acc: 0.9880 - val_loss: 1.7323 - val_acc: 0.7340\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 36s - loss: 0.0349 - acc: 0.9884 - val_loss: 1.9007 - val_acc: 0.7153\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 35s - loss: 0.0303 - acc: 0.9905 - val_loss: 2.0489 - val_acc: 0.7125\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 35s - loss: 0.0311 - acc: 0.9898 - val_loss: 2.0067 - val_acc: 0.7233\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 34s - loss: 0.0308 - acc: 0.9903 - val_loss: 2.0649 - val_acc: 0.7185\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 34s - loss: 0.0286 - acc: 0.9906 - val_loss: 2.0349 - val_acc: 0.7173\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 37s - loss: 0.0271 - acc: 0.9914 - val_loss: 2.0826 - val_acc: 0.7299\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 34s - loss: 0.0225 - acc: 0.9929 - val_loss: 2.2095 - val_acc: 0.7145\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 34s - loss: 0.0242 - acc: 0.9920 - val_loss: 2.1419 - val_acc: 0.7232\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD, rmsprop\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "from keras.optimizers import SGD, rmsprop\n",
    "opt = rmsprop(lr=0.001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt, metrics=['accuracy'])\n",
    "history_callback = model.fit(x_train, y_train,batch_size=150,nb_epoch=25,\n",
    "validation_data=(x_test, y_test),shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = list(range(1,26))\n",
    "print(epochs)\n",
    "train_accuracy = history_callback.history[\"acc\"]\n",
    "validation_accyracy = history_callback.history[\"val_acc\"]\n",
    "plt.plot(epochs, train_accuracy )\n",
    "plt.plot( epochs, validation_accyracy )\n",
    "plt.legend( [\"training acc\", \"validation acc\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Se aprecia que el gráfico obtenido entrega errores de validación muy altos, mientras que el error de entrenamiento es casi cero<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>E) Se ha sugerido que la pr\u0013actica bastante habitual de continuar una capa convolucional con una capa de\n",
    "pooling puede generar una reducci\u0013on prematura de las dimensiones del patr\u0013on de entrada. Experimente\n",
    "con una arquitectura del tipo C \u0002C \u0002P \u0002C \u0002C \u0002P \u0002F \u0002F. Use 64 \f",
    "ltros para las primeras 2 capas\n",
    "convolucionales y 128 para las \u0013ultimas dos. Reflexione sobre qu\u0013e le parece m\u0013as sensato: >mantener el\n",
    "tama~no de los \f",
    "ltros usados anteriormente? o >usar \f",
    "ltros m\u0013as grandes en la segunda capa convolucional\n",
    "y m\u0013as peque~nos en la primera? o >usar \f",
    "ltros m\u0013as peque~nos en la segunda capa convolucional y m\u0013as\n",
    "grandes en la primera? Hint: con esta nueva arquitectura debiese superar el 70% de accuracy (de\n",
    "validaci\u0013on/test) antes de 5 epochs, pero la arquitectura es m\u0013as sensible a over\f",
    "tting por lo que podr\u0013\u0010a\n",
    "ser conveniente agregar un regularizador. Como resultado \f",
    "nal de esta actividad gr\u0013a\f",
    "cque los errores\n",
    "de entrenamiento, validaci\u0013on y pruebas como funci\u0013on del n\u0013umero de \\epochs\" (\f",
    "jando el m\u0013aximo en\n",
    "un n\u0013umero razonable como T = 25).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 64, 32, 32)        1792      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 32, 32)        36928     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 64, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 128, 16, 16)       73856     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 128, 8, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 128, 8, 8)         147584    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 128, 8, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 128, 4, 4)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,314,378\n",
      "Trainable params: 1,314,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", input_shape=(3, 32, 32...)`\n",
      "  from ipykernel import kernelapp as app\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\")`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\")`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:10: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\")`\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', input_shape=(3,32,32)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\"))\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 78s - loss: 1.7208 - acc: 0.3797 - val_loss: 1.4518 - val_acc: 0.4950\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 75s - loss: 1.1569 - acc: 0.5904 - val_loss: 1.0835 - val_acc: 0.6171\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 75s - loss: 0.8905 - acc: 0.6881 - val_loss: 0.9400 - val_acc: 0.6744\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 78s - loss: 0.7242 - acc: 0.7468 - val_loss: 0.8419 - val_acc: 0.7193\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 78s - loss: 0.5976 - acc: 0.7916 - val_loss: 0.8540 - val_acc: 0.7205\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 78s - loss: 0.4886 - acc: 0.8307 - val_loss: 0.8197 - val_acc: 0.7436\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 75s - loss: 0.3863 - acc: 0.8652 - val_loss: 1.3841 - val_acc: 0.6633\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 80s - loss: 0.2985 - acc: 0.8954 - val_loss: 0.9636 - val_acc: 0.7393\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 75s - loss: 0.2343 - acc: 0.9182 - val_loss: 1.0093 - val_acc: 0.7477\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 75s - loss: 0.1859 - acc: 0.9349 - val_loss: 0.9676 - val_acc: 0.7557\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 75s - loss: 0.1486 - acc: 0.9500 - val_loss: 1.0375 - val_acc: 0.7798\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 75s - loss: 0.1289 - acc: 0.9557 - val_loss: 1.1656 - val_acc: 0.7721\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 77s - loss: 0.1115 - acc: 0.9616 - val_loss: 1.2561 - val_acc: 0.7624\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 75s - loss: 0.0982 - acc: 0.9662 - val_loss: 1.1745 - val_acc: 0.7815\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 75s - loss: 0.0970 - acc: 0.9681 - val_loss: 1.3919 - val_acc: 0.7591\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 78s - loss: 0.0883 - acc: 0.9713 - val_loss: 1.4214 - val_acc: 0.7745\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 75s - loss: 0.0867 - acc: 0.9717 - val_loss: 1.4147 - val_acc: 0.7728\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 75s - loss: 0.0853 - acc: 0.9732 - val_loss: 2.0204 - val_acc: 0.7416\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 75s - loss: 0.0798 - acc: 0.9756 - val_loss: 1.6519 - val_acc: 0.7133\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 75s - loss: 0.0831 - acc: 0.9741 - val_loss: 1.4994 - val_acc: 0.7771\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 75s - loss: 0.0754 - acc: 0.9769 - val_loss: 1.8949 - val_acc: 0.7627\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 75s - loss: 0.0769 - acc: 0.9754 - val_loss: 1.6668 - val_acc: 0.7659\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 77s - loss: 0.0746 - acc: 0.9775 - val_loss: 1.8847 - val_acc: 0.7549\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 75s - loss: 0.0734 - acc: 0.9783 - val_loss: 1.6542 - val_acc: 0.7833\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 75s - loss: 0.0722 - acc: 0.9790 - val_loss: 1.7904 - val_acc: 0.7379\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD, rmsprop\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "from keras.optimizers import SGD, rmsprop\n",
    "opt = rmsprop(lr=0.001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt, metrics=['accuracy'])\n",
    "history_callback = model.fit(x_train, y_train,batch_size=150,nb_epoch=25,\n",
    "validation_data=(x_test, y_test),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", input_shape=(3, 32, 32...)`\n",
      "  from ipykernel import kernelapp as app\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\")`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\")`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:10: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 64, 32, 32)        1792      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 64, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 64, 32, 32)        36928     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 64, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 64, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 128, 16, 16)       73856     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 128, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 128, 8, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 128, 8, 8)         147584    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 128, 8, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 128, 4, 4)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,314,378\n",
      "Trainable params: 1,314,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "50000/50000 [==============================] - 79s - loss: 1.7475 - acc: 0.3734 - val_loss: 1.2778 - val_acc: 0.5405\n",
      "Epoch 2/8\n",
      "50000/50000 [==============================] - 75s - loss: 1.1539 - acc: 0.5938 - val_loss: 1.0769 - val_acc: 0.6114\n",
      "Epoch 3/8\n",
      "50000/50000 [==============================] - 78s - loss: 0.8923 - acc: 0.6894 - val_loss: 0.8839 - val_acc: 0.6951\n",
      "Epoch 4/8\n",
      "50000/50000 [==============================] - 75s - loss: 0.7204 - acc: 0.7486 - val_loss: 1.0588 - val_acc: 0.6525\n",
      "Epoch 5/8\n",
      "50000/50000 [==============================] - 81s - loss: 0.5887 - acc: 0.7963 - val_loss: 0.7971 - val_acc: 0.7378\n",
      "Epoch 6/8\n",
      "50000/50000 [==============================] - 77s - loss: 0.4803 - acc: 0.8317 - val_loss: 0.7975 - val_acc: 0.7274\n",
      "Epoch 7/8\n",
      "50000/50000 [==============================] - 75s - loss: 0.3888 - acc: 0.8627 - val_loss: 0.9349 - val_acc: 0.7428\n",
      "Epoch 8/8\n",
      "50000/50000 [==============================] - 80s - loss: 0.3013 - acc: 0.8927 - val_loss: 0.9288 - val_acc: 0.7539\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', input_shape=(3,32,32)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\"))\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "from keras.optimizers import SGD, rmsprop\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "from keras.optimizers import SGD, rmsprop\n",
    "opt = rmsprop(lr=0.001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt, metrics=['accuracy'])\n",
    "history_callback = model.fit(x_train, y_train,batch_size=150,nb_epoch=8,\n",
    "validation_data=(x_test, y_test),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", input_shape=(3, 32, 32...)`\n",
      "  from ipykernel import kernelapp as app\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\")`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (20, 20), padding=\"same\")`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:10: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(data_format=\"channels_first\", pool_size=(2, 2))`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (20, 20), padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 64, 32, 32)        1792      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 32, 32)        36928     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 64, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 128, 16, 16)       3276928   \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 128, 8, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 128, 8, 8)         6553728   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 128, 8, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 128, 4, 4)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================================================================\n",
      "Total params: 10,923,594\n",
      "Trainable params: 10,923,594\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "50000/50000 [==============================] - 217s - loss: 2.1183 - acc: 0.2838 - val_loss: 2.1769 - val_acc: 0.3152\n",
      "Epoch 2/8\n",
      "50000/50000 [==============================] - 225s - loss: 1.2290 - acc: 0.5665 - val_loss: 1.0832 - val_acc: 0.6286\n",
      "Epoch 3/8\n",
      "50000/50000 [==============================] - 204s - loss: 0.9111 - acc: 0.6817 - val_loss: 1.1176 - val_acc: 0.6012\n",
      "Epoch 4/8\n",
      "50000/50000 [==============================] - 220s - loss: 0.7114 - acc: 0.7539 - val_loss: 1.1437 - val_acc: 0.6899\n",
      "Epoch 5/8\n",
      "50000/50000 [==============================] - 226s - loss: 0.5698 - acc: 0.8053 - val_loss: 0.8045 - val_acc: 0.7419\n",
      "Epoch 6/8\n",
      "50000/50000 [==============================] - 215s - loss: 0.4345 - acc: 0.8507 - val_loss: 0.9317 - val_acc: 0.7281\n",
      "Epoch 7/8\n",
      "50000/50000 [==============================] - 266s - loss: 0.3330 - acc: 0.8858 - val_loss: 0.9931 - val_acc: 0.7428\n",
      "Epoch 8/8\n",
      "50000/50000 [==============================] - 218s - loss: 0.2659 - acc: 0.9122 - val_loss: 1.0743 - val_acc: 0.7348\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', input_shape=(3,32,32)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Convolution2D(128, 20, 20, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\"))\n",
    "model.add(Convolution2D(128, 20, 20, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "from keras.optimizers import SGD, rmsprop\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "from keras.optimizers import SGD, rmsprop\n",
    "opt = rmsprop(lr=0.001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt, metrics=['accuracy'])\n",
    "history_callback = model.fit(x_train, y_train,batch_size=150,nb_epoch=8,\n",
    "validation_data=(x_test, y_test),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (20, 20), padding=\"same\", input_shape=(3, 32, 32...)`\n",
      "  from ipykernel import kernelapp as app\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (20, 20), padding=\"same\")`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\")`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:10: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), data_format=\"channels_first\")`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 64, 32, 32)        76864     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 64, 32, 32)        1638464   \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 64, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 128, 16, 16)       73856     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128, 16, 16)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 128, 8, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 128, 8, 8)         147584    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 128, 8, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 128, 4, 4)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 2,990,986\n",
      "Trainable params: 2,990,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "50000/50000 [==============================] - 133s - loss: 14.4724 - acc: 0.0998 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 2/8\n",
      "50000/50000 [==============================] - 123s - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 3/8\n",
      "50000/50000 [==============================] - 122s - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 4/8\n",
      "50000/50000 [==============================] - 120s - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 5/8\n",
      "50000/50000 [==============================] - 120s - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 6/8\n",
      "50000/50000 [==============================] - 120s - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 7/8\n",
      "50000/50000 [==============================] - 120s - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 8/8\n",
      "50000/50000 [==============================] - 122s - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(64, 20, 20, border_mode='same', input_shape=(3,32,32)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 20, 20, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), dim_ordering=\"th\"))\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "from keras.optimizers import SGD, rmsprop\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "from keras.optimizers import SGD, rmsprop\n",
    "opt = rmsprop(lr=0.001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt, metrics=['accuracy'])\n",
    "history_callback = model.fit(x_train, y_train,batch_size=150,nb_epoch=8,\n",
    "validation_data=(x_test, y_test),shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Se aprecia al agregar filtros más pequeños en las primeras capas un accuracy un poco mayor que con las capas dadas por la pregunta, y además de esto, el tiempo de entrenamiento aumenta considerablemente, por lo que en este problema especifico no es conveniente tener mayor número de filtros en el segundo par de capas convolucionales.</p>\n",
    "\n",
    "<p>En el caso de aumentar el tamaño del filtro de las primeras capas, se obtienen resultados extraños</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>F) Algunos investigadores, han propuesto que las capas de pooling se pueden reemplazar por capas\n",
    "convoluciones con stride 2. >Se reduce dimensionalidad de este modo? Compru\u0013ebelo veri\f",
    "cando los\n",
    "cambios de forma (dimensionalidad) que experimenta un patr\u0013on de entrada a medida que se ejecuta\n",
    "un forward-pass. Entrene la red resultante con el m\u0013etodo que pre\f",
    "era, gr\u0013a\f",
    "cando los errores de entrenamiento,\n",
    "validaci\u0013on y pruebas como funci\u0013on del n\u0013umero de \\epochs\" (\f",
    "jando el m\u0013aximo en un n\u0013umero\n",
    "razonable como T = 25).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (20, 20), input_shape=(3, 32, 32..., padding=\"same\")`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), padding=\"same\")`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"valid\", strides=(2, 2))`\n",
      "D:\\Users\\Felipe\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py:837: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 64, 32, 32)        76864     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 64, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 128, 32, 32)       73856     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 128, 32, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 64, 15, 15)        73792     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 14400)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               7373312   \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 7,602,954\n",
      "Trainable params: 7,602,954\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 113s - loss: 14.4668 - acc: 0.0996 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 112s - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 112s - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 114s - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 112s - loss: 14.5063 - acc: 0.1000 - val_loss: 14.5063 - val_acc: 0.1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(64, 20, 20, border_mode='same', input_shape=(3,32,32)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3, subsample=(2, 2), border_mode='valid'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "\n",
    "from keras.optimizers import SGD, rmsprop\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "from keras.optimizers import SGD, rmsprop\n",
    "opt = rmsprop(lr=0.001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt, metrics=['accuracy'])\n",
    "history_callback = model.fit(x_train, y_train,batch_size=150,nb_epoch=5,\n",
    "validation_data=(x_test, y_test),shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<p>G) Una forma interesante de regularizar modelos entrenados para visi\u0013on arti\f",
    "cial consiste en \\aumentar\"\n",
    "el n\u0013umero de ejemplos de entrenamiento usando transformaciones sencillas como: rotaciones,\n",
    "corrimientos y re\n",
    "exiones, tanto horizontales como verticales. Explique porqu\u0013e este procedimiento\n",
    "podr\u0013\u0010a ayudar a mejorar el modelo. Eval\u0013ue experimentalmente la conveniencia de incorporarlo.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "333/333 [==============================] - 36s - loss: 1.6919 - acc: 0.3995 - val_loss: 1.2463 - val_acc: 0.5543\n",
      "Epoch 2/5\n",
      "333/333 [==============================] - 33s - loss: 1.2547 - acc: 0.5572 - val_loss: 1.0687 - val_acc: 0.6226\n",
      "Epoch 3/5\n",
      "333/333 [==============================] - 36s - loss: 1.0826 - acc: 0.6210 - val_loss: 0.9366 - val_acc: 0.6754\n",
      "Epoch 4/5\n",
      "333/333 [==============================] - 33s - loss: 0.9899 - acc: 0.6555 - val_loss: 0.9003 - val_acc: 0.6857\n",
      "Epoch 5/5\n",
      "333/333 [==============================] - 33s - loss: 0.9167 - acc: 0.6788 - val_loss: 0.8292 - val_acc: 0.7142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ac254ade10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import SGD, rmsprop\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False, # set input mean to 0 over the dataset\n",
    "    samplewise_center=False, # set each sample mean to 0\n",
    "    featurewise_std_normalization=False, # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False, # divide each input by its std\n",
    "    zca_whitening=False, # apply ZCA whitening\n",
    "    rotation_range=0, # randomly rotate images (degrees, 0 to 180)\n",
    "    width_shift_range=0.1, # randomly shift images horizontally (fraction of width)\n",
    "    height_shift_range=0.1, # randomly shift images vertically (fraction of height)\n",
    "    horizontal_flip=True, # randomly flip images\n",
    "    vertical_flip=False) # randomly flip images\n",
    "datagen.fit(x_train)\n",
    "opt = rmsprop(lr=0.001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy',optimizer=opt, metrics=['accuracy'])\n",
    "model.fit_generator(datagen.flow(x_train, y_train,batch_size=150),\n",
    "                    steps_per_epoch=x_train.shape[0]// 150,\n",
    "                    epochs=5,validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
